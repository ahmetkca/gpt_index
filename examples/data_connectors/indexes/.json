{"index_struct": {"text": "\nThe .flake8 document is a configuration file for the Flake8 linter, which specifies the maximum line length and excludes certain directories from being checked.\n\nThe .gitignore document is a configuration file for the Git version control system, which specifies which files and directories should be ignored when committing changes.\n\nThe .readthedocs.yaml document is a configuration file for the Read the Docs documentation platform, which specifies the configuration of the Sphinx documentation, the Python version, and the dependencies.\n\nThe CITATION.cff document is a configuration file for the Citation File Format, which specifies the authors, title, DOI, date released, and URL of the software.\n\nThe LICENSE document is a text file containing the MIT License, which grants permission to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software.\n\nThe MANIFEST.in document is a configuration file for the Python package, which specifies which files should be included in the package.\n\nThe Makefile document is a configuration file for the Make build automation tool, which specifies the commands for formatting, linting, and testing the code.\n\nThe pyproject.tom", "doc_id": "6c39b143-392b-46d6-ae5c-2ba555193c34", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "[flake8]\nexclude =\n    .venv\n    __pycache__\n    notebooks\n    .ipynb_checkpoints\n# Recommend matching the black line length (default 88),\n# rather than using the flake8 default of 79:\nmax-line-length = 88\nextend-ignore =\n    # See https://github.com/PyCQA/pycodestyle/issues/373\n    E203,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".flake8", "file_name": ".flake8"}, "index": 0, "child_indices": [], "ref_doc_id": "0fb583996cdc52a8429eff37f8fb6002a96f2e11", "node_info": null}, "1": {"text": ".DS_Store\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbin/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\netc/\ninclude/\nlib/\nlib64/\nparts/\nsdist/\nshare/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n#", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 1, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "2": {"text": "Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\nnotebooks/\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 2, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "3": {"text": "SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\npyvenv.cfg\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Jetbrains\n.idea\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 3, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "4": {"text": "version: 2\nsphinx:\n  configuration: docs/conf.py\nbuild:\n  image: testing\nformats: all\npython:\n  version: 3.9\n  install:\n    - requirements: docs/requirements.txt\n    - method: pip\n      path: .", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".readthedocs.yaml", "file_name": ".readthedocs.yaml"}, "index": 4, "child_indices": [], "ref_doc_id": "3170150b55fd587d7c76f0eb39382e751f0ccd48", "node_info": null}, "5": {"text": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Liu\"\n  given-names: \"Jerry\"\n  orcid: \"https://orcid.org/0000-0002-6694-3517\"\ntitle: \"GPT Index\"\ndoi: 10.5281/zenodo.1234\ndate-released: 2022-11-1\nurl: \"https://github.com/jerryjliu/gpt_index\"", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CITATION.cff", "file_name": "CITATION.cff"}, "index": 5, "child_indices": [], "ref_doc_id": "986d0c78b5b64bfac17a890c173753babbab9a64", "node_info": null}, "6": {"text": "\n\n\ud83d\udca1 Contributing to GPT Index\n\nInterested in contributing to GPT Index? Here's how to get started! \n\n\n\n\n\nContributions that we're looking for:\n- Bug fixes\n- New features\n\nAll future tasks are tracked in Github Issues Page.\nPlease feel free to open an issue and/or assign an issue to yourself.\n\nAlso, join our Discord for discussions: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\nEnvironment Setup\n\nGPT Index is a Python package. We've tested primarily with Python versions >= 3.8. Here's a quick\nand dirty guide to getting your environment setup.\n\nFirst, create a fork of GPT Index, by clicking the \"Fork\" button on the GPT Index Github page.\nFollowing these steps for more details\non how to fork the repo and clone the forked repo.\n\nThen, create a new Python virtual environment. The command below creates an environment in `.venv`,\nand activates it:\n```bash\npython -m venv .venv\nsource .venv/bin/activate\n```\n\nInstall the required dependencies (this will also install gpt-index through `pip install -e .` \nso", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 6, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "7": {"text": "install gpt-index through `pip install -e .` \nso that you can start developing on it):\n\n```bash\npip install -r requirements.txt\n```\n\nNow you should be set! \n\n\n\n\n\n\nValidating your Change\n\nLet's make sure to `format/lint` our change. For bigger changes,\nlet's also make sure to `test` it and perhaps create an `example notebook`.\n\n\n\n\n\nFormatting/Linting\n\nYou can format and lint your changes with the following commands in the root directory:\n\n```bash\nmake format; make lint\n```\n\nWe run an assortment of linters: `black`, `isort`, `mypy`, `flake8`.\n\n\n\n\n\nTesting\n\nFor bigger changes, you'll want to create a unit test. Our tests are in the `tests` folder.\nWe use `pytest` for unit testing. To run all unit tests, run the following in the root dir:\n\n```bash\npytest tests\n```\n\n\n\n\n\nCreating an Example Notebook\n\nFor changes that involve entirely new features, it may be worth adding an example Jupyter notebook to showcase\nthis feature. \n\nExample notebooks can be found", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 7, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "8": {"text": "to showcase\nthis feature. \n\nExample notebooks can be found in this folder: https://github.com/jerryjliu/gpt_index/tree/main/examples.\n\n\n\n\n\n\nCreating a pull request\n\nSee these instructions\nto open a pull request against the main GPT Index repo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 8, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "9": {"text": "The MIT License\n\nCopyright (c) Jerry Liu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR", "doc_id": null, "embedding": null, "extra_info": {"file_path": "LICENSE", "file_name": "LICENSE"}, "index": 9, "child_indices": [], "ref_doc_id": "d1290334952fd430377e3f8cd28d1174593a507d", "node_info": null}, "10": {"text": "OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.", "doc_id": null, "embedding": null, "extra_info": {"file_path": "LICENSE", "file_name": "LICENSE"}, "index": 10, "child_indices": [], "ref_doc_id": "d1290334952fd430377e3f8cd28d1174593a507d", "node_info": null}, "11": {"text": "include gpt_index/py.typed\ninclude gpt_index/VERSION\ninclude LICENSE", "doc_id": null, "embedding": null, "extra_info": {"file_path": "MANIFEST.in", "file_name": "MANIFEST.in"}, "index": 11, "child_indices": [], "ref_doc_id": "567a63cc13b0be43db26fb4eaca6e6c9fbe90a24", "node_info": null}, "12": {"text": ".PHONY: format lint\n\nformat:\n\tblack .\n\tisort .\n\nlint:\n\tmypy .\n\tblack . --check\n\tisort . --check\n\tflake8 .\n\ntest:\n\tpytest tests", "doc_id": null, "embedding": null, "extra_info": {"file_path": "Makefile", "file_name": "Makefile"}, "index": 12, "child_indices": [], "ref_doc_id": "11f224f37191e11c667b547a80d4dafa15eae1a1", "node_info": null}, "13": {"text": "\n\n\ud83d\uddc2\ufe0f \ufe0fGPT Index\n\nGPT Index is a project consisting of a set of data structures designed to make it easier to \nuse large external knowledge bases with LLMs.\n\nPyPi: https://pypi.org/project/gpt-index/.\n\nDocumentation: https://gpt-index.readthedocs.io/en/latest/.\n\nTwitter: https://twitter.com/gpt_index.\n\nDiscord: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\n\ud83d\ude80 Overview\n\n**NOTE**: This README is not updated as frequently as the documentation. Please check out the documentation above for the latest updates!\n\n\n\n\n\nContext\n- LLMs are a phenomenonal piece of technology for knowledge generation and reasoning.\n- A big limitation of LLMs is context size (e.g. Davinci's limit is 4096 tokens. Large, but not infinite).\n- The ability to feed \"knowledge\" to LLMs is restricted to this limited prompt size and model weights.\n\n\n\n\n\nProposed Solution\n\nAt its core, GPT Index contains a toolkit of **index data structures** designed to easily connect LLM's with your external data.\nGPT Index", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 13, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "14": {"text": "to easily connect LLM's with your external data.\nGPT Index helps to provide the following advantages:\n- Remove concerns over prompt size limitations.\n- Abstract common usage patterns to reduce boilerplate code in your LLM app.\n- Provide data connectors to your common data sources (Google Docs, Slack, etc.).\n- Provide cost transparency + tools that reduce cost while increasing performance.\n\n\nEach data structure offers distinct use cases and a variety of customizable parameters. These indices can then be \n*queried* in a general purpose manner, in order to achieve any task that you would typically achieve with an LLM:\n- Question-Answering\n- Summarization\n- Text Generation (Stories, TODO's, emails, etc.)\n- and more!\n\n\n\n\n\n\n\ud83d\udca1 Contributing\n\nInteresting in contributing? See our Contribution Guide for more details.\n\n\n\n\n\n\ud83d\udcc4 Documentation\n\nFull documentation can be found here: https://gpt-index.readthedocs.io/en/latest/. \n\nPlease check it out for the most up-to-date tutorials, how-to guides, references, and other resources!", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 14, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "15": {"text": "how-to guides, references, and other resources! \n\n\n\n\n\n\n\ud83d\udcbb Example Usage\n\n```\npip install gpt-index\n```\n\nExamples are in the `examples` folder. Indices are in the `indices` folder (see list of indices below).\n\nTo build a simple vector store index:\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'YOUR_OPENAI_API_KEY'\n\nfrom gpt_index import GPTSimpleVectorIndex, SimpleDirectoryReader\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTSimpleVectorIndex(documents)\n```\n\nTo save to and load from disk:\n```python\n\n\n\n\nsave to disk\nindex.save_to_disk('index.json')\n\n\n\n\nload from disk\nindex = GPTSimpleVectorIndex.load_from_disk('index.json')\n```\n\nTo query:\n```python\nindex.query(\"?\")\n```\n\n\n\n\n\n\ud83d\udd27 Dependencies\n\nThe main third-party package requirements are `tiktoken`, `openai`, and `langchain`.\n\nAll requirements should be contained within the `setup.py` file. To run the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 15, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "16": {"text": "should be contained within the `setup.py` file. To run the package locally without building the wheel, simply run `pip install -r requirements.txt`. \n\n\n\n\n\n\n\ud83d\udcd6 Citation\n\nReference to cite if you use GPT Index in a paper:\n\n```\n@software{Liu_GPT_Index_2022,\nauthor = {Liu, Jerry},\ndoi = {10.5281/zenodo.1234},\nmonth = {11},\ntitle = {{GPT Index}},\nurl = {https://github.com/jerryjliu/gpt_index},year = {2022}\n}\n```\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 16, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "17": {"text": "# requirements for external data\n\nwikipedia\npymongo\nslack_sdk\ndiscord.py\n\n# google\ngoogle-api-python-client\ngoogle-auth-httplib2\ngoogle-auth-oauthlib", "doc_id": null, "embedding": null, "extra_info": {"file_path": "data_requirements.txt", "file_name": "data_requirements.txt"}, "index": 17, "child_indices": [], "ref_doc_id": "5b563dc31e23a89e7d920326e5a40f66ae33e727", "node_info": null}, "18": {"text": "[tool.isort]\nprofile = \"black\"\n\n[tool.mypy]\nignore_missing_imports = \"True\"\ndisallow_untyped_defs = \"True\"\nexclude = [\"notebooks\", \"build\"]", "doc_id": null, "embedding": null, "extra_info": {"file_path": "pyproject.toml", "file_name": "pyproject.toml"}, "index": 18, "child_indices": [], "ref_doc_id": "b545d6ada302f1b4f43a714dd4063b52e0cbe0a7", "node_info": null}, "19": {"text": "-e .\n\n# For testing\npytest==7.2.1\npytest-dotenv==0.5.2\n\n# third-party (libraries)\nrake_nltk==1.0.6\nipython==8.9.0\n\n# linting stubs\ntypes-requests==2.28.11.8\ntypes-setuptools==67.1.0.0\n\n# linting\nblack==22.12.0\nisort==5.11.4\nmypy==0.991\nflake8==6.0.0\nflake8-docstrings==1.6.0\npylint==2.15.10\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "requirements.txt", "file_name": "requirements.txt"}, "index": 19, "child_indices": [], "ref_doc_id": "11ee47eb5f86f10cdda33aef7dcba23112bf81f2", "node_info": null}, "20": {"text": "\"\"\"Set up the package.\"\"\"\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\n\nwith open(Path(__file__).absolute().parents[0] / \"gpt_index\" / \"VERSION\") as _f:\n    __version__ = _f.read().strip()\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n    long_description = f.read()\n\ninstall_requires = [\n    \"langchain\",\n    \"openai>=0.26.4\",\n    \"dataclasses_json\",\n    \"transformers\",\n    \"nltk\",\n    \"numpy\",\n    \"tenacity<8.2.0\",\n    \"pandas\",\n]\n\n# NOTE: if python version >= 3.9, install tiktoken\nif sys.version_info >= (3, 9):\n    install_requires.extend([\"tiktoken\"])\n\nsetup(\n    name=\"gpt_index\",\n    version=__version__,\n    packages=find_packages(),\n    description=\"Building an index of GPT", "doc_id": null, "embedding": null, "extra_info": {"file_path": "setup.py", "file_name": "setup.py"}, "index": 20, "child_indices": [], "ref_doc_id": "626dbe2923cb290cec18bc3e102f684c196abd4a", "node_info": null}, "21": {"text": "   description=\"Building an index of GPT summaries.\",\n    install_requires=install_requires,\n    long_description=long_description,\n    license=\"MIT\",\n    url=\"https://github.com/jerryjliu/gpt_index\",\n    include_package_data=True,\n    long_description_content_type=\"text/markdown\",\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "setup.py", "file_name": "setup.py"}, "index": 21, "child_indices": [], "ref_doc_id": "626dbe2923cb290cec18bc3e102f684c196abd4a", "node_info": null}, "22": {"text": "This code file contains several configuration files for the GPT Index project. The .flake8 file is used to configure the Flake8 linter, which is used to check for errors in the code. The .gitignore file is used to specify which files and directories should be ignored by Git. The .readthedocs.yaml file is used to configure the Read the Docs documentation. The CITATION.cff file is used to provide citation information for the project. The CONTRIBUTING.md file provides instructions for how to contribute to the project. The LICENSE file provides the MIT license for the project. The MANIFEST.in file is used to specify which files should be included in the project's distribution package.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a Makefile for the GPT Index project. It contains commands for formatting, linting, and testing the code. It also contains a README.md file with an overview of the project, instructions for contributing, documentation, example usage, dependencies, and a citation. Additionally, there is a data_requirements.txt file with the requirements for external data, a pyproject.toml file with the tool configuration, and a requirements.txt file with the third-party libraries. Finally, there is a setup.py file which sets up the package and includes the package name, version, packages, description, install_requires, long_description, license, url, include_package_data, and long_description_content_type.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file contains several configuration files for the GPT Index project. The .flake8 file is used to configure the Flake8 linter, which is used to check for errors in the code. The .gitignore file is used to specify which files and directories should be ignored by Git. The .readthedocs.yaml file is used to configure the Read the Docs documentation. The CITATION.cff file is used to provide citation information for the project. The CONTRIBUTING.md file provides instructions for how to contribute to the project. The LICENSE file provides the MIT license for the project. The MANIFEST.in file is used to specify which files should be included in the project's distribution package.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a Makefile for the GPT Index project. It contains commands for formatting, linting, and testing the code. It also contains a README.md file with an overview of the project, instructions for contributing, documentation, example usage, dependencies, and a citation. Additionally, there is a data_requirements.txt file with the requirements for external data, a pyproject.toml file with the tool configuration, and a requirements.txt file with the third-party libraries. Finally, there is a setup.py file which sets up the package and includes the package name, version, packages, description, install_requires, long_description, license, url, include_package_data, and long_description_content_type.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"0fb583996cdc52a8429eff37f8fb6002a96f2e11": {"text": "[flake8]\nexclude =\n    .venv\n    __pycache__\n    notebooks\n    .ipynb_checkpoints\n# Recommend matching the black line length (default 88),\n# rather than using the flake8 default of 79:\nmax-line-length = 88\nextend-ignore =\n    # See https://github.com/PyCQA/pycodestyle/issues/373\n    E203,\n", "doc_id": "0fb583996cdc52a8429eff37f8fb6002a96f2e11", "embedding": null, "extra_info": {"file_path": ".flake8", "file_name": ".flake8"}, "__type__": "Document"}, "0b89b543c23ca6b6ab74f3b6ea99653509ece673": {"text": ".DS_Store\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbin/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\netc/\ninclude/\nlib/\nlib64/\nparts/\nsdist/\nshare/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\nnotebooks/\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\npyvenv.cfg\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Jetbrains\n.idea\n", "doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "__type__": "Document"}, "3170150b55fd587d7c76f0eb39382e751f0ccd48": {"text": "version: 2\nsphinx:\n  configuration: docs/conf.py\nbuild:\n  image: testing\nformats: all\npython:\n  version: 3.9\n  install:\n    - requirements: docs/requirements.txt\n    - method: pip\n      path: .", "doc_id": "3170150b55fd587d7c76f0eb39382e751f0ccd48", "embedding": null, "extra_info": {"file_path": ".readthedocs.yaml", "file_name": ".readthedocs.yaml"}, "__type__": "Document"}, "986d0c78b5b64bfac17a890c173753babbab9a64": {"text": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Liu\"\n  given-names: \"Jerry\"\n  orcid: \"https://orcid.org/0000-0002-6694-3517\"\ntitle: \"GPT Index\"\ndoi: 10.5281/zenodo.1234\ndate-released: 2022-11-1\nurl: \"https://github.com/jerryjliu/gpt_index\"", "doc_id": "986d0c78b5b64bfac17a890c173753babbab9a64", "embedding": null, "extra_info": {"file_path": "CITATION.cff", "file_name": "CITATION.cff"}, "__type__": "Document"}, "024b24be1818f09f3b9cd631d9a2a851df2b99ae": {"text": "\n\n\ud83d\udca1 Contributing to GPT Index\n\nInterested in contributing to GPT Index? Here's how to get started! \n\n\n\n\n\nContributions that we're looking for:\n- Bug fixes\n- New features\n\nAll future tasks are tracked in Github Issues Page.\nPlease feel free to open an issue and/or assign an issue to yourself.\n\nAlso, join our Discord for discussions: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\nEnvironment Setup\n\nGPT Index is a Python package. We've tested primarily with Python versions >= 3.8. Here's a quick\nand dirty guide to getting your environment setup.\n\nFirst, create a fork of GPT Index, by clicking the \"Fork\" button on the GPT Index Github page.\nFollowing these steps for more details\non how to fork the repo and clone the forked repo.\n\nThen, create a new Python virtual environment. The command below creates an environment in `.venv`,\nand activates it:\n```bash\npython -m venv .venv\nsource .venv/bin/activate\n```\n\nInstall the required dependencies (this will also install gpt-index through `pip install -e .` \nso that you can start developing on it):\n\n```bash\npip install -r requirements.txt\n```\n\nNow you should be set! \n\n\n\n\n\n\nValidating your Change\n\nLet's make sure to `format/lint` our change. For bigger changes,\nlet's also make sure to `test` it and perhaps create an `example notebook`.\n\n\n\n\n\nFormatting/Linting\n\nYou can format and lint your changes with the following commands in the root directory:\n\n```bash\nmake format; make lint\n```\n\nWe run an assortment of linters: `black`, `isort`, `mypy`, `flake8`.\n\n\n\n\n\nTesting\n\nFor bigger changes, you'll want to create a unit test. Our tests are in the `tests` folder.\nWe use `pytest` for unit testing. To run all unit tests, run the following in the root dir:\n\n```bash\npytest tests\n```\n\n\n\n\n\nCreating an Example Notebook\n\nFor changes that involve entirely new features, it may be worth adding an example Jupyter notebook to showcase\nthis feature. \n\nExample notebooks can be found in this folder: https://github.com/jerryjliu/gpt_index/tree/main/examples.\n\n\n\n\n\n\nCreating a pull request\n\nSee these instructions\nto open a pull request against the main GPT Index repo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "__type__": "Document"}, "d1290334952fd430377e3f8cd28d1174593a507d": {"text": "The MIT License\n\nCopyright (c) Jerry Liu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.", "doc_id": "d1290334952fd430377e3f8cd28d1174593a507d", "embedding": null, "extra_info": {"file_path": "LICENSE", "file_name": "LICENSE"}, "__type__": "Document"}, "567a63cc13b0be43db26fb4eaca6e6c9fbe90a24": {"text": "include gpt_index/py.typed\ninclude gpt_index/VERSION\ninclude LICENSE", "doc_id": "567a63cc13b0be43db26fb4eaca6e6c9fbe90a24", "embedding": null, "extra_info": {"file_path": "MANIFEST.in", "file_name": "MANIFEST.in"}, "__type__": "Document"}, "11f224f37191e11c667b547a80d4dafa15eae1a1": {"text": ".PHONY: format lint\n\nformat:\n\tblack .\n\tisort .\n\nlint:\n\tmypy .\n\tblack . --check\n\tisort . --check\n\tflake8 .\n\ntest:\n\tpytest tests", "doc_id": "11f224f37191e11c667b547a80d4dafa15eae1a1", "embedding": null, "extra_info": {"file_path": "Makefile", "file_name": "Makefile"}, "__type__": "Document"}, "19e81e1976e5791f2485776a341f44f792881557": {"text": "\n\n\ud83d\uddc2\ufe0f \ufe0fGPT Index\n\nGPT Index is a project consisting of a set of data structures designed to make it easier to \nuse large external knowledge bases with LLMs.\n\nPyPi: https://pypi.org/project/gpt-index/.\n\nDocumentation: https://gpt-index.readthedocs.io/en/latest/.\n\nTwitter: https://twitter.com/gpt_index.\n\nDiscord: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\n\ud83d\ude80 Overview\n\n**NOTE**: This README is not updated as frequently as the documentation. Please check out the documentation above for the latest updates!\n\n\n\n\n\nContext\n- LLMs are a phenomenonal piece of technology for knowledge generation and reasoning.\n- A big limitation of LLMs is context size (e.g. Davinci's limit is 4096 tokens. Large, but not infinite).\n- The ability to feed \"knowledge\" to LLMs is restricted to this limited prompt size and model weights.\n\n\n\n\n\nProposed Solution\n\nAt its core, GPT Index contains a toolkit of **index data structures** designed to easily connect LLM's with your external data.\nGPT Index helps to provide the following advantages:\n- Remove concerns over prompt size limitations.\n- Abstract common usage patterns to reduce boilerplate code in your LLM app.\n- Provide data connectors to your common data sources (Google Docs, Slack, etc.).\n- Provide cost transparency + tools that reduce cost while increasing performance.\n\n\nEach data structure offers distinct use cases and a variety of customizable parameters. These indices can then be \n*queried* in a general purpose manner, in order to achieve any task that you would typically achieve with an LLM:\n- Question-Answering\n- Summarization\n- Text Generation (Stories, TODO's, emails, etc.)\n- and more!\n\n\n\n\n\n\n\ud83d\udca1 Contributing\n\nInteresting in contributing? See our Contribution Guide for more details.\n\n\n\n\n\n\ud83d\udcc4 Documentation\n\nFull documentation can be found here: https://gpt-index.readthedocs.io/en/latest/. \n\nPlease check it out for the most up-to-date tutorials, how-to guides, references, and other resources! \n\n\n\n\n\n\n\ud83d\udcbb Example Usage\n\n```\npip install gpt-index\n```\n\nExamples are in the `examples` folder. Indices are in the `indices` folder (see list of indices below).\n\nTo build a simple vector store index:\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'YOUR_OPENAI_API_KEY'\n\nfrom gpt_index import GPTSimpleVectorIndex, SimpleDirectoryReader\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTSimpleVectorIndex(documents)\n```\n\nTo save to and load from disk:\n```python\n\n\n\n\nsave to disk\nindex.save_to_disk('index.json')\n\n\n\n\nload from disk\nindex = GPTSimpleVectorIndex.load_from_disk('index.json')\n```\n\nTo query:\n```python\nindex.query(\"?\")\n```\n\n\n\n\n\n\ud83d\udd27 Dependencies\n\nThe main third-party package requirements are `tiktoken`, `openai`, and `langchain`.\n\nAll requirements should be contained within the `setup.py` file. To run the package locally without building the wheel, simply run `pip install -r requirements.txt`. \n\n\n\n\n\n\n\ud83d\udcd6 Citation\n\nReference to cite if you use GPT Index in a paper:\n\n```\n@software{Liu_GPT_Index_2022,\nauthor = {Liu, Jerry},\ndoi = {10.5281/zenodo.1234},\nmonth = {11},\ntitle = {{GPT Index}},\nurl = {https://github.com/jerryjliu/gpt_index},year = {2022}\n}\n```\n\n", "doc_id": "19e81e1976e5791f2485776a341f44f792881557", "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "__type__": "Document"}, "5b563dc31e23a89e7d920326e5a40f66ae33e727": {"text": "# requirements for external data\n\nwikipedia\npymongo\nslack_sdk\ndiscord.py\n\n# google\ngoogle-api-python-client\ngoogle-auth-httplib2\ngoogle-auth-oauthlib", "doc_id": "5b563dc31e23a89e7d920326e5a40f66ae33e727", "embedding": null, "extra_info": {"file_path": "data_requirements.txt", "file_name": "data_requirements.txt"}, "__type__": "Document"}, "b545d6ada302f1b4f43a714dd4063b52e0cbe0a7": {"text": "[tool.isort]\nprofile = \"black\"\n\n[tool.mypy]\nignore_missing_imports = \"True\"\ndisallow_untyped_defs = \"True\"\nexclude = [\"notebooks\", \"build\"]", "doc_id": "b545d6ada302f1b4f43a714dd4063b52e0cbe0a7", "embedding": null, "extra_info": {"file_path": "pyproject.toml", "file_name": "pyproject.toml"}, "__type__": "Document"}, "11ee47eb5f86f10cdda33aef7dcba23112bf81f2": {"text": "-e .\n\n# For testing\npytest==7.2.1\npytest-dotenv==0.5.2\n\n# third-party (libraries)\nrake_nltk==1.0.6\nipython==8.9.0\n\n# linting stubs\ntypes-requests==2.28.11.8\ntypes-setuptools==67.1.0.0\n\n# linting\nblack==22.12.0\nisort==5.11.4\nmypy==0.991\nflake8==6.0.0\nflake8-docstrings==1.6.0\npylint==2.15.10\n", "doc_id": "11ee47eb5f86f10cdda33aef7dcba23112bf81f2", "embedding": null, "extra_info": {"file_path": "requirements.txt", "file_name": "requirements.txt"}, "__type__": "Document"}, "626dbe2923cb290cec18bc3e102f684c196abd4a": {"text": "\"\"\"Set up the package.\"\"\"\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\n\nwith open(Path(__file__).absolute().parents[0] / \"gpt_index\" / \"VERSION\") as _f:\n    __version__ = _f.read().strip()\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n    long_description = f.read()\n\ninstall_requires = [\n    \"langchain\",\n    \"openai>=0.26.4\",\n    \"dataclasses_json\",\n    \"transformers\",\n    \"nltk\",\n    \"numpy\",\n    \"tenacity<8.2.0\",\n    \"pandas\",\n]\n\n# NOTE: if python version >= 3.9, install tiktoken\nif sys.version_info >= (3, 9):\n    install_requires.extend([\"tiktoken\"])\n\nsetup(\n    name=\"gpt_index\",\n    version=__version__,\n    packages=find_packages(),\n    description=\"Building an index of GPT summaries.\",\n    install_requires=install_requires,\n    long_description=long_description,\n    license=\"MIT\",\n    url=\"https://github.com/jerryjliu/gpt_index\",\n    include_package_data=True,\n    long_description_content_type=\"text/markdown\",\n)\n", "doc_id": "626dbe2923cb290cec18bc3e102f684c196abd4a", "embedding": null, "extra_info": {"file_path": "setup.py", "file_name": "setup.py"}, "__type__": "Document"}, "6c39b143-392b-46d6-ae5c-2ba555193c34": {"text": "\nThe .flake8 document is a configuration file for the Flake8 linter, which specifies the maximum line length and excludes certain directories from being checked.\n\nThe .gitignore document is a configuration file for the Git version control system, which specifies which files and directories should be ignored when committing changes.\n\nThe .readthedocs.yaml document is a configuration file for the Read the Docs documentation platform, which specifies the configuration of the Sphinx documentation, the Python version, and the dependencies.\n\nThe CITATION.cff document is a configuration file for the Citation File Format, which specifies the authors, title, DOI, date released, and URL of the software.\n\nThe LICENSE document is a text file containing the MIT License, which grants permission to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the software.\n\nThe MANIFEST.in document is a configuration file for the Python package, which specifies which files should be included in the package.\n\nThe Makefile document is a configuration file for the Make build automation tool, which specifies the commands for formatting, linting, and testing the code.\n\nThe pyproject.tom", "doc_id": "6c39b143-392b-46d6-ae5c-2ba555193c34", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "[flake8]\nexclude =\n    .venv\n    __pycache__\n    notebooks\n    .ipynb_checkpoints\n# Recommend matching the black line length (default 88),\n# rather than using the flake8 default of 79:\nmax-line-length = 88\nextend-ignore =\n    # See https://github.com/PyCQA/pycodestyle/issues/373\n    E203,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".flake8", "file_name": ".flake8"}, "index": 0, "child_indices": [], "ref_doc_id": "0fb583996cdc52a8429eff37f8fb6002a96f2e11", "node_info": null}, "1": {"text": ".DS_Store\n# Byte-compiled / optimized / DLL files\n__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbin/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\netc/\ninclude/\nlib/\nlib64/\nparts/\nsdist/\nshare/\nvar/\nwheels/\npip-wheel-metadata/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\n\n#", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 1, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "2": {"text": "Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\nnotebooks/\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\n#Pipfile.lock\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 2, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "3": {"text": "SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\npyvenv.cfg\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# Jetbrains\n.idea\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".gitignore", "file_name": ".gitignore"}, "index": 3, "child_indices": [], "ref_doc_id": "0b89b543c23ca6b6ab74f3b6ea99653509ece673", "node_info": null}, "4": {"text": "version: 2\nsphinx:\n  configuration: docs/conf.py\nbuild:\n  image: testing\nformats: all\npython:\n  version: 3.9\n  install:\n    - requirements: docs/requirements.txt\n    - method: pip\n      path: .", "doc_id": null, "embedding": null, "extra_info": {"file_path": ".readthedocs.yaml", "file_name": ".readthedocs.yaml"}, "index": 4, "child_indices": [], "ref_doc_id": "3170150b55fd587d7c76f0eb39382e751f0ccd48", "node_info": null}, "5": {"text": "cff-version: 1.2.0\nmessage: \"If you use this software, please cite it as below.\"\nauthors:\n- family-names: \"Liu\"\n  given-names: \"Jerry\"\n  orcid: \"https://orcid.org/0000-0002-6694-3517\"\ntitle: \"GPT Index\"\ndoi: 10.5281/zenodo.1234\ndate-released: 2022-11-1\nurl: \"https://github.com/jerryjliu/gpt_index\"", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CITATION.cff", "file_name": "CITATION.cff"}, "index": 5, "child_indices": [], "ref_doc_id": "986d0c78b5b64bfac17a890c173753babbab9a64", "node_info": null}, "6": {"text": "\n\n\ud83d\udca1 Contributing to GPT Index\n\nInterested in contributing to GPT Index? Here's how to get started! \n\n\n\n\n\nContributions that we're looking for:\n- Bug fixes\n- New features\n\nAll future tasks are tracked in Github Issues Page.\nPlease feel free to open an issue and/or assign an issue to yourself.\n\nAlso, join our Discord for discussions: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\nEnvironment Setup\n\nGPT Index is a Python package. We've tested primarily with Python versions >= 3.8. Here's a quick\nand dirty guide to getting your environment setup.\n\nFirst, create a fork of GPT Index, by clicking the \"Fork\" button on the GPT Index Github page.\nFollowing these steps for more details\non how to fork the repo and clone the forked repo.\n\nThen, create a new Python virtual environment. The command below creates an environment in `.venv`,\nand activates it:\n```bash\npython -m venv .venv\nsource .venv/bin/activate\n```\n\nInstall the required dependencies (this will also install gpt-index through `pip install -e .` \nso", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 6, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "7": {"text": "install gpt-index through `pip install -e .` \nso that you can start developing on it):\n\n```bash\npip install -r requirements.txt\n```\n\nNow you should be set! \n\n\n\n\n\n\nValidating your Change\n\nLet's make sure to `format/lint` our change. For bigger changes,\nlet's also make sure to `test` it and perhaps create an `example notebook`.\n\n\n\n\n\nFormatting/Linting\n\nYou can format and lint your changes with the following commands in the root directory:\n\n```bash\nmake format; make lint\n```\n\nWe run an assortment of linters: `black`, `isort`, `mypy`, `flake8`.\n\n\n\n\n\nTesting\n\nFor bigger changes, you'll want to create a unit test. Our tests are in the `tests` folder.\nWe use `pytest` for unit testing. To run all unit tests, run the following in the root dir:\n\n```bash\npytest tests\n```\n\n\n\n\n\nCreating an Example Notebook\n\nFor changes that involve entirely new features, it may be worth adding an example Jupyter notebook to showcase\nthis feature. \n\nExample notebooks can be found", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 7, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "8": {"text": "to showcase\nthis feature. \n\nExample notebooks can be found in this folder: https://github.com/jerryjliu/gpt_index/tree/main/examples.\n\n\n\n\n\n\nCreating a pull request\n\nSee these instructions\nto open a pull request against the main GPT Index repo.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "CONTRIBUTING.md", "file_name": "CONTRIBUTING.md"}, "index": 8, "child_indices": [], "ref_doc_id": "024b24be1818f09f3b9cd631d9a2a851df2b99ae", "node_info": null}, "9": {"text": "The MIT License\n\nCopyright (c) Jerry Liu\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR", "doc_id": null, "embedding": null, "extra_info": {"file_path": "LICENSE", "file_name": "LICENSE"}, "index": 9, "child_indices": [], "ref_doc_id": "d1290334952fd430377e3f8cd28d1174593a507d", "node_info": null}, "10": {"text": "OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.", "doc_id": null, "embedding": null, "extra_info": {"file_path": "LICENSE", "file_name": "LICENSE"}, "index": 10, "child_indices": [], "ref_doc_id": "d1290334952fd430377e3f8cd28d1174593a507d", "node_info": null}, "11": {"text": "include gpt_index/py.typed\ninclude gpt_index/VERSION\ninclude LICENSE", "doc_id": null, "embedding": null, "extra_info": {"file_path": "MANIFEST.in", "file_name": "MANIFEST.in"}, "index": 11, "child_indices": [], "ref_doc_id": "567a63cc13b0be43db26fb4eaca6e6c9fbe90a24", "node_info": null}, "12": {"text": ".PHONY: format lint\n\nformat:\n\tblack .\n\tisort .\n\nlint:\n\tmypy .\n\tblack . --check\n\tisort . --check\n\tflake8 .\n\ntest:\n\tpytest tests", "doc_id": null, "embedding": null, "extra_info": {"file_path": "Makefile", "file_name": "Makefile"}, "index": 12, "child_indices": [], "ref_doc_id": "11f224f37191e11c667b547a80d4dafa15eae1a1", "node_info": null}, "13": {"text": "\n\n\ud83d\uddc2\ufe0f \ufe0fGPT Index\n\nGPT Index is a project consisting of a set of data structures designed to make it easier to \nuse large external knowledge bases with LLMs.\n\nPyPi: https://pypi.org/project/gpt-index/.\n\nDocumentation: https://gpt-index.readthedocs.io/en/latest/.\n\nTwitter: https://twitter.com/gpt_index.\n\nDiscord: https://discord.gg/dGcwcsnxhU.\n\n\n\n\n\n\ud83d\ude80 Overview\n\n**NOTE**: This README is not updated as frequently as the documentation. Please check out the documentation above for the latest updates!\n\n\n\n\n\nContext\n- LLMs are a phenomenonal piece of technology for knowledge generation and reasoning.\n- A big limitation of LLMs is context size (e.g. Davinci's limit is 4096 tokens. Large, but not infinite).\n- The ability to feed \"knowledge\" to LLMs is restricted to this limited prompt size and model weights.\n\n\n\n\n\nProposed Solution\n\nAt its core, GPT Index contains a toolkit of **index data structures** designed to easily connect LLM's with your external data.\nGPT Index", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 13, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "14": {"text": "to easily connect LLM's with your external data.\nGPT Index helps to provide the following advantages:\n- Remove concerns over prompt size limitations.\n- Abstract common usage patterns to reduce boilerplate code in your LLM app.\n- Provide data connectors to your common data sources (Google Docs, Slack, etc.).\n- Provide cost transparency + tools that reduce cost while increasing performance.\n\n\nEach data structure offers distinct use cases and a variety of customizable parameters. These indices can then be \n*queried* in a general purpose manner, in order to achieve any task that you would typically achieve with an LLM:\n- Question-Answering\n- Summarization\n- Text Generation (Stories, TODO's, emails, etc.)\n- and more!\n\n\n\n\n\n\n\ud83d\udca1 Contributing\n\nInteresting in contributing? See our Contribution Guide for more details.\n\n\n\n\n\n\ud83d\udcc4 Documentation\n\nFull documentation can be found here: https://gpt-index.readthedocs.io/en/latest/. \n\nPlease check it out for the most up-to-date tutorials, how-to guides, references, and other resources!", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 14, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "15": {"text": "how-to guides, references, and other resources! \n\n\n\n\n\n\n\ud83d\udcbb Example Usage\n\n```\npip install gpt-index\n```\n\nExamples are in the `examples` folder. Indices are in the `indices` folder (see list of indices below).\n\nTo build a simple vector store index:\n```python\nimport os\nos.environ[\"OPENAI_API_KEY\"] = 'YOUR_OPENAI_API_KEY'\n\nfrom gpt_index import GPTSimpleVectorIndex, SimpleDirectoryReader\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTSimpleVectorIndex(documents)\n```\n\nTo save to and load from disk:\n```python\n\n\n\n\nsave to disk\nindex.save_to_disk('index.json')\n\n\n\n\nload from disk\nindex = GPTSimpleVectorIndex.load_from_disk('index.json')\n```\n\nTo query:\n```python\nindex.query(\"?\")\n```\n\n\n\n\n\n\ud83d\udd27 Dependencies\n\nThe main third-party package requirements are `tiktoken`, `openai`, and `langchain`.\n\nAll requirements should be contained within the `setup.py` file. To run the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 15, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "16": {"text": "should be contained within the `setup.py` file. To run the package locally without building the wheel, simply run `pip install -r requirements.txt`. \n\n\n\n\n\n\n\ud83d\udcd6 Citation\n\nReference to cite if you use GPT Index in a paper:\n\n```\n@software{Liu_GPT_Index_2022,\nauthor = {Liu, Jerry},\ndoi = {10.5281/zenodo.1234},\nmonth = {11},\ntitle = {{GPT Index}},\nurl = {https://github.com/jerryjliu/gpt_index},year = {2022}\n}\n```\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "README.md", "file_name": "README.md"}, "index": 16, "child_indices": [], "ref_doc_id": "19e81e1976e5791f2485776a341f44f792881557", "node_info": null}, "17": {"text": "# requirements for external data\n\nwikipedia\npymongo\nslack_sdk\ndiscord.py\n\n# google\ngoogle-api-python-client\ngoogle-auth-httplib2\ngoogle-auth-oauthlib", "doc_id": null, "embedding": null, "extra_info": {"file_path": "data_requirements.txt", "file_name": "data_requirements.txt"}, "index": 17, "child_indices": [], "ref_doc_id": "5b563dc31e23a89e7d920326e5a40f66ae33e727", "node_info": null}, "18": {"text": "[tool.isort]\nprofile = \"black\"\n\n[tool.mypy]\nignore_missing_imports = \"True\"\ndisallow_untyped_defs = \"True\"\nexclude = [\"notebooks\", \"build\"]", "doc_id": null, "embedding": null, "extra_info": {"file_path": "pyproject.toml", "file_name": "pyproject.toml"}, "index": 18, "child_indices": [], "ref_doc_id": "b545d6ada302f1b4f43a714dd4063b52e0cbe0a7", "node_info": null}, "19": {"text": "-e .\n\n# For testing\npytest==7.2.1\npytest-dotenv==0.5.2\n\n# third-party (libraries)\nrake_nltk==1.0.6\nipython==8.9.0\n\n# linting stubs\ntypes-requests==2.28.11.8\ntypes-setuptools==67.1.0.0\n\n# linting\nblack==22.12.0\nisort==5.11.4\nmypy==0.991\nflake8==6.0.0\nflake8-docstrings==1.6.0\npylint==2.15.10\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "requirements.txt", "file_name": "requirements.txt"}, "index": 19, "child_indices": [], "ref_doc_id": "11ee47eb5f86f10cdda33aef7dcba23112bf81f2", "node_info": null}, "20": {"text": "\"\"\"Set up the package.\"\"\"\nimport sys\nfrom pathlib import Path\n\nfrom setuptools import find_packages, setup\n\nwith open(Path(__file__).absolute().parents[0] / \"gpt_index\" / \"VERSION\") as _f:\n    __version__ = _f.read().strip()\n\nwith open(\"README.md\", \"r\", encoding=\"utf-8\") as f:\n    long_description = f.read()\n\ninstall_requires = [\n    \"langchain\",\n    \"openai>=0.26.4\",\n    \"dataclasses_json\",\n    \"transformers\",\n    \"nltk\",\n    \"numpy\",\n    \"tenacity<8.2.0\",\n    \"pandas\",\n]\n\n# NOTE: if python version >= 3.9, install tiktoken\nif sys.version_info >= (3, 9):\n    install_requires.extend([\"tiktoken\"])\n\nsetup(\n    name=\"gpt_index\",\n    version=__version__,\n    packages=find_packages(),\n    description=\"Building an index of GPT", "doc_id": null, "embedding": null, "extra_info": {"file_path": "setup.py", "file_name": "setup.py"}, "index": 20, "child_indices": [], "ref_doc_id": "626dbe2923cb290cec18bc3e102f684c196abd4a", "node_info": null}, "21": {"text": "   description=\"Building an index of GPT summaries.\",\n    install_requires=install_requires,\n    long_description=long_description,\n    license=\"MIT\",\n    url=\"https://github.com/jerryjliu/gpt_index\",\n    include_package_data=True,\n    long_description_content_type=\"text/markdown\",\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "setup.py", "file_name": "setup.py"}, "index": 21, "child_indices": [], "ref_doc_id": "626dbe2923cb290cec18bc3e102f684c196abd4a", "node_info": null}, "22": {"text": "This code file contains several configuration files for the GPT Index project. The .flake8 file is used to configure the Flake8 linter, which is used to check for errors in the code. The .gitignore file is used to specify which files and directories should be ignored by Git. The .readthedocs.yaml file is used to configure the Read the Docs documentation. The CITATION.cff file is used to provide citation information for the project. The CONTRIBUTING.md file provides instructions for how to contribute to the project. The LICENSE file provides the MIT license for the project. The MANIFEST.in file is used to specify which files should be included in the project's distribution package.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a Makefile for the GPT Index project. It contains commands for formatting, linting, and testing the code. It also contains a README.md file with an overview of the project, instructions for contributing, documentation, example usage, dependencies, and a citation. Additionally, there is a data_requirements.txt file with the requirements for external data, a pyproject.toml file with the tool configuration, and a requirements.txt file with the third-party libraries. Finally, there is a setup.py file which sets up the package and includes the package name, version, packages, description, install_requires, long_description, license, url, include_package_data, and long_description_content_type.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file contains several configuration files for the GPT Index project. The .flake8 file is used to configure the Flake8 linter, which is used to check for errors in the code. The .gitignore file is used to specify which files and directories should be ignored by Git. The .readthedocs.yaml file is used to configure the Read the Docs documentation. The CITATION.cff file is used to provide citation information for the project. The CONTRIBUTING.md file provides instructions for how to contribute to the project. The LICENSE file provides the MIT license for the project. The MANIFEST.in file is used to specify which files should be included in the project's distribution package.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a Makefile for the GPT Index project. It contains commands for formatting, linting, and testing the code. It also contains a README.md file with an overview of the project, instructions for contributing, documentation, example usage, dependencies, and a citation. Additionally, there is a data_requirements.txt file with the requirements for external data, a pyproject.toml file with the tool configuration, and a requirements.txt file with the third-party libraries. Finally, there is a setup.py file which sets up the package and includes the package name, version, packages, description, install_requires, long_description, license, url, include_package_data, and long_description_content_type.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}