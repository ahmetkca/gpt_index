{"index_struct": {"text": "\nThe summaries of these documents are concise overviews of the content of the documents, generated using a GPT-based language model. The language model is prompted with a summary prompt and provided with the text chunks as context. The summaries are generated using the GPTTreeIndexBuilder class, which builds up a tree-index in a bottom-up fashion.", "doc_id": "7028514f-8fd9-491a-aeb6-47d6dd018281", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\n\n\ud83c\udf32 Tree Index\n\nCurrently the tree index refers to the `GPTTreeIndex` class. It organizes external data into a tree structure that can be queried.\n\n\n\n\n\nIndex Construction\n\nThe `GPTTreeIndex` first takes in a set of text documents as input. It then builds up a tree-index in a bottom-up fashion; each parent node is able to summarize the children nodes using a general **summarization prompt**; each intermediate node contains text summarizing the components below. Once the index is built, it can be saved to disk as a JSON and loaded for future use.\n\n\n\n\n\nQuery\n\nThere are two query modes: `default` and `retrieve`.\n\n**Default (GPTTreeIndexLeafQuery)**\n\nUsing a **query prompt template**, the GPTTreeIndex will be able to recursively perform tree traversal in a top-down fashion in order to answer a question. For example, in the very beginning GPT-3 is tasked with selecting between _n_ top-level nodes which best answers a provided query, by outputting a number as a multiple-choice problem. The", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 0, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "1": {"text": "provided query, by outputting a number as a multiple-choice problem. The GPTTreeIndex then uses the number to select the corresponding node, and the process repeats recursively among the children nodes until a leaf node is reached.\n\n**Retrieve (GPTTreeIndexRetQuery)**\n\nSimply use the root nodes as context to synthesize an answer to the query. This is especially effective if the tree is preseeded with a `query_str`.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTTreeIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTTreeIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_tree.json')\n\n\n\n\nload index from disk\nindex = GPTListIndex.load_from_disk('index_tree.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ\n\n**Why build a tree? Why not just incrementally go through each chunk?**\n\nAlgorithmically speaking, $O(\\log N)$ is better than", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 1, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "2": {"text": "speaking, $O(\\log N)$ is better than $O(N)$.\n\nMore broadly, building a tree helps us to test GPT's capabilities in modeling information in a hierarchy. It seems to me that our brains organize information in a similar way (citation needed). We can use this design to test how GPT can use its own hierarchy to answer questions.\n\nPractically speaking, it is much cheaper to do so and I want to limit my monthly spending (see below for costs).\n\n**How much does this cost to run?**\n\nWe currently use the Davinci model for good results. Unfortunately Davinci is quite expensive. The cost of building the tree is roughly\n$cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens ($0.02 as mentioned on the pricing page). The cost of querying the tree is roughly \n$c\\log(N)\\frac{p}{1000}$.\n\nFor the NYC example, this equates to \\$~0.40 per query.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 2, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "3": {"text": "\"\"\"Tree-structured Index Data Structures.\"\"\"\n\n# indices\nfrom gpt_index.indices.tree.base import GPTTreeIndex\n\n__all__ = [\n    \"GPTTreeIndex\",\n]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/__init__.py", "file_name": "__init__.py"}, "index": 3, "child_indices": [], "ref_doc_id": "c13b792b07486dc27964e134193fcbfbe2b877a5", "node_info": null}, "4": {"text": "\"\"\"Tree-based index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import IndexGraph\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.common.tree.base import GPTTreeIndexBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.query.tree.leaf_query import GPTTreeIndexLeafQuery\nfrom gpt_index.indices.query.tree.retrieve_query import GPTTreeIndexRetQuery\nfrom gpt_index.indices.query.tree.summarize_query import GPTTreeIndexSummarizeQuery\nfrom gpt_index.indices.tree.inserter import GPTIndexInserter\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "5": {"text": "import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.prompts.prompts import SummaryPrompt, TreeInsertPrompt\nfrom gpt_index.schema import BaseDocument\n\nREQUIRE_TREE_MODES = {\n    QueryMode.DEFAULT,\n    QueryMode.EMBEDDING,\n    QueryMode.RETRIEVE,\n}\n\n\nclass GPTTreeIndex(BaseGPTIndex[IndexGraph]):\n    \"\"\"GPT Tree Index.\n\n    The tree index is a tree-structured index, where each node is a summary of\n    the children nodes. During index construction, the tree is constructed\n    in a bottoms-up fashion until we end up with a set of root_nodes.\n\n    There are a few different options during query time (see :ref:`Ref-Query`).\n    The main option is to traverse down the tree from the root nodes.\n    A secondary answer is to directly", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "6": {"text": "the root nodes.\n    A secondary answer is to directly synthesize the answer from the root nodes.\n\n    Args:\n        summary_template (Optional[SummaryPrompt]): A Summarization Prompt\n            (see :ref:`Prompt-Templates`).\n        insert_prompt (Optional[TreeInsertPrompt]): An Tree Insertion Prompt\n            (see :ref:`Prompt-Templates`).\n        num_children (int): The number of children each node should have.\n        build_tree (bool): Whether to build the tree during index construction.\n\n    \"\"\"\n\n    index_struct_cls = IndexGraph\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[IndexGraph] = None,\n        summary_template: Optional[SummaryPrompt] =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "7": {"text": "     summary_template: Optional[SummaryPrompt] = None,\n        insert_prompt: Optional[TreeInsertPrompt] = None,\n        num_children: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        build_tree: bool = True,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.num_children = num_children\n        self.summary_template = summary_template or DEFAULT_SUMMARY_PROMPT\n        self.insert_prompt: TreeInsertPrompt = insert_prompt or DEFAULT_INSERT_PROMPT\n        self.build_tree = build_tree\n        super().__init__(\n            documents=documents,\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "8": {"text": "       documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTTreeIndexLeafQuery,\n            QueryMode.EMBEDDING: GPTTreeIndexEmbeddingQuery,\n            QueryMode.RETRIEVE: GPTTreeIndexRetQuery,\n            QueryMode.SUMMARIZE: GPTTreeIndexSummarizeQuery,\n        }\n\n    def _validate_build_tree_required(self, mode: QueryMode) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "9": {"text": "mode: QueryMode) -> None:\n        \"\"\"Check if index supports modes that require trees.\"\"\"\n        if mode in REQUIRE_TREE_MODES and not self.build_tree:\n            raise ValueError(\n                \"Index was constructed without building trees, \"\n                f\"but mode {mode} requires trees.\"\n            )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        self._validate_build_tree_required(mode)\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> IndexGraph:\n        \"\"\"Build the index from", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "10": {"text": "IndexGraph:\n        \"\"\"Build the index from documents.\"\"\"\n        # do simple concatenation\n        index_builder = GPTTreeIndexBuilder(\n            self.num_children,\n            self.summary_template,\n            self._llm_predictor,\n            self._prompt_helper,\n        )\n        index_graph = index_builder.build_from_text(\n            documents, build_tree=self.build_tree\n        )\n        return index_graph\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        # TODO: allow to customize insert prompt\n        inserter = GPTIndexInserter(\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "11": {"text": "   inserter = GPTIndexInserter(\n            self.index_struct,\n            num_children=self.num_children,\n            insert_prompt=self.insert_prompt,\n            summary_prompt=self.summary_template,\n            llm_predictor=self._llm_predictor,\n            prompt_helper=self._prompt_helper,\n        )\n        inserter.insert(document)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not implemented for tree index.\")\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "12": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 12, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "13": {"text": "    prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 13, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "14": {"text": "       self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 14, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "15": {"text": "           ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 15, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "16": {"text": "           # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n            summary1, _ = self._llm_predictor.predict(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 16, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "17": {"text": "_ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n             ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 17, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "18": {"text": "               self.summary_prompt, context_str=text_chunk2\n            )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 18, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "19": {"text": "               self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 19, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "20": {"text": "== 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 20, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "21": {"text": "               self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 21, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "22": {"text": "> len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 22, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "23": {"text": "           cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 23, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "24": {"text": "       for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 24, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "25": {"text": "The GPTTreeIndex is a tree-structured index that organizes external data into a tree structure that can be queried. It is built in a bottom-up fashion, with each parent node summarizing the children nodes using a general summarization prompt. There are two query modes: Default (GPTTreeIndexLeafQuery) and Retrieve (GPTTreeIndexRetQuery). The cost of building the tree is roughly $cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens. The GPTTreeIndex class takes in a set of text documents as input, and can be saved to disk as a JSON and loaded for future use.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file is for the GPT Tree Index inserter. It contains a class GPTIndexInserter which initializes with parameters such as index_graph, llm_predictor, prompt_helper, num_children, insert_prompt, and summary_prompt. It contains methods such as _insert_under_parent_and_consolidate, _insert_node, and insert. The _insert_under_parent_and_consolidate method inserts a node under a parent node and consolidates by dividing up child nodes and creating a new intermediate layer of nodes. The _insert_node method tries to find the right summary node to insert under and the insert method inserts into the index_graph.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "inserter.py is a file located in the gpt_index/indices/tree directory. It contains a function that takes in a list of text chunks and a document, and inserts each text chunk into the document as a node. This allows for the efficient storage and retrieval of text chunks in the document.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"25": {"text": "The GPTTreeIndex is a tree-structured index that organizes external data into a tree structure that can be queried. It is built in a bottom-up fashion, with each parent node summarizing the children nodes using a general summarization prompt. There are two query modes: Default (GPTTreeIndexLeafQuery) and Retrieve (GPTTreeIndexRetQuery). The cost of building the tree is roughly $cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens. The GPTTreeIndex class takes in a set of text documents as input, and can be saved to disk as a JSON and loaded for future use.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file is for the GPT Tree Index inserter. It contains a class GPTIndexInserter which initializes with parameters such as index_graph, llm_predictor, prompt_helper, num_children, insert_prompt, and summary_prompt. It contains methods such as _insert_under_parent_and_consolidate, _insert_node, and insert. The _insert_under_parent_and_consolidate method inserts a node under a parent node and consolidates by dividing up child nodes and creating a new intermediate layer of nodes. The _insert_node method tries to find the right summary node to insert under and the insert method inserts into the index_graph.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "inserter.py is a file located in the gpt_index/indices/tree directory. It contains a function that takes in a list of text chunks and a document, and inserts each text chunk into the document as a node. This allows for the efficient storage and retrieval of text chunks in the document.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd": {"text": "\n\n\ud83c\udf32 Tree Index\n\nCurrently the tree index refers to the `GPTTreeIndex` class. It organizes external data into a tree structure that can be queried.\n\n\n\n\n\nIndex Construction\n\nThe `GPTTreeIndex` first takes in a set of text documents as input. It then builds up a tree-index in a bottom-up fashion; each parent node is able to summarize the children nodes using a general **summarization prompt**; each intermediate node contains text summarizing the components below. Once the index is built, it can be saved to disk as a JSON and loaded for future use.\n\n\n\n\n\nQuery\n\nThere are two query modes: `default` and `retrieve`.\n\n**Default (GPTTreeIndexLeafQuery)**\n\nUsing a **query prompt template**, the GPTTreeIndex will be able to recursively perform tree traversal in a top-down fashion in order to answer a question. For example, in the very beginning GPT-3 is tasked with selecting between _n_ top-level nodes which best answers a provided query, by outputting a number as a multiple-choice problem. The GPTTreeIndex then uses the number to select the corresponding node, and the process repeats recursively among the children nodes until a leaf node is reached.\n\n**Retrieve (GPTTreeIndexRetQuery)**\n\nSimply use the root nodes as context to synthesize an answer to the query. This is especially effective if the tree is preseeded with a `query_str`.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTTreeIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTTreeIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_tree.json')\n\n\n\n\nload index from disk\nindex = GPTListIndex.load_from_disk('index_tree.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ\n\n**Why build a tree? Why not just incrementally go through each chunk?**\n\nAlgorithmically speaking, $O(\\log N)$ is better than $O(N)$.\n\nMore broadly, building a tree helps us to test GPT's capabilities in modeling information in a hierarchy. It seems to me that our brains organize information in a similar way (citation needed). We can use this design to test how GPT can use its own hierarchy to answer questions.\n\nPractically speaking, it is much cheaper to do so and I want to limit my monthly spending (see below for costs).\n\n**How much does this cost to run?**\n\nWe currently use the Davinci model for good results. Unfortunately Davinci is quite expensive. The cost of building the tree is roughly\n$cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens ($0.02 as mentioned on the pricing page). The cost of querying the tree is roughly \n$c\\log(N)\\frac{p}{1000}$.\n\nFor the NYC example, this equates to \\$~0.40 per query.\n\n", "doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "__type__": "Document"}, "c13b792b07486dc27964e134193fcbfbe2b877a5": {"text": "\"\"\"Tree-structured Index Data Structures.\"\"\"\n\n# indices\nfrom gpt_index.indices.tree.base import GPTTreeIndex\n\n__all__ = [\n    \"GPTTreeIndex\",\n]\n", "doc_id": "c13b792b07486dc27964e134193fcbfbe2b877a5", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39": {"text": "\"\"\"Tree-based index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import IndexGraph\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.common.tree.base import GPTTreeIndexBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.query.tree.leaf_query import GPTTreeIndexLeafQuery\nfrom gpt_index.indices.query.tree.retrieve_query import GPTTreeIndexRetQuery\nfrom gpt_index.indices.query.tree.summarize_query import GPTTreeIndexSummarizeQuery\nfrom gpt_index.indices.tree.inserter import GPTIndexInserter\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.prompts.prompts import SummaryPrompt, TreeInsertPrompt\nfrom gpt_index.schema import BaseDocument\n\nREQUIRE_TREE_MODES = {\n    QueryMode.DEFAULT,\n    QueryMode.EMBEDDING,\n    QueryMode.RETRIEVE,\n}\n\n\nclass GPTTreeIndex(BaseGPTIndex[IndexGraph]):\n    \"\"\"GPT Tree Index.\n\n    The tree index is a tree-structured index, where each node is a summary of\n    the children nodes. During index construction, the tree is constructed\n    in a bottoms-up fashion until we end up with a set of root_nodes.\n\n    There are a few different options during query time (see :ref:`Ref-Query`).\n    The main option is to traverse down the tree from the root nodes.\n    A secondary answer is to directly synthesize the answer from the root nodes.\n\n    Args:\n        summary_template (Optional[SummaryPrompt]): A Summarization Prompt\n            (see :ref:`Prompt-Templates`).\n        insert_prompt (Optional[TreeInsertPrompt]): An Tree Insertion Prompt\n            (see :ref:`Prompt-Templates`).\n        num_children (int): The number of children each node should have.\n        build_tree (bool): Whether to build the tree during index construction.\n\n    \"\"\"\n\n    index_struct_cls = IndexGraph\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[IndexGraph] = None,\n        summary_template: Optional[SummaryPrompt] = None,\n        insert_prompt: Optional[TreeInsertPrompt] = None,\n        num_children: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        build_tree: bool = True,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.num_children = num_children\n        self.summary_template = summary_template or DEFAULT_SUMMARY_PROMPT\n        self.insert_prompt: TreeInsertPrompt = insert_prompt or DEFAULT_INSERT_PROMPT\n        self.build_tree = build_tree\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTTreeIndexLeafQuery,\n            QueryMode.EMBEDDING: GPTTreeIndexEmbeddingQuery,\n            QueryMode.RETRIEVE: GPTTreeIndexRetQuery,\n            QueryMode.SUMMARIZE: GPTTreeIndexSummarizeQuery,\n        }\n\n    def _validate_build_tree_required(self, mode: QueryMode) -> None:\n        \"\"\"Check if index supports modes that require trees.\"\"\"\n        if mode in REQUIRE_TREE_MODES and not self.build_tree:\n            raise ValueError(\n                \"Index was constructed without building trees, \"\n                f\"but mode {mode} requires trees.\"\n            )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        self._validate_build_tree_required(mode)\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> IndexGraph:\n        \"\"\"Build the index from documents.\"\"\"\n        # do simple concatenation\n        index_builder = GPTTreeIndexBuilder(\n            self.num_children,\n            self.summary_template,\n            self._llm_predictor,\n            self._prompt_helper,\n        )\n        index_graph = index_builder.build_from_text(\n            documents, build_tree=self.build_tree\n        )\n        return index_graph\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        # TODO: allow to customize insert prompt\n        inserter = GPTIndexInserter(\n            self.index_struct,\n            num_children=self.num_children,\n            insert_prompt=self.insert_prompt,\n            summary_prompt=self.summary_template,\n            llm_predictor=self._llm_predictor,\n            prompt_helper=self._prompt_helper,\n        )\n        inserter.insert(document)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not implemented for tree index.\")\n", "doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "__type__": "Document"}, "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n            ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n            summary1, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk2\n            )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n                self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n                self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "__type__": "Document"}, "7028514f-8fd9-491a-aeb6-47d6dd018281": {"text": "\nThe summaries of these documents are concise overviews of the content of the documents, generated using a GPT-based language model. The language model is prompted with a summary prompt and provided with the text chunks as context. The summaries are generated using the GPTTreeIndexBuilder class, which builds up a tree-index in a bottom-up fashion.", "doc_id": "7028514f-8fd9-491a-aeb6-47d6dd018281", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\n\n\ud83c\udf32 Tree Index\n\nCurrently the tree index refers to the `GPTTreeIndex` class. It organizes external data into a tree structure that can be queried.\n\n\n\n\n\nIndex Construction\n\nThe `GPTTreeIndex` first takes in a set of text documents as input. It then builds up a tree-index in a bottom-up fashion; each parent node is able to summarize the children nodes using a general **summarization prompt**; each intermediate node contains text summarizing the components below. Once the index is built, it can be saved to disk as a JSON and loaded for future use.\n\n\n\n\n\nQuery\n\nThere are two query modes: `default` and `retrieve`.\n\n**Default (GPTTreeIndexLeafQuery)**\n\nUsing a **query prompt template**, the GPTTreeIndex will be able to recursively perform tree traversal in a top-down fashion in order to answer a question. For example, in the very beginning GPT-3 is tasked with selecting between _n_ top-level nodes which best answers a provided query, by outputting a number as a multiple-choice problem. The", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 0, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "1": {"text": "provided query, by outputting a number as a multiple-choice problem. The GPTTreeIndex then uses the number to select the corresponding node, and the process repeats recursively among the children nodes until a leaf node is reached.\n\n**Retrieve (GPTTreeIndexRetQuery)**\n\nSimply use the root nodes as context to synthesize an answer to the query. This is especially effective if the tree is preseeded with a `query_str`.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTTreeIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTTreeIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_tree.json')\n\n\n\n\nload index from disk\nindex = GPTListIndex.load_from_disk('index_tree.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ\n\n**Why build a tree? Why not just incrementally go through each chunk?**\n\nAlgorithmically speaking, $O(\\log N)$ is better than", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 1, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "2": {"text": "speaking, $O(\\log N)$ is better than $O(N)$.\n\nMore broadly, building a tree helps us to test GPT's capabilities in modeling information in a hierarchy. It seems to me that our brains organize information in a similar way (citation needed). We can use this design to test how GPT can use its own hierarchy to answer questions.\n\nPractically speaking, it is much cheaper to do so and I want to limit my monthly spending (see below for costs).\n\n**How much does this cost to run?**\n\nWe currently use the Davinci model for good results. Unfortunately Davinci is quite expensive. The cost of building the tree is roughly\n$cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens ($0.02 as mentioned on the pricing page). The cost of querying the tree is roughly \n$c\\log(N)\\frac{p}{1000}$.\n\nFor the NYC example, this equates to \\$~0.40 per query.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/README.md", "file_name": "gpt_index/indices/tree/README.md"}, "index": 2, "child_indices": [], "ref_doc_id": "aa53c642b9c9f3e8695dcbe11ea3a6a33628a1fd", "node_info": null}, "3": {"text": "\"\"\"Tree-structured Index Data Structures.\"\"\"\n\n# indices\nfrom gpt_index.indices.tree.base import GPTTreeIndex\n\n__all__ = [\n    \"GPTTreeIndex\",\n]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/__init__.py", "file_name": "__init__.py"}, "index": 3, "child_indices": [], "ref_doc_id": "c13b792b07486dc27964e134193fcbfbe2b877a5", "node_info": null}, "4": {"text": "\"\"\"Tree-based index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import IndexGraph\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.common.tree.base import GPTTreeIndexBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.query.tree.leaf_query import GPTTreeIndexLeafQuery\nfrom gpt_index.indices.query.tree.retrieve_query import GPTTreeIndexRetQuery\nfrom gpt_index.indices.query.tree.summarize_query import GPTTreeIndexSummarizeQuery\nfrom gpt_index.indices.tree.inserter import GPTIndexInserter\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "5": {"text": "import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.prompts.prompts import SummaryPrompt, TreeInsertPrompt\nfrom gpt_index.schema import BaseDocument\n\nREQUIRE_TREE_MODES = {\n    QueryMode.DEFAULT,\n    QueryMode.EMBEDDING,\n    QueryMode.RETRIEVE,\n}\n\n\nclass GPTTreeIndex(BaseGPTIndex[IndexGraph]):\n    \"\"\"GPT Tree Index.\n\n    The tree index is a tree-structured index, where each node is a summary of\n    the children nodes. During index construction, the tree is constructed\n    in a bottoms-up fashion until we end up with a set of root_nodes.\n\n    There are a few different options during query time (see :ref:`Ref-Query`).\n    The main option is to traverse down the tree from the root nodes.\n    A secondary answer is to directly", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "6": {"text": "the root nodes.\n    A secondary answer is to directly synthesize the answer from the root nodes.\n\n    Args:\n        summary_template (Optional[SummaryPrompt]): A Summarization Prompt\n            (see :ref:`Prompt-Templates`).\n        insert_prompt (Optional[TreeInsertPrompt]): An Tree Insertion Prompt\n            (see :ref:`Prompt-Templates`).\n        num_children (int): The number of children each node should have.\n        build_tree (bool): Whether to build the tree during index construction.\n\n    \"\"\"\n\n    index_struct_cls = IndexGraph\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[IndexGraph] = None,\n        summary_template: Optional[SummaryPrompt] =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "7": {"text": "     summary_template: Optional[SummaryPrompt] = None,\n        insert_prompt: Optional[TreeInsertPrompt] = None,\n        num_children: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        build_tree: bool = True,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.num_children = num_children\n        self.summary_template = summary_template or DEFAULT_SUMMARY_PROMPT\n        self.insert_prompt: TreeInsertPrompt = insert_prompt or DEFAULT_INSERT_PROMPT\n        self.build_tree = build_tree\n        super().__init__(\n            documents=documents,\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "8": {"text": "       documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTTreeIndexLeafQuery,\n            QueryMode.EMBEDDING: GPTTreeIndexEmbeddingQuery,\n            QueryMode.RETRIEVE: GPTTreeIndexRetQuery,\n            QueryMode.SUMMARIZE: GPTTreeIndexSummarizeQuery,\n        }\n\n    def _validate_build_tree_required(self, mode: QueryMode) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "9": {"text": "mode: QueryMode) -> None:\n        \"\"\"Check if index supports modes that require trees.\"\"\"\n        if mode in REQUIRE_TREE_MODES and not self.build_tree:\n            raise ValueError(\n                \"Index was constructed without building trees, \"\n                f\"but mode {mode} requires trees.\"\n            )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        self._validate_build_tree_required(mode)\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> IndexGraph:\n        \"\"\"Build the index from", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "10": {"text": "IndexGraph:\n        \"\"\"Build the index from documents.\"\"\"\n        # do simple concatenation\n        index_builder = GPTTreeIndexBuilder(\n            self.num_children,\n            self.summary_template,\n            self._llm_predictor,\n            self._prompt_helper,\n        )\n        index_graph = index_builder.build_from_text(\n            documents, build_tree=self.build_tree\n        )\n        return index_graph\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        # TODO: allow to customize insert prompt\n        inserter = GPTIndexInserter(\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "11": {"text": "   inserter = GPTIndexInserter(\n            self.index_struct,\n            num_children=self.num_children,\n            insert_prompt=self.insert_prompt,\n            summary_prompt=self.summary_template,\n            llm_predictor=self._llm_predictor,\n            prompt_helper=self._prompt_helper,\n        )\n        inserter.insert(document)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not implemented for tree index.\")\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/base.py", "file_name": "base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e627d6f084fdbaefa7f0a5c7d67f5efba7ae8b39", "node_info": null}, "12": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 12, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "13": {"text": "    prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 13, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "14": {"text": "       self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 14, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "15": {"text": "           ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 15, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "16": {"text": "           # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n            summary1, _ = self._llm_predictor.predict(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 16, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "17": {"text": "_ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n             ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 17, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "18": {"text": "               self.summary_prompt, context_str=text_chunk2\n            )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 18, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "19": {"text": "               self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 19, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "20": {"text": "== 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 20, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "21": {"text": "               self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 21, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "22": {"text": "> len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 22, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "23": {"text": "           cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 23, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "24": {"text": "       for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 24, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "25": {"text": "The GPTTreeIndex is a tree-structured index that organizes external data into a tree structure that can be queried. It is built in a bottom-up fashion, with each parent node summarizing the children nodes using a general summarization prompt. There are two query modes: Default (GPTTreeIndexLeafQuery) and Retrieve (GPTTreeIndexRetQuery). The cost of building the tree is roughly $cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens. The GPTTreeIndex class takes in a set of text documents as input, and can be saved to disk as a JSON and loaded for future use.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file is for the GPT Tree Index inserter. It contains a class GPTIndexInserter which initializes with parameters such as index_graph, llm_predictor, prompt_helper, num_children, insert_prompt, and summary_prompt. It contains methods such as _insert_under_parent_and_consolidate, _insert_node, and insert. The _insert_under_parent_and_consolidate method inserts a node under a parent node and consolidates by dividing up child nodes and creating a new intermediate layer of nodes. The _insert_node method tries to find the right summary node to insert under and the insert method inserts into the index_graph.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "inserter.py is a file located in the gpt_index/indices/tree directory. It contains a function that takes in a list of text chunks and a document, and inserts each text chunk into the document as a node. This allows for the efficient storage and retrieval of text chunks in the document.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"25": {"text": "The GPTTreeIndex is a tree-structured index that organizes external data into a tree structure that can be queried. It is built in a bottom-up fashion, with each parent node summarizing the children nodes using a general summarization prompt. There are two query modes: Default (GPTTreeIndexLeafQuery) and Retrieve (GPTTreeIndexRetQuery). The cost of building the tree is roughly $cN\\log(N)\\frac{p}{1000}$, where $p=4096$ is the prompt limit and $c$ is the cost per 1000 tokens. The GPTTreeIndex class takes in a set of text documents as input, and can be saved to disk as a JSON and loaded for future use.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file is for the GPT Tree Index inserter. It contains a class GPTIndexInserter which initializes with parameters such as index_graph, llm_predictor, prompt_helper, num_children, insert_prompt, and summary_prompt. It contains methods such as _insert_under_parent_and_consolidate, _insert_node, and insert. The _insert_under_parent_and_consolidate method inserts a node under a parent node and consolidates by dividing up child nodes and creating a new intermediate layer of nodes. The _insert_node method tries to find the right summary node to insert under and the insert method inserts into the index_graph.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "inserter.py is a file located in the gpt_index/indices/tree directory. It contains a function that takes in a list of text chunks and a document, and inserts each text chunk into the document as a node. This allows for the efficient storage and retrieval of text chunks in the document.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}