{"index_struct": {"text": "\nSUMMARY: These documents contain classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables which are used to generate the prompt.", "doc_id": "a7ba7f31-862d-4209-804f-d29c6fb53ab4", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Prompt class.\"\"\"\n\nfrom gpt_index.prompts.base import Prompt\n\n__all__ = [\"Prompt\"]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "70a9a06c14c38bb373b8afc1d1e6b4b7febf726e", "node_info": null}, "1": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "2": {"text": "   ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "3": {"text": "           f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n            ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "4": {"text": "should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "5": {"text": "prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "6": {"text": "       return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "7": {"text": "         format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "8": {"text": "Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "9": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 9, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "10": {"text": "\"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 10, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "11": {"text": "= TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 11, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "12": {"text": "= (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 12, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "13": {"text": "= (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 13, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "14": {"text": "and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 14, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "15": {"text": "the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 15, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "16": {"text": "= (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n#", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 16, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "17": {"text": "NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 17, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "18": {"text": "table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 18, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "19": {"text": "= TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 19, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "20": {"text": "= RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 20, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "21": {"text": "\"\"\"Prompt types enum.\"\"\"\n\nfrom enum import Enum\n\n\nclass PromptType(str, Enum):\n    \"\"\"Prompt type.\"\"\"\n\n    # summarization\n    SUMMARY = \"summary\"\n    # tree insert node\n    TREE_INSERT = \"insert\"\n    # tree select query prompt\n    TREE_SELECT = \"tree_select\"\n    # tree select query prompt (multiple)\n    TREE_SELECT_MULTIPLE = \"tree_select_multiple\"\n    # question-answer\n    QUESTION_ANSWER = \"text_qa\"\n    # refine\n    REFINE = \"refine\"\n    # keyword extract\n    KEYWORD_EXTRACT = \"keyword_extract\"\n    # query keyword extract\n    QUERY_KEYWORD_EXTRACT = \"query_keyword_extract\"\n\n    # schema extract\n    SCHEMA_EXTRACT = \"schema_extract\"\n\n    # text to sql\n    TEXT_TO_SQL", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompt_type.py", "file_name": "prompt_type.py"}, "index": 21, "child_indices": [], "ref_doc_id": "6733ae7741e49b480a7fa692ec545ff3edec1a13", "node_info": null}, "22": {"text": "   # text to sql\n    TEXT_TO_SQL = \"text_to_sql\"\n\n    # table context\n    TABLE_CONTEXT = \"table_context\"\n\n    # custom (by default)\n    CUSTOM = \"custom\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompt_type.py", "file_name": "prompt_type.py"}, "index": 22, "child_indices": [], "ref_doc_id": "6733ae7741e49b480a7fa692ec545ff3edec1a13", "node_info": null}, "23": {"text": "\"\"\"Subclasses from base prompt.\"\"\"\nfrom typing import List\n\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.prompt_type import PromptType\n\n\nclass SummaryPrompt(Prompt):\n    \"\"\"Summary prompt.\n\n    Prompt to summarize the provided `context_str`.\n\n    Required template variables: `context_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SUMMARY\n    input_variables: List[str] = [\"context_str\"]\n\n\nclass TreeInsertPrompt(Prompt):\n    \"\"\"Tree Insert prompt.\n\n    Prompt to insert a new chunk of text `new_chunk_text` into the tree index.\n    More specifically, this prompt has the LLM select the relevant candidate\n    child node to continue tree traversal.\n\n    Required template variables:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 23, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "24": {"text": "to continue tree traversal.\n\n    Required template variables: `num_chunks`, `context_list`, `new_chunk_text`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_INSERT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"new_chunk_text\"]\n\n\nclass TreeSelectPrompt(Prompt):\n    \"\"\"Tree select prompt.\n\n    Prompt to select a candidate child node out of all child nodes\n    provided in `context_list`, given a query `query_str`. `num_chunks` is\n    the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 24, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "25": {"text": "Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_SELECT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"query_str\"]\n\n\nclass TreeSelectMultiplePrompt(Prompt):\n    \"\"\"Tree select multiple prompt.\n\n    Prompt to select multiple candidate child nodes out of all\n    child nodes provided in `context_list`, given a query `query_str`.\n    `branching_factor` refers to the number of child nodes to select, and\n    `num_chunks` is the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`,\n        `branching_factor`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 25, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "26": {"text": "Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type = PromptType.TREE_SELECT_MULTIPLE\n    input_variables: List[str] = [\n        \"num_chunks\",\n        \"context_list\",\n        \"query_str\",\n        \"branching_factor\",\n    ]\n\n\nclass RefinePrompt(Prompt):\n    \"\"\"Refine prompt.\n\n    Prompt to refine an existing answer `existing_answer` given a context `context_msg`,\n    and a query `query_str`.\n\n    Required template variables: `query_str`, `existing_answer`, `context_msg`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.REFINE\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 26, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "27": {"text": "PromptType = PromptType.REFINE\n    input_variables: List[str] = [\"query_str\", \"existing_answer\", \"context_msg\"]\n\n\nclass QuestionAnswerPrompt(Prompt):\n    \"\"\"Question Answer prompt.\n\n    Prompt to answer a question `query_str` given a context `context_str`.\n\n    Required template variables: `context_str`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUESTION_ANSWER\n    input_variables: List[str] = [\"context_str\", \"query_str\"]\n\n\nclass KeywordExtractPrompt(Prompt):\n    \"\"\"Keyword extract prompt.\n\n    Prompt to extract keywords from a text `text` with a maximum of\n    `max_keywords` keywords.\n\n    Required template variables: `text`, `max_keywords`\n\n    Args:\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 27, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "28": {"text": "`max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.KEYWORD_EXTRACT\n    input_variables: List[str] = [\"text\", \"max_keywords\"]\n\n\nclass QueryKeywordExtractPrompt(Prompt):\n    \"\"\"Query keyword extract prompt.\n\n    Prompt to extract keywords from a query `query_str` with a maximum\n    of `max_keywords` keywords.\n\n    Required template variables: `query_str`, `max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUERY_KEYWORD_EXTRACT\n    input_variables: List[str] = [\"question\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 28, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "29": {"text": "   input_variables: List[str] = [\"question\", \"max_keywords\"]\n\n\nclass SchemaExtractPrompt(Prompt):\n    \"\"\"Schema extract prompt.\n\n    Prompt to extract schema from unstructured text `text`.\n\n    Required template variables: `text`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SCHEMA_EXTRACT\n    input_variables: List[str] = [\"text\", \"schema\"]\n\n\nclass TextToSQLPrompt(Prompt):\n    \"\"\"Text to SQL prompt.\n\n    Prompt to translate a natural language query into SQL,\n    given a schema `schema`.\n\n    Required template variables: `query_str`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 29, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "30": {"text": "Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TEXT_TO_SQL\n    input_variables: List[str] = [\"query_str\", \"schema\"]\n\n\nclass TableContextPrompt(Prompt):\n    \"\"\"Table context prompt.\n\n    Prompt to generate a table context given a table schema `schema`,\n    as well as unstructured text context `context_str`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\"schema\", \"context_str\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 30, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "31": {"text": "List[str] = [\"schema\", \"context_str\", \"query_str\"]\n\n\nclass RefineTableContextPrompt(Prompt):\n    \"\"\"Refine Table context prompt.\n\n    Prompt to refine a table context given a table schema `schema`,\n    as well as unstructured text context `context_msg`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\n        \"schema\",\n        \"context_msg\",\n        \"query_str\",\n        \"existing_answer\",\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 31, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "32": {"text": "       \"existing_answer\",\n    ]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 32, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "33": {"text": "\nThis code file contains the Prompt class, which is a wrapper around langchain's prompt class. It adds the ability to enforce certain prompt types and partially fill values. It also contains a set of default prompts, such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, and TreeSelectMultiplePrompt. These prompts are used to generate templates for summarizing, inserting, selecting, and selecting multiple pieces of information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 33, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "34": {"text": "This code file contains a set of default prompts for use in a GPT-based index. It includes prompts for summarization, tree insert node, tree select query, tree select query (multiple), question-answer, refine, keyword extract, query keyword extract, schema extract, text to SQL, table context, and custom. Each prompt contains a template with variables such as context_str, query_str, schema, context_msg, existing_answer, and more. The purpose of these prompts is to provide a set of default prompts for use in a GPT-based index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 34, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "35": {"text": "prompts.py is a Python file containing classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables. The input variables are specific to each prompt type and are used to generate the prompt.", "doc_id": null, "embedding": null, "extra_info": null, "index": 35, "child_indices": [32, 24, 25, 26, 27, 28, 29, 30, 31], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"33": {"text": "\nThis code file contains the Prompt class, which is a wrapper around langchain's prompt class. It adds the ability to enforce certain prompt types and partially fill values. It also contains a set of default prompts, such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, and TreeSelectMultiplePrompt. These prompts are used to generate templates for summarizing, inserting, selecting, and selecting multiple pieces of information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 33, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "34": {"text": "This code file contains a set of default prompts for use in a GPT-based index. It includes prompts for summarization, tree insert node, tree select query, tree select query (multiple), question-answer, refine, keyword extract, query keyword extract, schema extract, text to SQL, table context, and custom. Each prompt contains a template with variables such as context_str, query_str, schema, context_msg, existing_answer, and more. The purpose of these prompts is to provide a set of default prompts for use in a GPT-based index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 34, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "35": {"text": "prompts.py is a Python file containing classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables. The input variables are specific to each prompt type and are used to generate the prompt.", "doc_id": null, "embedding": null, "extra_info": null, "index": 35, "child_indices": [32, 24, 25, 26, 27, 28, 29, 30, 31], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"70a9a06c14c38bb373b8afc1d1e6b4b7febf726e": {"text": "\"\"\"Prompt class.\"\"\"\n\nfrom gpt_index.prompts.base import Prompt\n\n__all__ = [\"Prompt\"]\n", "doc_id": "70a9a06c14c38bb373b8afc1d1e6b4b7febf726e", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "7d31d14e71a85ec7b6245e0d2ffd714cce527961": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n        return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "__type__": "Document"}, "67d318229cee08ef396c5183c85a937be9a1a2db": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT = TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n# NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT = TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "__type__": "Document"}, "6733ae7741e49b480a7fa692ec545ff3edec1a13": {"text": "\"\"\"Prompt types enum.\"\"\"\n\nfrom enum import Enum\n\n\nclass PromptType(str, Enum):\n    \"\"\"Prompt type.\"\"\"\n\n    # summarization\n    SUMMARY = \"summary\"\n    # tree insert node\n    TREE_INSERT = \"insert\"\n    # tree select query prompt\n    TREE_SELECT = \"tree_select\"\n    # tree select query prompt (multiple)\n    TREE_SELECT_MULTIPLE = \"tree_select_multiple\"\n    # question-answer\n    QUESTION_ANSWER = \"text_qa\"\n    # refine\n    REFINE = \"refine\"\n    # keyword extract\n    KEYWORD_EXTRACT = \"keyword_extract\"\n    # query keyword extract\n    QUERY_KEYWORD_EXTRACT = \"query_keyword_extract\"\n\n    # schema extract\n    SCHEMA_EXTRACT = \"schema_extract\"\n\n    # text to sql\n    TEXT_TO_SQL = \"text_to_sql\"\n\n    # table context\n    TABLE_CONTEXT = \"table_context\"\n\n    # custom (by default)\n    CUSTOM = \"custom\"\n", "doc_id": "6733ae7741e49b480a7fa692ec545ff3edec1a13", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompt_type.py", "file_name": "prompt_type.py"}, "__type__": "Document"}, "583437e9d61e15269b7b59a5121fa41dedd096c3": {"text": "\"\"\"Subclasses from base prompt.\"\"\"\nfrom typing import List\n\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.prompt_type import PromptType\n\n\nclass SummaryPrompt(Prompt):\n    \"\"\"Summary prompt.\n\n    Prompt to summarize the provided `context_str`.\n\n    Required template variables: `context_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SUMMARY\n    input_variables: List[str] = [\"context_str\"]\n\n\nclass TreeInsertPrompt(Prompt):\n    \"\"\"Tree Insert prompt.\n\n    Prompt to insert a new chunk of text `new_chunk_text` into the tree index.\n    More specifically, this prompt has the LLM select the relevant candidate\n    child node to continue tree traversal.\n\n    Required template variables: `num_chunks`, `context_list`, `new_chunk_text`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_INSERT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"new_chunk_text\"]\n\n\nclass TreeSelectPrompt(Prompt):\n    \"\"\"Tree select prompt.\n\n    Prompt to select a candidate child node out of all child nodes\n    provided in `context_list`, given a query `query_str`. `num_chunks` is\n    the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_SELECT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"query_str\"]\n\n\nclass TreeSelectMultiplePrompt(Prompt):\n    \"\"\"Tree select multiple prompt.\n\n    Prompt to select multiple candidate child nodes out of all\n    child nodes provided in `context_list`, given a query `query_str`.\n    `branching_factor` refers to the number of child nodes to select, and\n    `num_chunks` is the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`,\n        `branching_factor`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type = PromptType.TREE_SELECT_MULTIPLE\n    input_variables: List[str] = [\n        \"num_chunks\",\n        \"context_list\",\n        \"query_str\",\n        \"branching_factor\",\n    ]\n\n\nclass RefinePrompt(Prompt):\n    \"\"\"Refine prompt.\n\n    Prompt to refine an existing answer `existing_answer` given a context `context_msg`,\n    and a query `query_str`.\n\n    Required template variables: `query_str`, `existing_answer`, `context_msg`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.REFINE\n    input_variables: List[str] = [\"query_str\", \"existing_answer\", \"context_msg\"]\n\n\nclass QuestionAnswerPrompt(Prompt):\n    \"\"\"Question Answer prompt.\n\n    Prompt to answer a question `query_str` given a context `context_str`.\n\n    Required template variables: `context_str`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUESTION_ANSWER\n    input_variables: List[str] = [\"context_str\", \"query_str\"]\n\n\nclass KeywordExtractPrompt(Prompt):\n    \"\"\"Keyword extract prompt.\n\n    Prompt to extract keywords from a text `text` with a maximum of\n    `max_keywords` keywords.\n\n    Required template variables: `text`, `max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.KEYWORD_EXTRACT\n    input_variables: List[str] = [\"text\", \"max_keywords\"]\n\n\nclass QueryKeywordExtractPrompt(Prompt):\n    \"\"\"Query keyword extract prompt.\n\n    Prompt to extract keywords from a query `query_str` with a maximum\n    of `max_keywords` keywords.\n\n    Required template variables: `query_str`, `max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUERY_KEYWORD_EXTRACT\n    input_variables: List[str] = [\"question\", \"max_keywords\"]\n\n\nclass SchemaExtractPrompt(Prompt):\n    \"\"\"Schema extract prompt.\n\n    Prompt to extract schema from unstructured text `text`.\n\n    Required template variables: `text`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SCHEMA_EXTRACT\n    input_variables: List[str] = [\"text\", \"schema\"]\n\n\nclass TextToSQLPrompt(Prompt):\n    \"\"\"Text to SQL prompt.\n\n    Prompt to translate a natural language query into SQL,\n    given a schema `schema`.\n\n    Required template variables: `query_str`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TEXT_TO_SQL\n    input_variables: List[str] = [\"query_str\", \"schema\"]\n\n\nclass TableContextPrompt(Prompt):\n    \"\"\"Table context prompt.\n\n    Prompt to generate a table context given a table schema `schema`,\n    as well as unstructured text context `context_str`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\"schema\", \"context_str\", \"query_str\"]\n\n\nclass RefineTableContextPrompt(Prompt):\n    \"\"\"Refine Table context prompt.\n\n    Prompt to refine a table context given a table schema `schema`,\n    as well as unstructured text context `context_msg`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\n        \"schema\",\n        \"context_msg\",\n        \"query_str\",\n        \"existing_answer\",\n    ]\n", "doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "__type__": "Document"}, "a7ba7f31-862d-4209-804f-d29c6fb53ab4": {"text": "\nSUMMARY: These documents contain classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables which are used to generate the prompt.", "doc_id": "a7ba7f31-862d-4209-804f-d29c6fb53ab4", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Prompt class.\"\"\"\n\nfrom gpt_index.prompts.base import Prompt\n\n__all__ = [\"Prompt\"]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "70a9a06c14c38bb373b8afc1d1e6b4b7febf726e", "node_info": null}, "1": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "2": {"text": "   ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "3": {"text": "           f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n            ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "4": {"text": "should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "5": {"text": "prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "6": {"text": "       return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "7": {"text": "         format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "8": {"text": "Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "9": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 9, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "10": {"text": "\"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 10, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "11": {"text": "= TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 11, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "12": {"text": "= (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 12, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "13": {"text": "= (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 13, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "14": {"text": "and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 14, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "15": {"text": "the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 15, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "16": {"text": "= (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n#", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 16, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "17": {"text": "NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 17, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "18": {"text": "table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 18, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "19": {"text": "= TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 19, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "20": {"text": "= RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 20, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "21": {"text": "\"\"\"Prompt types enum.\"\"\"\n\nfrom enum import Enum\n\n\nclass PromptType(str, Enum):\n    \"\"\"Prompt type.\"\"\"\n\n    # summarization\n    SUMMARY = \"summary\"\n    # tree insert node\n    TREE_INSERT = \"insert\"\n    # tree select query prompt\n    TREE_SELECT = \"tree_select\"\n    # tree select query prompt (multiple)\n    TREE_SELECT_MULTIPLE = \"tree_select_multiple\"\n    # question-answer\n    QUESTION_ANSWER = \"text_qa\"\n    # refine\n    REFINE = \"refine\"\n    # keyword extract\n    KEYWORD_EXTRACT = \"keyword_extract\"\n    # query keyword extract\n    QUERY_KEYWORD_EXTRACT = \"query_keyword_extract\"\n\n    # schema extract\n    SCHEMA_EXTRACT = \"schema_extract\"\n\n    # text to sql\n    TEXT_TO_SQL", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompt_type.py", "file_name": "prompt_type.py"}, "index": 21, "child_indices": [], "ref_doc_id": "6733ae7741e49b480a7fa692ec545ff3edec1a13", "node_info": null}, "22": {"text": "   # text to sql\n    TEXT_TO_SQL = \"text_to_sql\"\n\n    # table context\n    TABLE_CONTEXT = \"table_context\"\n\n    # custom (by default)\n    CUSTOM = \"custom\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompt_type.py", "file_name": "prompt_type.py"}, "index": 22, "child_indices": [], "ref_doc_id": "6733ae7741e49b480a7fa692ec545ff3edec1a13", "node_info": null}, "23": {"text": "\"\"\"Subclasses from base prompt.\"\"\"\nfrom typing import List\n\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.prompt_type import PromptType\n\n\nclass SummaryPrompt(Prompt):\n    \"\"\"Summary prompt.\n\n    Prompt to summarize the provided `context_str`.\n\n    Required template variables: `context_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SUMMARY\n    input_variables: List[str] = [\"context_str\"]\n\n\nclass TreeInsertPrompt(Prompt):\n    \"\"\"Tree Insert prompt.\n\n    Prompt to insert a new chunk of text `new_chunk_text` into the tree index.\n    More specifically, this prompt has the LLM select the relevant candidate\n    child node to continue tree traversal.\n\n    Required template variables:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 23, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "24": {"text": "to continue tree traversal.\n\n    Required template variables: `num_chunks`, `context_list`, `new_chunk_text`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_INSERT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"new_chunk_text\"]\n\n\nclass TreeSelectPrompt(Prompt):\n    \"\"\"Tree select prompt.\n\n    Prompt to select a candidate child node out of all child nodes\n    provided in `context_list`, given a query `query_str`. `num_chunks` is\n    the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 24, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "25": {"text": "Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TREE_SELECT\n    input_variables: List[str] = [\"num_chunks\", \"context_list\", \"query_str\"]\n\n\nclass TreeSelectMultiplePrompt(Prompt):\n    \"\"\"Tree select multiple prompt.\n\n    Prompt to select multiple candidate child nodes out of all\n    child nodes provided in `context_list`, given a query `query_str`.\n    `branching_factor` refers to the number of child nodes to select, and\n    `num_chunks` is the number of child nodes in `context_list`.\n\n    Required template variables: `num_chunks`, `context_list`, `query_str`,\n        `branching_factor`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 25, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "26": {"text": "Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type = PromptType.TREE_SELECT_MULTIPLE\n    input_variables: List[str] = [\n        \"num_chunks\",\n        \"context_list\",\n        \"query_str\",\n        \"branching_factor\",\n    ]\n\n\nclass RefinePrompt(Prompt):\n    \"\"\"Refine prompt.\n\n    Prompt to refine an existing answer `existing_answer` given a context `context_msg`,\n    and a query `query_str`.\n\n    Required template variables: `query_str`, `existing_answer`, `context_msg`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.REFINE\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 26, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "27": {"text": "PromptType = PromptType.REFINE\n    input_variables: List[str] = [\"query_str\", \"existing_answer\", \"context_msg\"]\n\n\nclass QuestionAnswerPrompt(Prompt):\n    \"\"\"Question Answer prompt.\n\n    Prompt to answer a question `query_str` given a context `context_str`.\n\n    Required template variables: `context_str`, `query_str`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUESTION_ANSWER\n    input_variables: List[str] = [\"context_str\", \"query_str\"]\n\n\nclass KeywordExtractPrompt(Prompt):\n    \"\"\"Keyword extract prompt.\n\n    Prompt to extract keywords from a text `text` with a maximum of\n    `max_keywords` keywords.\n\n    Required template variables: `text`, `max_keywords`\n\n    Args:\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 27, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "28": {"text": "`max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.KEYWORD_EXTRACT\n    input_variables: List[str] = [\"text\", \"max_keywords\"]\n\n\nclass QueryKeywordExtractPrompt(Prompt):\n    \"\"\"Query keyword extract prompt.\n\n    Prompt to extract keywords from a query `query_str` with a maximum\n    of `max_keywords` keywords.\n\n    Required template variables: `query_str`, `max_keywords`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.QUERY_KEYWORD_EXTRACT\n    input_variables: List[str] = [\"question\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 28, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "29": {"text": "   input_variables: List[str] = [\"question\", \"max_keywords\"]\n\n\nclass SchemaExtractPrompt(Prompt):\n    \"\"\"Schema extract prompt.\n\n    Prompt to extract schema from unstructured text `text`.\n\n    Required template variables: `text`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.SCHEMA_EXTRACT\n    input_variables: List[str] = [\"text\", \"schema\"]\n\n\nclass TextToSQLPrompt(Prompt):\n    \"\"\"Text to SQL prompt.\n\n    Prompt to translate a natural language query into SQL,\n    given a schema `schema`.\n\n    Required template variables: `query_str`, `schema`\n\n    Args:\n        template (str): Template for the prompt.\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 29, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "30": {"text": "Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TEXT_TO_SQL\n    input_variables: List[str] = [\"query_str\", \"schema\"]\n\n\nclass TableContextPrompt(Prompt):\n    \"\"\"Table context prompt.\n\n    Prompt to generate a table context given a table schema `schema`,\n    as well as unstructured text context `context_str`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\"schema\", \"context_str\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 30, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "31": {"text": "List[str] = [\"schema\", \"context_str\", \"query_str\"]\n\n\nclass RefineTableContextPrompt(Prompt):\n    \"\"\"Refine Table context prompt.\n\n    Prompt to refine a table context given a table schema `schema`,\n    as well as unstructured text context `context_msg`, and\n    a task `query_str`.\n    This includes both a high-level description of the table\n    as well as a description of each column in the table.\n\n    Args:\n        template (str): Template for the prompt.\n        **prompt_kwargs: Keyword arguments for the prompt.\n\n    \"\"\"\n\n    # TODO: rename context_msg to context_str\n\n    prompt_type: PromptType = PromptType.TABLE_CONTEXT\n    input_variables: List[str] = [\n        \"schema\",\n        \"context_msg\",\n        \"query_str\",\n        \"existing_answer\",\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 31, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "32": {"text": "       \"existing_answer\",\n    ]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/prompts.py", "file_name": "prompts.py"}, "index": 32, "child_indices": [], "ref_doc_id": "583437e9d61e15269b7b59a5121fa41dedd096c3", "node_info": null}, "33": {"text": "\nThis code file contains the Prompt class, which is a wrapper around langchain's prompt class. It adds the ability to enforce certain prompt types and partially fill values. It also contains a set of default prompts, such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, and TreeSelectMultiplePrompt. These prompts are used to generate templates for summarizing, inserting, selecting, and selecting multiple pieces of information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 33, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "34": {"text": "This code file contains a set of default prompts for use in a GPT-based index. It includes prompts for summarization, tree insert node, tree select query, tree select query (multiple), question-answer, refine, keyword extract, query keyword extract, schema extract, text to SQL, table context, and custom. Each prompt contains a template with variables such as context_str, query_str, schema, context_msg, existing_answer, and more. The purpose of these prompts is to provide a set of default prompts for use in a GPT-based index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 34, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "35": {"text": "prompts.py is a Python file containing classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables. The input variables are specific to each prompt type and are used to generate the prompt.", "doc_id": null, "embedding": null, "extra_info": null, "index": 35, "child_indices": [32, 24, 25, 26, 27, 28, 29, 30, 31], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"33": {"text": "\nThis code file contains the Prompt class, which is a wrapper around langchain's prompt class. It adds the ability to enforce certain prompt types and partially fill values. It also contains a set of default prompts, such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, and TreeSelectMultiplePrompt. These prompts are used to generate templates for summarizing, inserting, selecting, and selecting multiple pieces of information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 33, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "34": {"text": "This code file contains a set of default prompts for use in a GPT-based index. It includes prompts for summarization, tree insert node, tree select query, tree select query (multiple), question-answer, refine, keyword extract, query keyword extract, schema extract, text to SQL, table context, and custom. Each prompt contains a template with variables such as context_str, query_str, schema, context_msg, existing_answer, and more. The purpose of these prompts is to provide a set of default prompts for use in a GPT-based index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 34, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "35": {"text": "prompts.py is a Python file containing classes for various types of prompts used in GPT-Index. These prompts include TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, RefinePrompt, QuestionAnswerPrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, SchemaExtractPrompt, TextToSQLPrompt, TableContextPrompt, and RefineTableContextPrompt. Each prompt class contains a prompt type, template, and input variables. The input variables are specific to each prompt type and are used to generate the prompt.", "doc_id": null, "embedding": null, "extra_info": null, "index": 35, "child_indices": [32, 24, 25, 26, 27, 28, 29, 30, 31], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}