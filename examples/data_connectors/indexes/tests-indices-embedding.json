{"index_struct": {"text": "\nThe summaries of these documents are not provided.", "doc_id": "860ea69f-e687-43f1-a96b-9e168c74ad3d", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test embedding functionalities.\"\"\"\n\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmchain_predict\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_QUERY_PROMPT,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "2": {"text": "  MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef test_embedding_similarity() -> None:\n    \"\"\"Test embedding similarity.\"\"\"\n    embed_model = OpenAIEmbedding()\n    text_embedding = [3.0, 4.0, 0.0]\n    query_embedding = [0.0, 1.0, 0.0]\n    cosine = embed_model.similarity(query_embedding, text_embedding)\n    assert cosine == 0.8\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"summary_template\": MOCK_SUMMARY_PROMPT,\n        \"insert_prompt\": MOCK_INSERT_PROMPT,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "3": {"text": "       \"num_children\": 2,\n    }\n    query_kwargs = {\n        \"query_template\": MOCK_QUERY_PROMPT,\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\ndef _get_node_text_embedding_similarities(\n    query_embedding: List[float], nodes:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "4": {"text": "   query_embedding: List[float], nodes: List[Node]\n) -> List[float]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_similarity_map = defaultdict(lambda: 0.0)\n    text_similarity_map[\"Hello world.\"] = 0.9\n    text_similarity_map[\"This is a test.\"] = 0.8\n    text_similarity_map[\"This is another test.\"] = 0.7\n    text_similarity_map[\"This is a test v2.\"] = 0.6\n\n    similarities = []\n    for node in nodes:\n        similarities.append(text_similarity_map[node.get_text()])\n\n    return similarities\n\n\n@patch_common\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "5": {"text": "   _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    tree = GPTTreeIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = tree.query(query_str, mode=\"embedding\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch.object(LLMChain, \"predict\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "6": {"text": "\"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_query_and_count_tokens(\n    _mock_similarity: Any,\n    _mock_llmchain: Any,\n    _mock_llm_metadata: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query and count tokens.\"\"\"\n    index_kwargs, query_kwargs", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "7": {"text": "   index_kwargs, query_kwargs = struct_kwargs\n    # mock_prompts.MOCK_SUMMARY_PROMPT_TMPL adds a \"\\n\" to the document text\n    document_token_count = 24\n    llmchain_mock_resp_token_count = 10\n    # build the tree\n    tree = GPTTreeIndex(documents, **index_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used\n        == document_token_count + llmchain_mock_resp_token_count\n    )\n\n    # test embedding query\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    query_str = \"What is?\"\n    # From MOCK_TEXT_QA_PROMPT, the prompt is 28 total\n    query_prompt_token_count = 28\n    tree.query(query_str, mode=\"embedding\", **query_kwargs)\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "8": {"text": "mode=\"embedding\", **query_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used - start_token_ct\n        == query_prompt_token_count + llmchain_mock_resp_token_count\n    )\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "9": {"text": "This code file tests the embedding functionalities of the GPTTreeIndex class. It tests the embedding similarity, query, and token count. It uses fixtures such as documents, index_kwargs, and query_kwargs to set up the tests. It also uses patching to mock the LLMChain, OpenAI, LLMPredictor, and GPTTreeIndexEmbeddingQuery classes. The tests check the similarity between two embeddings, the query response, and the token count.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file tests the embedding functionalities of the GPTTreeIndex class. It tests the embedding similarity, query, and token count. It uses fixtures such as documents, index_kwargs, and query_kwargs to set up the tests. It also uses patching to mock the LLMChain, OpenAI, LLMPredictor, and GPTTreeIndexEmbeddingQuery classes. The tests check the similarity between two embeddings, the query response, and the token count.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"1d4640565ae2765d9ca96a509dc9809217f62f2f": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "6aea22e046e0a392ed78df85b9cb73e44e66fbbb": {"text": "\"\"\"Test embedding functionalities.\"\"\"\n\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmchain_predict\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef test_embedding_similarity() -> None:\n    \"\"\"Test embedding similarity.\"\"\"\n    embed_model = OpenAIEmbedding()\n    text_embedding = [3.0, 4.0, 0.0]\n    query_embedding = [0.0, 1.0, 0.0]\n    cosine = embed_model.similarity(query_embedding, text_embedding)\n    assert cosine == 0.8\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"summary_template\": MOCK_SUMMARY_PROMPT,\n        \"insert_prompt\": MOCK_INSERT_PROMPT,\n        \"num_children\": 2,\n    }\n    query_kwargs = {\n        \"query_template\": MOCK_QUERY_PROMPT,\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\ndef _get_node_text_embedding_similarities(\n    query_embedding: List[float], nodes: List[Node]\n) -> List[float]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_similarity_map = defaultdict(lambda: 0.0)\n    text_similarity_map[\"Hello world.\"] = 0.9\n    text_similarity_map[\"This is a test.\"] = 0.8\n    text_similarity_map[\"This is another test.\"] = 0.7\n    text_similarity_map[\"This is a test v2.\"] = 0.6\n\n    similarities = []\n    for node in nodes:\n        similarities.append(text_similarity_map[node.get_text()])\n\n    return similarities\n\n\n@patch_common\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    tree = GPTTreeIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = tree.query(query_str, mode=\"embedding\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_query_and_count_tokens(\n    _mock_similarity: Any,\n    _mock_llmchain: Any,\n    _mock_llm_metadata: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query and count tokens.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    # mock_prompts.MOCK_SUMMARY_PROMPT_TMPL adds a \"\\n\" to the document text\n    document_token_count = 24\n    llmchain_mock_resp_token_count = 10\n    # build the tree\n    tree = GPTTreeIndex(documents, **index_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used\n        == document_token_count + llmchain_mock_resp_token_count\n    )\n\n    # test embedding query\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    query_str = \"What is?\"\n    # From MOCK_TEXT_QA_PROMPT, the prompt is 28 total\n    query_prompt_token_count = 28\n    tree.query(query_str, mode=\"embedding\", **query_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used - start_token_ct\n        == query_prompt_token_count + llmchain_mock_resp_token_count\n    )\n", "doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "860ea69f-e687-43f1-a96b-9e168c74ad3d": {"text": "\nThe summaries of these documents are not provided.", "doc_id": "860ea69f-e687-43f1-a96b-9e168c74ad3d", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test embedding functionalities.\"\"\"\n\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.query.tree.embedding_query import GPTTreeIndexEmbeddingQuery\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmchain_predict\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_QUERY_PROMPT,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "2": {"text": "  MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef test_embedding_similarity() -> None:\n    \"\"\"Test embedding similarity.\"\"\"\n    embed_model = OpenAIEmbedding()\n    text_embedding = [3.0, 4.0, 0.0]\n    query_embedding = [0.0, 1.0, 0.0]\n    cosine = embed_model.similarity(query_embedding, text_embedding)\n    assert cosine == 0.8\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"summary_template\": MOCK_SUMMARY_PROMPT,\n        \"insert_prompt\": MOCK_INSERT_PROMPT,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "3": {"text": "       \"num_children\": 2,\n    }\n    query_kwargs = {\n        \"query_template\": MOCK_QUERY_PROMPT,\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\ndef _get_node_text_embedding_similarities(\n    query_embedding: List[float], nodes:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "4": {"text": "   query_embedding: List[float], nodes: List[Node]\n) -> List[float]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_similarity_map = defaultdict(lambda: 0.0)\n    text_similarity_map[\"Hello world.\"] = 0.9\n    text_similarity_map[\"This is a test.\"] = 0.8\n    text_similarity_map[\"This is another test.\"] = 0.7\n    text_similarity_map[\"This is a test v2.\"] = 0.6\n\n    similarities = []\n    for node in nodes:\n        similarities.append(text_similarity_map[node.get_text()])\n\n    return similarities\n\n\n@patch_common\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "5": {"text": "   _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    tree = GPTTreeIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = tree.query(query_str, mode=\"embedding\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch.object(LLMChain, \"predict\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "6": {"text": "\"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\n@patch.object(\n    GPTTreeIndexEmbeddingQuery,\n    \"_get_query_text_embedding_similarities\",\n    side_effect=_get_node_text_embedding_similarities,\n)\ndef test_query_and_count_tokens(\n    _mock_similarity: Any,\n    _mock_llmchain: Any,\n    _mock_llm_metadata: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    struct_kwargs: Dict,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query and count tokens.\"\"\"\n    index_kwargs, query_kwargs", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "7": {"text": "   index_kwargs, query_kwargs = struct_kwargs\n    # mock_prompts.MOCK_SUMMARY_PROMPT_TMPL adds a \"\\n\" to the document text\n    document_token_count = 24\n    llmchain_mock_resp_token_count = 10\n    # build the tree\n    tree = GPTTreeIndex(documents, **index_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used\n        == document_token_count + llmchain_mock_resp_token_count\n    )\n\n    # test embedding query\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    query_str = \"What is?\"\n    # From MOCK_TEXT_QA_PROMPT, the prompt is 28 total\n    query_prompt_token_count = 28\n    tree.query(query_str, mode=\"embedding\", **query_kwargs)\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "8": {"text": "mode=\"embedding\", **query_kwargs)\n    assert (\n        tree._llm_predictor.total_tokens_used - start_token_ct\n        == query_prompt_token_count + llmchain_mock_resp_token_count\n    )\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/embedding/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "6aea22e046e0a392ed78df85b9cb73e44e66fbbb", "node_info": null}, "9": {"text": "This code file tests the embedding functionalities of the GPTTreeIndex class. It tests the embedding similarity, query, and token count. It uses fixtures such as documents, index_kwargs, and query_kwargs to set up the tests. It also uses patching to mock the LLMChain, OpenAI, LLMPredictor, and GPTTreeIndexEmbeddingQuery classes. The tests check the similarity between two embeddings, the query response, and the token count.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file tests the embedding functionalities of the GPTTreeIndex class. It tests the embedding similarity, query, and token count. It uses fixtures such as documents, index_kwargs, and query_kwargs to set up the tests. It also uses patching to mock the LLMChain, OpenAI, LLMPredictor, and GPTTreeIndexEmbeddingQuery classes. The tests check the similarity between two embeddings, the query response, and the token count.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}