{"index_struct": {"text": "\nThe tests/indices/keyword_table/test_base.py file tests the build table, insert, delete, and query functions of the GPTSimpleKeywordTableIndex. The tests/indices/keyword_table/test_utils.py file tests the extract_keywords_given_response utility function. Both files test the functionality of the keyword table index in the GPT-Index library, using a mock keyword extractor to extract keywords from documents and testing the functionality of the keyword table index with different parameters.", "doc_id": "cd80b0cb-641f-49c4-bece-18cbcfc4430c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test keyword table index.\"\"\"\n\nfrom typing import Any, List\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_utils import mock_extract_keywords\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\n@patch(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "2": {"text": "   \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_build_table(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build table.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert len(table_chunks) == 4\n    assert \"Hello world.\" in table_chunks\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "3": {"text": " assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_insert(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "4": {"text": "test_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    table = GPTSimpleKeywordTableIndex([])\n    assert len(table.index_struct.table.keys()) == 0\n    table.insert(documents[0])\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "5": {"text": "keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n    # test insert with doc_id\n    document1 = Document(\"This is\", doc_id=\"test_id1\")\n    document2 = Document(\"test v3\", doc_id=\"test_id2\")\n    table = GPTSimpleKeywordTableIndex([])\n    table.insert(document1)\n    table.insert(document2)\n    chunk_index1_1 = list(table.index_struct.table[\"this\"])[0]\n    chunk_index1_2 = list(table.index_struct.table[\"is\"])[0]\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "6": {"text": "   chunk_index2_1 = list(table.index_struct.table[\"test\"])[0]\n    chunk_index2_2 = list(table.index_struct.table[\"v3\"])[0]\n    assert table.index_struct.text_chunks[chunk_index1_1].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index1_2].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index2_1].ref_doc_id == \"test_id2\"\n    assert table.index_struct.text_chunks[chunk_index2_2].ref_doc_id == \"test_id2\"\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_delete(\n    _mock_init: Any,\n    _mock_predict:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "7": {"text": "Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # test delete\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_1\")\n    assert len(table.index_struct.table.keys()) == 6\n    print(table.index_struct.table.keys())\n    assert len(table.index_struct.table[\"this\"]) == 2\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "8": {"text": "len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"This is another test.\", \"This is a test v2.\"}\n\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_2\")\n    assert len(table.index_struct.table.keys()) == 7\n    assert len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"Hello world.\", \"This is a test.\", \"This is a test v2.\"}\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\n@patch(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "9": {"text": "   \"gpt_index.indices.query.keyword_table.query.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n\n    response = table.query(\"Hello\", mode=\"simple\")\n    assert str(response) == \"Hello:Hello world.\"\n\n    # try with filters\n    doc_text = (\n        \"Hello world\\n\" \"Hello", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "10": {"text": "       \"Hello world\\n\" \"Hello foo\\n\" \"This is another test\\n\" \"This is a test v2\"\n    )\n    documents2 = [Document(doc_text)]\n    table2 = GPTSimpleKeywordTableIndex(documents2)\n    # NOTE: required keywords are somewhat redundant\n    response = table2.query(\"This\", mode=\"simple\", required_keywords=[\"v2\"])\n    assert str(response) == \"This:This is a test v2\"\n\n    # test exclude_keywords\n    response = table2.query(\"Hello\", mode=\"simple\", exclude_keywords=[\"world\"])\n    assert str(response) == \"Hello:Hello foo\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "11": {"text": "\"\"\"Test utils.\"\"\"\n\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\n\n\ndef test_expand_tokens_with_subtokens() -> None:\n    \"\"\"Test extract keywords given response.\"\"\"\n    response = \"foo bar, baz, Hello hello wOrld bye\"\n    keywords = extract_keywords_given_response(response)\n    assert keywords == {\n        \"foo bar\",\n        \"foo\",\n        \"bar\",\n        \"baz\",\n        \"hello hello world bye\",\n        \"hello\",\n        \"world\",\n        \"bye\",\n    }\n\n\ndef test_extract_keywords_with_start_delimiter() -> None:\n    \"\"\"Test extract keywords with start delimiter.\"\"\"\n    response = \"KEYWORDS: foo, bar, foobar\"\n    keywords =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_utils.py", "file_name": "test_utils.py"}, "index": 11, "child_indices": [], "ref_doc_id": "a565c5ede9769e63647e38e89a7ebe3be397c9c9", "node_info": null}, "12": {"text": "foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n\n    response = \"TOKENS: foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"TOKENS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_utils.py", "file_name": "test_utils.py"}, "index": 12, "child_indices": [], "ref_doc_id": "a565c5ede9769e63647e38e89a7ebe3be397c9c9", "node_info": null}, "13": {"text": "This code file contains tests for the keyword table index in the GPT-Index library. It tests the build table, insert, delete, and query functions. It also tests the extract keywords given response and extract keywords with start delimiter functions. The tests use a mock keyword extractor to extract keywords from documents, and also test the functionality of the keyword table index with different parameters such as required keywords, exclude keywords, and start delimiters.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "14": {"text": "test_utils.py is a code file that tests the functionality of the extract_keywords_given_response() function. This function takes a response string and a start_token as parameters and returns a set of keywords. The code file tests the function by providing two response strings, each with a different start_token, and asserting that the returned set of keywords is the same for both.", "doc_id": null, "embedding": null, "extra_info": null, "index": 14, "child_indices": [12], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"13": {"text": "This code file contains tests for the keyword table index in the GPT-Index library. It tests the build table, insert, delete, and query functions. It also tests the extract keywords given response and extract keywords with start delimiter functions. The tests use a mock keyword extractor to extract keywords from documents, and also test the functionality of the keyword table index with different parameters such as required keywords, exclude keywords, and start delimiters.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "14": {"text": "test_utils.py is a code file that tests the functionality of the extract_keywords_given_response() function. This function takes a response string and a start_token as parameters and returns a set of keywords. The code file tests the function by providing two response strings, each with a different start_token, and asserting that the returned set of keywords is the same for both.", "doc_id": null, "embedding": null, "extra_info": null, "index": 14, "child_indices": [12], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"1d4640565ae2765d9ca96a509dc9809217f62f2f": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "3766f7eb2961e7918fad3622ac9b52bc211a5c03": {"text": "\"\"\"Test keyword table index.\"\"\"\n\nfrom typing import Any, List\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_utils import mock_extract_keywords\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_build_table(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build table.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert len(table_chunks) == 4\n    assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    table = GPTSimpleKeywordTableIndex([])\n    assert len(table.index_struct.table.keys()) == 0\n    table.insert(documents[0])\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n    # test insert with doc_id\n    document1 = Document(\"This is\", doc_id=\"test_id1\")\n    document2 = Document(\"test v3\", doc_id=\"test_id2\")\n    table = GPTSimpleKeywordTableIndex([])\n    table.insert(document1)\n    table.insert(document2)\n    chunk_index1_1 = list(table.index_struct.table[\"this\"])[0]\n    chunk_index1_2 = list(table.index_struct.table[\"is\"])[0]\n    chunk_index2_1 = list(table.index_struct.table[\"test\"])[0]\n    chunk_index2_2 = list(table.index_struct.table[\"v3\"])[0]\n    assert table.index_struct.text_chunks[chunk_index1_1].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index1_2].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index2_1].ref_doc_id == \"test_id2\"\n    assert table.index_struct.text_chunks[chunk_index2_2].ref_doc_id == \"test_id2\"\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # test delete\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_1\")\n    assert len(table.index_struct.table.keys()) == 6\n    print(table.index_struct.table.keys())\n    assert len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"This is another test.\", \"This is a test v2.\"}\n\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_2\")\n    assert len(table.index_struct.table.keys()) == 7\n    assert len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"Hello world.\", \"This is a test.\", \"This is a test v2.\"}\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\n@patch(\n    \"gpt_index.indices.query.keyword_table.query.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n\n    response = table.query(\"Hello\", mode=\"simple\")\n    assert str(response) == \"Hello:Hello world.\"\n\n    # try with filters\n    doc_text = (\n        \"Hello world\\n\" \"Hello foo\\n\" \"This is another test\\n\" \"This is a test v2\"\n    )\n    documents2 = [Document(doc_text)]\n    table2 = GPTSimpleKeywordTableIndex(documents2)\n    # NOTE: required keywords are somewhat redundant\n    response = table2.query(\"This\", mode=\"simple\", required_keywords=[\"v2\"])\n    assert str(response) == \"This:This is a test v2\"\n\n    # test exclude_keywords\n    response = table2.query(\"Hello\", mode=\"simple\", exclude_keywords=[\"world\"])\n    assert str(response) == \"Hello:Hello foo\"\n", "doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "a565c5ede9769e63647e38e89a7ebe3be397c9c9": {"text": "\"\"\"Test utils.\"\"\"\n\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\n\n\ndef test_expand_tokens_with_subtokens() -> None:\n    \"\"\"Test extract keywords given response.\"\"\"\n    response = \"foo bar, baz, Hello hello wOrld bye\"\n    keywords = extract_keywords_given_response(response)\n    assert keywords == {\n        \"foo bar\",\n        \"foo\",\n        \"bar\",\n        \"baz\",\n        \"hello hello world bye\",\n        \"hello\",\n        \"world\",\n        \"bye\",\n    }\n\n\ndef test_extract_keywords_with_start_delimiter() -> None:\n    \"\"\"Test extract keywords with start delimiter.\"\"\"\n    response = \"KEYWORDS: foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n\n    response = \"TOKENS: foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"TOKENS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n", "doc_id": "a565c5ede9769e63647e38e89a7ebe3be397c9c9", "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_utils.py", "file_name": "test_utils.py"}, "__type__": "Document"}, "cd80b0cb-641f-49c4-bece-18cbcfc4430c": {"text": "\nThe tests/indices/keyword_table/test_base.py file tests the build table, insert, delete, and query functions of the GPTSimpleKeywordTableIndex. The tests/indices/keyword_table/test_utils.py file tests the extract_keywords_given_response utility function. Both files test the functionality of the keyword table index in the GPT-Index library, using a mock keyword extractor to extract keywords from documents and testing the functionality of the keyword table index with different parameters.", "doc_id": "cd80b0cb-641f-49c4-bece-18cbcfc4430c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test keyword table index.\"\"\"\n\nfrom typing import Any, List\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_utils import mock_extract_keywords\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\n@patch(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "2": {"text": "   \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_build_table(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build table.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert len(table_chunks) == 4\n    assert \"Hello world.\" in table_chunks\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "3": {"text": " assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_insert(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "4": {"text": "test_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    table = GPTSimpleKeywordTableIndex([])\n    assert len(table.index_struct.table.keys()) == 0\n    table.insert(documents[0])\n    table_chunks = {n.text for n in table.index_struct.text_chunks.values()}\n    assert \"Hello world.\" in table_chunks\n    assert \"This is a test.\" in table_chunks\n    assert \"This is another test.\" in table_chunks\n    assert \"This is a test v2.\" in table_chunks\n    # test that expected keys are present in table\n    # NOTE: in mock keyword extractor, stopwords are not filtered\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "5": {"text": "keyword extractor, stopwords are not filtered\n    assert table.index_struct.table.keys() == {\n        \"this\",\n        \"hello\",\n        \"world\",\n        \"test\",\n        \"another\",\n        \"v2\",\n        \"is\",\n        \"a\",\n        \"v2\",\n    }\n\n    # test insert with doc_id\n    document1 = Document(\"This is\", doc_id=\"test_id1\")\n    document2 = Document(\"test v3\", doc_id=\"test_id2\")\n    table = GPTSimpleKeywordTableIndex([])\n    table.insert(document1)\n    table.insert(document2)\n    chunk_index1_1 = list(table.index_struct.table[\"this\"])[0]\n    chunk_index1_2 = list(table.index_struct.table[\"is\"])[0]\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "6": {"text": "   chunk_index2_1 = list(table.index_struct.table[\"test\"])[0]\n    chunk_index2_2 = list(table.index_struct.table[\"v3\"])[0]\n    assert table.index_struct.text_chunks[chunk_index1_1].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index1_2].ref_doc_id == \"test_id1\"\n    assert table.index_struct.text_chunks[chunk_index2_1].ref_doc_id == \"test_id2\"\n    assert table.index_struct.text_chunks[chunk_index2_2].ref_doc_id == \"test_id2\"\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_delete(\n    _mock_init: Any,\n    _mock_predict:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "7": {"text": "Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # test delete\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_1\")\n    assert len(table.index_struct.table.keys()) == 6\n    print(table.index_struct.table.keys())\n    assert len(table.index_struct.table[\"this\"]) == 2\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "8": {"text": "len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"This is another test.\", \"This is a test v2.\"}\n\n    table = GPTSimpleKeywordTableIndex(new_documents)\n    table.delete(\"test_id_2\")\n    assert len(table.index_struct.table.keys()) == 7\n    assert len(table.index_struct.table[\"this\"]) == 2\n    node_texts = {n.text for n in table.index_struct.text_chunks.values()}\n    assert node_texts == {\"Hello world.\", \"This is a test.\", \"This is a test v2.\"}\n\n\n@patch_common\n@patch(\n    \"gpt_index.indices.keyword_table.simple_base.simple_extract_keywords\",\n    mock_extract_keywords,\n)\n@patch(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "9": {"text": "   \"gpt_index.indices.query.keyword_table.query.simple_extract_keywords\",\n    mock_extract_keywords,\n)\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test query.\"\"\"\n    # test simple keyword table\n    # NOTE: here the keyword extraction isn't mocked because we're using\n    # the regex-based keyword extractor, not GPT\n    table = GPTSimpleKeywordTableIndex(documents)\n\n    response = table.query(\"Hello\", mode=\"simple\")\n    assert str(response) == \"Hello:Hello world.\"\n\n    # try with filters\n    doc_text = (\n        \"Hello world\\n\" \"Hello", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "10": {"text": "       \"Hello world\\n\" \"Hello foo\\n\" \"This is another test\\n\" \"This is a test v2\"\n    )\n    documents2 = [Document(doc_text)]\n    table2 = GPTSimpleKeywordTableIndex(documents2)\n    # NOTE: required keywords are somewhat redundant\n    response = table2.query(\"This\", mode=\"simple\", required_keywords=[\"v2\"])\n    assert str(response) == \"This:This is a test v2\"\n\n    # test exclude_keywords\n    response = table2.query(\"Hello\", mode=\"simple\", exclude_keywords=[\"world\"])\n    assert str(response) == \"Hello:Hello foo\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "3766f7eb2961e7918fad3622ac9b52bc211a5c03", "node_info": null}, "11": {"text": "\"\"\"Test utils.\"\"\"\n\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\n\n\ndef test_expand_tokens_with_subtokens() -> None:\n    \"\"\"Test extract keywords given response.\"\"\"\n    response = \"foo bar, baz, Hello hello wOrld bye\"\n    keywords = extract_keywords_given_response(response)\n    assert keywords == {\n        \"foo bar\",\n        \"foo\",\n        \"bar\",\n        \"baz\",\n        \"hello hello world bye\",\n        \"hello\",\n        \"world\",\n        \"bye\",\n    }\n\n\ndef test_extract_keywords_with_start_delimiter() -> None:\n    \"\"\"Test extract keywords with start delimiter.\"\"\"\n    response = \"KEYWORDS: foo, bar, foobar\"\n    keywords =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_utils.py", "file_name": "test_utils.py"}, "index": 11, "child_indices": [], "ref_doc_id": "a565c5ede9769e63647e38e89a7ebe3be397c9c9", "node_info": null}, "12": {"text": "foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n\n    response = \"TOKENS: foo, bar, foobar\"\n    keywords = extract_keywords_given_response(response, start_token=\"TOKENS:\")\n    assert keywords == {\n        \"foo\",\n        \"bar\",\n        \"foobar\",\n    }\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/keyword_table/test_utils.py", "file_name": "test_utils.py"}, "index": 12, "child_indices": [], "ref_doc_id": "a565c5ede9769e63647e38e89a7ebe3be397c9c9", "node_info": null}, "13": {"text": "This code file contains tests for the keyword table index in the GPT-Index library. It tests the build table, insert, delete, and query functions. It also tests the extract keywords given response and extract keywords with start delimiter functions. The tests use a mock keyword extractor to extract keywords from documents, and also test the functionality of the keyword table index with different parameters such as required keywords, exclude keywords, and start delimiters.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "14": {"text": "test_utils.py is a code file that tests the functionality of the extract_keywords_given_response() function. This function takes a response string and a start_token as parameters and returns a set of keywords. The code file tests the function by providing two response strings, each with a different start_token, and asserting that the returned set of keywords is the same for both.", "doc_id": null, "embedding": null, "extra_info": null, "index": 14, "child_indices": [12], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"13": {"text": "This code file contains tests for the keyword table index in the GPT-Index library. It tests the build table, insert, delete, and query functions. It also tests the extract keywords given response and extract keywords with start delimiter functions. The tests use a mock keyword extractor to extract keywords from documents, and also test the functionality of the keyword table index with different parameters such as required keywords, exclude keywords, and start delimiters.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "14": {"text": "test_utils.py is a code file that tests the functionality of the extract_keywords_given_response() function. This function takes a response string and a start_token as parameters and returns a set of keywords. The code file tests the function by providing two response strings, each with a different start_token, and asserting that the returned set of keywords is the same for both.", "doc_id": null, "embedding": null, "extra_info": null, "index": 14, "child_indices": [12], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}