{"index_struct": {"text": "\nThe first document summary is: \"Hello world. This is a test. This is another test. This is a test v2.\"\n\nThe second document summary is: \"This is another test. This is a test v2.\"", "doc_id": "4e4d9a79-7b29-4530-97e1-efaf4c60875f", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"List-based data structures.\"\"\"\n\nfrom gpt_index.indices.list.base import GPTListIndex\n\n__all__ = [\n    \"GPTListIndex\",\n]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "b24c607f33df4130279f81016b5fdc2a22d19fd0", "node_info": null}, "1": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "2": {"text": "tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "3": {"text": "       \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "4": {"text": "== \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "5": {"text": "== \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "6": {"text": "== \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "7": {"text": "   _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "8": {"text": "== \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id ==", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "9": {"text": "== \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "10": {"text": "0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "11": {"text": "   index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "12": {"text": "Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 12, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "13": {"text": "           chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 13, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "14": {"text": "{}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 14, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "15": {"text": "  assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 15, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "16": {"text": "== (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 16, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "17": {"text": "query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 17, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "18": {"text": "       \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 18, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "19": {"text": "   _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 19, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "20": {"text": "== \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 20, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "21": {"text": "= cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 21, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "22": {"text": "This code file contains tests for the GPTListIndex class, which is a list-based data structure. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to split text into overlapping chunks. The tests use mock functions to simulate the behavior of the functions. The tests check the contents of the nodes, the insertion and deletion of documents, and the query response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to index and query documents. The code tests the calculation of node info with overlapping node text, query with keywords, embedding query, building/querying with extra info, saving to/from disk, and saving to/from string. The code uses the patch library to mock functions and objects, and uses the PromptHelper, TokenTextSplitter, and GPTListIndexEmbeddingQuery classes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file contains tests for the GPTListIndex class, which is a list-based data structure. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to split text into overlapping chunks. The tests use mock functions to simulate the behavior of the functions. The tests check the contents of the nodes, the insertion and deletion of documents, and the query response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to index and query documents. The code tests the calculation of node info with overlapping node text, query with keywords, embedding query, building/querying with extra info, saving to/from disk, and saving to/from string. The code uses the patch library to mock functions and objects, and uses the PromptHelper, TokenTextSplitter, and GPTListIndexEmbeddingQuery classes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"b24c607f33df4130279f81016b5fdc2a22d19fd0": {"text": "\"\"\"List-based data structures.\"\"\"\n\nfrom gpt_index.indices.list.base import GPTListIndex\n\n__all__ = [\n    \"GPTListIndex\",\n]\n", "doc_id": "b24c607f33df4130279f81016b5fdc2a22d19fd0", "embedding": null, "extra_info": {"file_path": "tests/indices/list/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "e08da1f225af970a08546034c5064e568f7aa219": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n            chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "4e4d9a79-7b29-4530-97e1-efaf4c60875f": {"text": "\nThe first document summary is: \"Hello world. This is a test. This is another test. This is a test v2.\"\n\nThe second document summary is: \"This is another test. This is a test v2.\"", "doc_id": "4e4d9a79-7b29-4530-97e1-efaf4c60875f", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"List-based data structures.\"\"\"\n\nfrom gpt_index.indices.list.base import GPTListIndex\n\n__all__ = [\n    \"GPTListIndex\",\n]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "b24c607f33df4130279f81016b5fdc2a22d19fd0", "node_info": null}, "1": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "2": {"text": "tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "3": {"text": "       \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "4": {"text": "== \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "5": {"text": "== \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "6": {"text": "== \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "7": {"text": "   _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "8": {"text": "== \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id ==", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "9": {"text": "== \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "10": {"text": "0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "11": {"text": "   index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "12": {"text": "Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 12, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "13": {"text": "           chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 13, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "14": {"text": "{}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 14, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "15": {"text": "  assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 15, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "16": {"text": "== (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 16, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "17": {"text": "query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 17, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "18": {"text": "       \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 18, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "19": {"text": "   _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 19, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "20": {"text": "== \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 20, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "21": {"text": "= cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 21, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "22": {"text": "This code file contains tests for the GPTListIndex class, which is a list-based data structure. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to split text into overlapping chunks. The tests use mock functions to simulate the behavior of the functions. The tests check the contents of the nodes, the insertion and deletion of documents, and the query response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to index and query documents. The code tests the calculation of node info with overlapping node text, query with keywords, embedding query, building/querying with extra info, saving to/from disk, and saving to/from string. The code uses the patch library to mock functions and objects, and uses the PromptHelper, TokenTextSplitter, and GPTListIndexEmbeddingQuery classes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file contains tests for the GPTListIndex class, which is a list-based data structure. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to split text into overlapping chunks. The tests use mock functions to simulate the behavior of the functions. The tests check the contents of the nodes, the insertion and deletion of documents, and the query response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to index and query documents. The code tests the calculation of node info with overlapping node text, query with keywords, embedding query, building/querying with extra info, saving to/from disk, and saving to/from string. The code uses the patch library to mock functions and objects, and uses the PromptHelper, TokenTextSplitter, and GPTListIndexEmbeddingQuery classes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}