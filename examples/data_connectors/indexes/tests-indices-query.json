{"index_struct": {"text": "\nIt is not possible to answer this question without additional information.", "doc_id": "f590a524-76b1-4722-a27d-55ebf451364c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init params.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "c637335013c599b07de054fba07b47ecb86ad3e8", "node_info": null}, "1": {"text": "\"\"\"Test query runner.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index import PromptHelper\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\n\n\ndef mock_llmchain_predict(**full_prompt_args: Any) -> str:\n    \"\"\"Mock LLMChain predict with a generic response.\"\"\"\n    return \"foo bar 2\"\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_passing_args_to_query(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "2": {"text": "test_passing_args_to_query(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_openai: Any,\n    _mock_predict: Any,\n) -> None:\n    \"\"\"Test passing args to query works.\n\n    Test that passing LLMPredictor from build index to query works.\n\n    \"\"\"\n    doc_text = \"Hello world.\"\n    doc = Document(doc_text)\n    llm_predictor = LLMPredictor()\n    prompt_helper = PromptHelper.from_llm_predictor(llm_predictor)\n    # index construction should not use llm_predictor at all\n    index = GPTListIndex(\n        [doc], llm_predictor=llm_predictor, prompt_helper=prompt_helper\n    )\n    # should use llm_predictor during query time\n    response = index.query(\"What is?\")\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "3": {"text": " response = index.query(\"What is?\")\n    assert str(response) == \"foo bar 2\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "4": {"text": "\"\"\"Test recursive queries.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.composability.graph import ComposableGraph\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.query.schema import QueryConfig, QueryMode\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_predict import (\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 4, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "5": {"text": "import (\n    mock_llmchain_predict,\n    mock_llmpredictor_predict,\n)\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, List]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"tree\": {\n            \"summary_template\": MOCK_SUMMARY_PROMPT,\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 5, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "6": {"text": "           \"insert_prompt\": MOCK_INSERT_PROMPT,\n            \"num_children\": 2,\n        },\n        \"list\": {\n            \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        },\n        \"table\": {\n            \"keyword_extract_template\": MOCK_KEYWORD_EXTRACT_PROMPT,\n        },\n    }\n    query_configs = [\n        QueryConfig(\n            index_struct_type=IndexStructType.TREE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_template\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 6, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "7": {"text": "           \"query_template\": MOCK_QUERY_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.LIST,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 7, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "8": {"text": "},\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.KEYWORD_TABLE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_keyword_extract_template\": MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n    ]\n    return index_kwargs, query_configs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    docs = [\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 8, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "9": {"text": "   docs = [\n        Document(\"This is a test v2.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test.\"),\n        Document(\"Hello world.\"),\n        Document(\"Hello world.\"),\n        Document(\"This is a test.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test v2.\"),\n    ]\n    return docs\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree(\n    _mock_init: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 9, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "10": {"text": "   _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 10, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "11": {"text": "   list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"What is?:This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 11, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "12": {"text": "  assert str(response) == (\"What is?:This is a test v2.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    tree_query_kwargs = query_configs[0].query_kwargs\n    response = tree.query(query_str, mode=\"default\", **tree_query_kwargs)\n    assert str(response) == (\"What is?:summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_tree_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 12, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "13": {"text": "Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    tree1 = GPTTreeIndex(documents[2:6], **tree_kwargs)\n    tree2 = GPTTreeIndex(documents[:2] + documents[6:], **tree_kwargs)\n    tree1.set_text(\"tree_summary1\")\n    tree2.set_text(\"tree_summary2\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    list_index = GPTListIndex([tree1, tree2],", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 13, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "14": {"text": " list_index = GPTListIndex([tree1, tree2], **list_kwargs)\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"What is?:This is a test.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    list_query_kwargs = query_configs[1].query_kwargs\n    response = list_index.query(query_str, mode=\"default\", **list_query_kwargs)\n    assert str(response) == (\"What is?:tree_summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 14, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "15": {"text": "\"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_table_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    table1 = GPTSimpleKeywordTableIndex(documents[4:6], **table_kwargs)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 15, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "16": {"text": "**table_kwargs)\n    table2 = GPTSimpleKeywordTableIndex(documents[2:3], **table_kwargs)\n    table1.set_text(\"table_summary1\")\n    table2.set_text(\"table_summary2\")\n    table1.set_doc_id(\"table1\")\n    table2.set_doc_id(\"table2\")\n\n    list_index = GPTListIndex([table1, table2], **list_kwargs)\n    query_str = \"World?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"World?:Hello world.\")\n\n    query_str = \"Test?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"Test?:This is a test.\")\n\n    # test serialize and then back\n    with", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 16, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "17": {"text": "   # test serialize and then back\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(list_index)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Test?:This is a test.\")\n\n        # test graph.get_index\n        test_table1 = graph.get_index(\"table1\", GPTSimpleKeywordTableIndex)\n        response = test_table1.query(\"Hello\")\n        assert str(response) == (\"Hello:Hello world.\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 17, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "18": {"text": "\"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_table(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 18, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "19": {"text": "of 4, then a list\n    # use a diff set of documents\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"foo bar\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"apple orange\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"toronto london\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"cat dog\")\n\n    table = GPTSimpleKeywordTableIndex([list1, list2, list3, list4], **table_kwargs)\n    query_str = \"Foo?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Foo?:This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 19, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "20": {"text": "  assert str(response) == (\"Foo?:This is a test v2.\")\n    query_str = \"Orange?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Orange?:This is a test.\")\n    query_str = \"Cat?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Cat?:This is another test.\")\n\n    # test serialize and then back\n    # use composable graph struct\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(table)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 20, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "21": {"text": "      response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Cat?:This is another test.\")\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree_token_count(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_llmchain: Any,\n    _mock_predict: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 21, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "22": {"text": "= struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    # import pdb; pdb.set_trace()\n    tree = GPTTreeIndex(\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 22, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "23": {"text": " tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    # first pass prompt is \"summary1\\nsummary2\\n\" (6 tokens),\n    # response is the mock response (10 tokens)\n    # total is 16 tokens, multiply by 2 to get the total\n    assert tree._llm_predictor.total_tokens_used == 32\n\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    tree.query(query_str, mode=\"recursive\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 23, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "24": {"text": "   tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    # prompt is which is 35 tokens, plus 10 for the mock response\n    assert tree._llm_predictor.total_tokens_used - start_token_ct == 45\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 24, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "25": {"text": "This code file contains tests for the query runner and recursive queries. The test_passing_args_to_query function tests that passing LLMPredictor from build index to query works. The test_recursive_query_list_tree function tests that a query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code uses unittest.mock to mock LLMChain predict, OpenAI, LLMPredictor get_llm_metadata, and LLMChain __init__. It also uses pytest fixtures to set up documents, index kwargs, and query configs.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file tests the recursive query functionality of GPTIndex. It tests the query of a GPTTreeIndex, GPTListIndex, and GPTSimpleKeywordTableIndex. It also tests the serialization and deserialization of the ComposableGraph structure. The query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code also tests the token count of the LLMChain predictor.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "test_recursive.py is a code file that tests the query function of a tree object. The query function is called with the parameters query_str, mode=\"recursive\", and query_configs. The code then checks that the total number of tokens used by the tree's _llm_predictor is 45, which is 35 tokens for the query_str plus 10 for the mock response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"25": {"text": "This code file contains tests for the query runner and recursive queries. The test_passing_args_to_query function tests that passing LLMPredictor from build index to query works. The test_recursive_query_list_tree function tests that a query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code uses unittest.mock to mock LLMChain predict, OpenAI, LLMPredictor get_llm_metadata, and LLMChain __init__. It also uses pytest fixtures to set up documents, index kwargs, and query configs.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file tests the recursive query functionality of GPTIndex. It tests the query of a GPTTreeIndex, GPTListIndex, and GPTSimpleKeywordTableIndex. It also tests the serialization and deserialization of the ComposableGraph structure. The query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code also tests the token count of the LLMChain predictor.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "test_recursive.py is a code file that tests the query function of a tree object. The query function is called with the parameters query_str, mode=\"recursive\", and query_configs. The code then checks that the total number of tokens used by the tree's _llm_predictor is 45, which is 35 tokens for the query_str plus 10 for the mock response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"c637335013c599b07de054fba07b47ecb86ad3e8": {"text": "\"\"\"Init params.\"\"\"\n", "doc_id": "c637335013c599b07de054fba07b47ecb86ad3e8", "embedding": null, "extra_info": {"file_path": "tests/indices/query/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "d283765f8173ce6fa83ad61a8a33198283818051": {"text": "\"\"\"Test query runner.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index import PromptHelper\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\n\n\ndef mock_llmchain_predict(**full_prompt_args: Any) -> str:\n    \"\"\"Mock LLMChain predict with a generic response.\"\"\"\n    return \"foo bar 2\"\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_passing_args_to_query(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_openai: Any,\n    _mock_predict: Any,\n) -> None:\n    \"\"\"Test passing args to query works.\n\n    Test that passing LLMPredictor from build index to query works.\n\n    \"\"\"\n    doc_text = \"Hello world.\"\n    doc = Document(doc_text)\n    llm_predictor = LLMPredictor()\n    prompt_helper = PromptHelper.from_llm_predictor(llm_predictor)\n    # index construction should not use llm_predictor at all\n    index = GPTListIndex(\n        [doc], llm_predictor=llm_predictor, prompt_helper=prompt_helper\n    )\n    # should use llm_predictor during query time\n    response = index.query(\"What is?\")\n    assert str(response) == \"foo bar 2\"\n", "doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "__type__": "Document"}, "1ed25268212c3ce05ed55f5f93ff110b69836ea8": {"text": "\"\"\"Test recursive queries.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.composability.graph import ComposableGraph\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.query.schema import QueryConfig, QueryMode\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_predict import (\n    mock_llmchain_predict,\n    mock_llmpredictor_predict,\n)\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, List]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"tree\": {\n            \"summary_template\": MOCK_SUMMARY_PROMPT,\n            \"insert_prompt\": MOCK_INSERT_PROMPT,\n            \"num_children\": 2,\n        },\n        \"list\": {\n            \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        },\n        \"table\": {\n            \"keyword_extract_template\": MOCK_KEYWORD_EXTRACT_PROMPT,\n        },\n    }\n    query_configs = [\n        QueryConfig(\n            index_struct_type=IndexStructType.TREE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_template\": MOCK_QUERY_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.LIST,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.KEYWORD_TABLE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_keyword_extract_template\": MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n    ]\n    return index_kwargs, query_configs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    docs = [\n        Document(\"This is a test v2.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test.\"),\n        Document(\"Hello world.\"),\n        Document(\"Hello world.\"),\n        Document(\"This is a test.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test v2.\"),\n    ]\n    return docs\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"What is?:This is a test v2.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    tree_query_kwargs = query_configs[0].query_kwargs\n    response = tree.query(query_str, mode=\"default\", **tree_query_kwargs)\n    assert str(response) == (\"What is?:summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_tree_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    tree1 = GPTTreeIndex(documents[2:6], **tree_kwargs)\n    tree2 = GPTTreeIndex(documents[:2] + documents[6:], **tree_kwargs)\n    tree1.set_text(\"tree_summary1\")\n    tree2.set_text(\"tree_summary2\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    list_index = GPTListIndex([tree1, tree2], **list_kwargs)\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"What is?:This is a test.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    list_query_kwargs = query_configs[1].query_kwargs\n    response = list_index.query(query_str, mode=\"default\", **list_query_kwargs)\n    assert str(response) == (\"What is?:tree_summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_table_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    table1 = GPTSimpleKeywordTableIndex(documents[4:6], **table_kwargs)\n    table2 = GPTSimpleKeywordTableIndex(documents[2:3], **table_kwargs)\n    table1.set_text(\"table_summary1\")\n    table2.set_text(\"table_summary2\")\n    table1.set_doc_id(\"table1\")\n    table2.set_doc_id(\"table2\")\n\n    list_index = GPTListIndex([table1, table2], **list_kwargs)\n    query_str = \"World?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"World?:Hello world.\")\n\n    query_str = \"Test?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"Test?:This is a test.\")\n\n    # test serialize and then back\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(list_index)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Test?:This is a test.\")\n\n        # test graph.get_index\n        test_table1 = graph.get_index(\"table1\", GPTSimpleKeywordTableIndex)\n        response = test_table1.query(\"Hello\")\n        assert str(response) == (\"Hello:Hello world.\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_table(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"foo bar\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"apple orange\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"toronto london\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"cat dog\")\n\n    table = GPTSimpleKeywordTableIndex([list1, list2, list3, list4], **table_kwargs)\n    query_str = \"Foo?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Foo?:This is a test v2.\")\n    query_str = \"Orange?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Orange?:This is a test.\")\n    query_str = \"Cat?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Cat?:This is another test.\")\n\n    # test serialize and then back\n    # use composable graph struct\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(table)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Cat?:This is another test.\")\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree_token_count(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_llmchain: Any,\n    _mock_predict: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    # import pdb; pdb.set_trace()\n    tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    # first pass prompt is \"summary1\\nsummary2\\n\" (6 tokens),\n    # response is the mock response (10 tokens)\n    # total is 16 tokens, multiply by 2 to get the total\n    assert tree._llm_predictor.total_tokens_used == 32\n\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    # prompt is which is 35 tokens, plus 10 for the mock response\n    assert tree._llm_predictor.total_tokens_used - start_token_ct == 45\n", "doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "__type__": "Document"}, "f590a524-76b1-4722-a27d-55ebf451364c": {"text": "\nIt is not possible to answer this question without additional information.", "doc_id": "f590a524-76b1-4722-a27d-55ebf451364c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init params.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "c637335013c599b07de054fba07b47ecb86ad3e8", "node_info": null}, "1": {"text": "\"\"\"Test query runner.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index import PromptHelper\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.readers.schema.base import Document\n\n\ndef mock_llmchain_predict(**full_prompt_args: Any) -> str:\n    \"\"\"Mock LLMChain predict with a generic response.\"\"\"\n    return \"foo bar 2\"\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_passing_args_to_query(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "2": {"text": "test_passing_args_to_query(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_openai: Any,\n    _mock_predict: Any,\n) -> None:\n    \"\"\"Test passing args to query works.\n\n    Test that passing LLMPredictor from build index to query works.\n\n    \"\"\"\n    doc_text = \"Hello world.\"\n    doc = Document(doc_text)\n    llm_predictor = LLMPredictor()\n    prompt_helper = PromptHelper.from_llm_predictor(llm_predictor)\n    # index construction should not use llm_predictor at all\n    index = GPTListIndex(\n        [doc], llm_predictor=llm_predictor, prompt_helper=prompt_helper\n    )\n    # should use llm_predictor during query time\n    response = index.query(\"What is?\")\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "3": {"text": " response = index.query(\"What is?\")\n    assert str(response) == \"foo bar 2\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_query_runner.py", "file_name": "test_query_runner.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d283765f8173ce6fa83ad61a8a33198283818051", "node_info": null}, "4": {"text": "\"\"\"Test recursive queries.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Tuple\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.composability.graph import ComposableGraph\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.indices.keyword_table.simple_base import GPTSimpleKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.query.schema import QueryConfig, QueryMode\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import (\n    LLMChain,\n    LLMMetadata,\n    LLMPredictor,\n)\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom tests.mock_utils.mock_predict import (\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 4, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "5": {"text": "import (\n    mock_llmchain_predict,\n    mock_llmpredictor_predict,\n)\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_INSERT_PROMPT,\n    MOCK_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n    MOCK_QUERY_PROMPT,\n    MOCK_REFINE_PROMPT,\n    MOCK_SUMMARY_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, List]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"tree\": {\n            \"summary_template\": MOCK_SUMMARY_PROMPT,\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 5, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "6": {"text": "           \"insert_prompt\": MOCK_INSERT_PROMPT,\n            \"num_children\": 2,\n        },\n        \"list\": {\n            \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        },\n        \"table\": {\n            \"keyword_extract_template\": MOCK_KEYWORD_EXTRACT_PROMPT,\n        },\n    }\n    query_configs = [\n        QueryConfig(\n            index_struct_type=IndexStructType.TREE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_template\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 6, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "7": {"text": "           \"query_template\": MOCK_QUERY_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.LIST,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 7, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "8": {"text": "},\n        ),\n        QueryConfig(\n            index_struct_type=IndexStructType.KEYWORD_TABLE,\n            query_mode=QueryMode.DEFAULT,\n            query_kwargs={\n                \"query_keyword_extract_template\": MOCK_QUERY_KEYWORD_EXTRACT_PROMPT,\n                \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n                \"refine_template\": MOCK_REFINE_PROMPT,\n            },\n        ),\n    ]\n    return index_kwargs, query_configs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    docs = [\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 8, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "9": {"text": "   docs = [\n        Document(\"This is a test v2.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test.\"),\n        Document(\"Hello world.\"),\n        Document(\"Hello world.\"),\n        Document(\"This is a test.\"),\n        Document(\"This is another test.\"),\n        Document(\"This is a test v2.\"),\n    ]\n    return docs\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree(\n    _mock_init: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 9, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "10": {"text": "   _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 10, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "11": {"text": "   list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"What is?:This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 11, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "12": {"text": "  assert str(response) == (\"What is?:This is a test v2.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    tree_query_kwargs = query_configs[0].query_kwargs\n    response = tree.query(query_str, mode=\"default\", **tree_query_kwargs)\n    assert str(response) == (\"What is?:summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_tree_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 12, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "13": {"text": "Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    tree1 = GPTTreeIndex(documents[2:6], **tree_kwargs)\n    tree2 = GPTTreeIndex(documents[:2] + documents[6:], **tree_kwargs)\n    tree1.set_text(\"tree_summary1\")\n    tree2.set_text(\"tree_summary2\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    list_index = GPTListIndex([tree1, tree2],", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 13, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "14": {"text": " list_index = GPTListIndex([tree1, tree2], **list_kwargs)\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"What is?:This is a test.\")\n\n    # Also test a non-recursive query. This should not go down into the list\n    list_query_kwargs = query_configs[1].query_kwargs\n    response = list_index.query(query_str, mode=\"default\", **list_query_kwargs)\n    assert str(response) == (\"What is?:tree_summary1\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 14, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "15": {"text": "\"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_table_list(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of documents\n    table1 = GPTSimpleKeywordTableIndex(documents[4:6], **table_kwargs)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 15, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "16": {"text": "**table_kwargs)\n    table2 = GPTSimpleKeywordTableIndex(documents[2:3], **table_kwargs)\n    table1.set_text(\"table_summary1\")\n    table2.set_text(\"table_summary2\")\n    table1.set_doc_id(\"table1\")\n    table2.set_doc_id(\"table2\")\n\n    list_index = GPTListIndex([table1, table2], **list_kwargs)\n    query_str = \"World?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"World?:Hello world.\")\n\n    query_str = \"Test?\"\n    response = list_index.query(\n        query_str, mode=\"recursive\", query_configs=query_configs\n    )\n    assert str(response) == (\"Test?:This is a test.\")\n\n    # test serialize and then back\n    with", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 16, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "17": {"text": "   # test serialize and then back\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(list_index)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Test?:This is a test.\")\n\n        # test graph.get_index\n        test_table1 = graph.get_index(\"table1\", GPTSimpleKeywordTableIndex)\n        response = test_table1.query(\"Hello\")\n        assert str(response) == (\"Hello:Hello world.\")\n\n\n@patch.object(TokenTextSplitter, \"split_text\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 17, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "18": {"text": "\"split_text\", side_effect=mock_token_splitter_newline)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_recursive_query_list_table(\n    _mock_init: Any,\n    _mock_total_tokens_used: Any,\n    _mock_predict: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    table_kwargs = index_kwargs[\"table\"]\n    # try building a tree for a group of 4, then a list\n    # use a diff set of", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 18, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "19": {"text": "of 4, then a list\n    # use a diff set of documents\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"foo bar\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"apple orange\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"toronto london\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"cat dog\")\n\n    table = GPTSimpleKeywordTableIndex([list1, list2, list3, list4], **table_kwargs)\n    query_str = \"Foo?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Foo?:This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 19, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "20": {"text": "  assert str(response) == (\"Foo?:This is a test v2.\")\n    query_str = \"Orange?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Orange?:This is a test.\")\n    query_str = \"Cat?\"\n    response = table.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    assert str(response) == (\"Cat?:This is another test.\")\n\n    # test serialize and then back\n    # use composable graph struct\n    with TemporaryDirectory() as tmpdir:\n        graph = ComposableGraph.build_from_index(table)\n        graph.save_to_disk(str(Path(tmpdir) / \"tmp.json\"))\n        graph = ComposableGraph.load_from_disk(str(Path(tmpdir) / \"tmp.json\"))\n        response = graph.query(query_str,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 20, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "21": {"text": "      response = graph.query(query_str, query_configs=query_configs)\n        assert str(response) == (\"Cat?:This is another test.\")\n\n\n@patch.object(LLMChain, \"predict\", side_effect=mock_llmchain_predict)\n@patch(\"gpt_index.langchain_helpers.chain_wrapper.OpenAI\")\n@patch.object(LLMPredictor, \"get_llm_metadata\", return_value=LLMMetadata())\n@patch.object(LLMChain, \"__init__\", return_value=None)\ndef test_recursive_query_list_tree_token_count(\n    _mock_init: Any,\n    _mock_llm_metadata: Any,\n    _mock_llmchain: Any,\n    _mock_predict: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test query.\"\"\"\n    index_kwargs, query_configs = struct_kwargs\n    list_kwargs =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 21, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "22": {"text": "= struct_kwargs\n    list_kwargs = index_kwargs[\"list\"]\n    tree_kwargs = index_kwargs[\"tree\"]\n    # try building a list for every two, then a tree\n    list1 = GPTListIndex(documents[0:2], **list_kwargs)\n    list1.set_text(\"summary1\")\n    list2 = GPTListIndex(documents[2:4], **list_kwargs)\n    list2.set_text(\"summary2\")\n    list3 = GPTListIndex(documents[4:6], **list_kwargs)\n    list3.set_text(\"summary3\")\n    list4 = GPTListIndex(documents[6:8], **list_kwargs)\n    list4.set_text(\"summary4\")\n\n    # there are two root nodes in this tree: one containing [list1, list2]\n    # and the other containing [list3, list4]\n    # import pdb; pdb.set_trace()\n    tree = GPTTreeIndex(\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 22, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "23": {"text": " tree = GPTTreeIndex(\n        [\n            list1,\n            list2,\n            list3,\n            list4,\n        ],\n        **tree_kwargs\n    )\n    # first pass prompt is \"summary1\\nsummary2\\n\" (6 tokens),\n    # response is the mock response (10 tokens)\n    # total is 16 tokens, multiply by 2 to get the total\n    assert tree._llm_predictor.total_tokens_used == 32\n\n    query_str = \"What is?\"\n    # query should first pick the left root node, then pick list1\n    # within list1, it should go through the first document and second document\n    start_token_ct = tree._llm_predictor.total_tokens_used\n    tree.query(query_str, mode=\"recursive\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 23, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "24": {"text": "   tree.query(query_str, mode=\"recursive\", query_configs=query_configs)\n    # prompt is which is 35 tokens, plus 10 for the mock response\n    assert tree._llm_predictor.total_tokens_used - start_token_ct == 45\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/query/test_recursive.py", "file_name": "test_recursive.py"}, "index": 24, "child_indices": [], "ref_doc_id": "1ed25268212c3ce05ed55f5f93ff110b69836ea8", "node_info": null}, "25": {"text": "This code file contains tests for the query runner and recursive queries. The test_passing_args_to_query function tests that passing LLMPredictor from build index to query works. The test_recursive_query_list_tree function tests that a query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code uses unittest.mock to mock LLMChain predict, OpenAI, LLMPredictor get_llm_metadata, and LLMChain __init__. It also uses pytest fixtures to set up documents, index kwargs, and query configs.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file tests the recursive query functionality of GPTIndex. It tests the query of a GPTTreeIndex, GPTListIndex, and GPTSimpleKeywordTableIndex. It also tests the serialization and deserialization of the ComposableGraph structure. The query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code also tests the token count of the LLMChain predictor.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "test_recursive.py is a code file that tests the query function of a tree object. The query function is called with the parameters query_str, mode=\"recursive\", and query_configs. The code then checks that the total number of tokens used by the tree's _llm_predictor is 45, which is 35 tokens for the query_str plus 10 for the mock response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"25": {"text": "This code file contains tests for the query runner and recursive queries. The test_passing_args_to_query function tests that passing LLMPredictor from build index to query works. The test_recursive_query_list_tree function tests that a query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code uses unittest.mock to mock LLMChain predict, OpenAI, LLMPredictor get_llm_metadata, and LLMChain __init__. It also uses pytest fixtures to set up documents, index kwargs, and query configs.", "doc_id": null, "embedding": null, "extra_info": null, "index": 25, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], "ref_doc_id": null, "node_info": null}, "26": {"text": "This code file tests the recursive query functionality of GPTIndex. It tests the query of a GPTTreeIndex, GPTListIndex, and GPTSimpleKeywordTableIndex. It also tests the serialization and deserialization of the ComposableGraph structure. The query should first pick the left root node, then pick list1 within list1, it should go through the first document and second document. The code also tests the token count of the LLMChain predictor.", "doc_id": null, "embedding": null, "extra_info": null, "index": 26, "child_indices": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], "ref_doc_id": null, "node_info": null}, "27": {"text": "test_recursive.py is a code file that tests the query function of a tree object. The query function is called with the parameters query_str, mode=\"recursive\", and query_configs. The code then checks that the total number of tokens used by the tree's _llm_predictor is 45, which is 35 tokens for the query_str plus 10 for the mock response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 27, "child_indices": [24], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}