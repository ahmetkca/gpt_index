{"index_struct": {"text": "\nThese documents test the functionality of the Prompt class from the gpt_index.prompts.base module. They check the validate, partial_format, from_prompt, and from_langchain_prompt methods, as well as errors that occur when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": "6795e856-047f-4f42-8d1a-9c6caff1cdb7", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test prompts.\"\"\"\n\nfrom typing import List\n\nimport pytest\nfrom langchain import PromptTemplate\n\nfrom gpt_index.prompts.base import Prompt\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\", \"foo\"]\n\n\ndef test_prompt_validate() -> None:\n    \"\"\"Test prompt validate.\"\"\"\n    # assert passes\n    prompt_txt = \"hello {text} {foo}\"\n    TestPrompt(prompt_txt)\n\n    # assert fails (missing required values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {tmp}\"\n        TestPrompt(prompt_txt)\n\n    # assert fails (extraneous values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {text2}\"\n        TestPrompt(prompt_txt)\n\n\ndef", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "2": {"text": "    TestPrompt(prompt_txt)\n\n\ndef test_partial_format() -> None:\n    \"\"\"Test partial format.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    assert isinstance(prompt_fmt, TestPrompt)\n    assert prompt_fmt.format(text=\"world\") == \"hello world bar\"\n\n\ndef test_from_prompt() -> None:\n    \"\"\"Test new prompt from a partially formatted prompt.\"\"\"\n\n    class TestPromptTextOnly(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"text\"]\n\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    prompt_new =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "3": {"text": "   prompt_new = TestPromptTextOnly.from_prompt(prompt_fmt)\n    assert isinstance(prompt_new, TestPromptTextOnly)\n\n    assert prompt_new.format(text=\"world2\") == \"hello world2 bar\"\n\n\ndef test_from_langchain_prompt() -> None:\n    \"\"\"Test from langchain prompt.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n    prompt_new = TestPrompt.from_langchain_prompt(prompt)\n\n    assert isinstance(prompt_new, TestPrompt)\n    assert prompt_new.prompt == prompt\n    assert prompt_new.format(text=\"world2\", foo=\"bar\") == \"hello world2 bar\"\n\n    # test errors if langchain prompt input var doesn't match\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {tmp}\"\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "4": {"text": "\"hello {text} {foo} {tmp}\"\n        prompt = PromptTemplate(\n            input_variables=[\"text\", \"foo\", \"tmp\"], template=prompt_txt\n        )\n        TestPrompt.from_langchain_prompt(prompt)\n\n    # test errors if we specify both template and langchain prompt\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo}\"\n        prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n        TestPrompt(template=prompt_txt, langchain_prompt=prompt)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "5": {"text": "This code file tests the functionality of the Prompt class from the gpt_index.prompts.base module. It tests the validate, partial_format, from_prompt, and from_langchain_prompt methods. It also tests for errors when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "This code file tests the functionality of the Prompt class from the gpt_index.prompts.base module. It tests the validate, partial_format, from_prompt, and from_langchain_prompt methods. It also tests for errors when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"1d4640565ae2765d9ca96a509dc9809217f62f2f": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "embedding": null, "extra_info": {"file_path": "tests/prompts/__init__.py", "file_name": "__init__.py"}, "__type__": "Document"}, "e4b5eca71db3211c5ea203a9274fc6029bb553be": {"text": "\"\"\"Test prompts.\"\"\"\n\nfrom typing import List\n\nimport pytest\nfrom langchain import PromptTemplate\n\nfrom gpt_index.prompts.base import Prompt\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\", \"foo\"]\n\n\ndef test_prompt_validate() -> None:\n    \"\"\"Test prompt validate.\"\"\"\n    # assert passes\n    prompt_txt = \"hello {text} {foo}\"\n    TestPrompt(prompt_txt)\n\n    # assert fails (missing required values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {tmp}\"\n        TestPrompt(prompt_txt)\n\n    # assert fails (extraneous values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {text2}\"\n        TestPrompt(prompt_txt)\n\n\ndef test_partial_format() -> None:\n    \"\"\"Test partial format.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    assert isinstance(prompt_fmt, TestPrompt)\n    assert prompt_fmt.format(text=\"world\") == \"hello world bar\"\n\n\ndef test_from_prompt() -> None:\n    \"\"\"Test new prompt from a partially formatted prompt.\"\"\"\n\n    class TestPromptTextOnly(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"text\"]\n\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    prompt_new = TestPromptTextOnly.from_prompt(prompt_fmt)\n    assert isinstance(prompt_new, TestPromptTextOnly)\n\n    assert prompt_new.format(text=\"world2\") == \"hello world2 bar\"\n\n\ndef test_from_langchain_prompt() -> None:\n    \"\"\"Test from langchain prompt.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n    prompt_new = TestPrompt.from_langchain_prompt(prompt)\n\n    assert isinstance(prompt_new, TestPrompt)\n    assert prompt_new.prompt == prompt\n    assert prompt_new.format(text=\"world2\", foo=\"bar\") == \"hello world2 bar\"\n\n    # test errors if langchain prompt input var doesn't match\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {tmp}\"\n        prompt = PromptTemplate(\n            input_variables=[\"text\", \"foo\", \"tmp\"], template=prompt_txt\n        )\n        TestPrompt.from_langchain_prompt(prompt)\n\n    # test errors if we specify both template and langchain prompt\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo}\"\n        prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n        TestPrompt(template=prompt_txt, langchain_prompt=prompt)\n", "doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "6795e856-047f-4f42-8d1a-9c6caff1cdb7": {"text": "\nThese documents test the functionality of the Prompt class from the gpt_index.prompts.base module. They check the validate, partial_format, from_prompt, and from_langchain_prompt methods, as well as errors that occur when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": "6795e856-047f-4f42-8d1a-9c6caff1cdb7", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Init file.\"\"\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/__init__.py", "file_name": "__init__.py"}, "index": 0, "child_indices": [], "ref_doc_id": "1d4640565ae2765d9ca96a509dc9809217f62f2f", "node_info": null}, "1": {"text": "\"\"\"Test prompts.\"\"\"\n\nfrom typing import List\n\nimport pytest\nfrom langchain import PromptTemplate\n\nfrom gpt_index.prompts.base import Prompt\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\", \"foo\"]\n\n\ndef test_prompt_validate() -> None:\n    \"\"\"Test prompt validate.\"\"\"\n    # assert passes\n    prompt_txt = \"hello {text} {foo}\"\n    TestPrompt(prompt_txt)\n\n    # assert fails (missing required values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {tmp}\"\n        TestPrompt(prompt_txt)\n\n    # assert fails (extraneous values)\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {text2}\"\n        TestPrompt(prompt_txt)\n\n\ndef", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "2": {"text": "    TestPrompt(prompt_txt)\n\n\ndef test_partial_format() -> None:\n    \"\"\"Test partial format.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    assert isinstance(prompt_fmt, TestPrompt)\n    assert prompt_fmt.format(text=\"world\") == \"hello world bar\"\n\n\ndef test_from_prompt() -> None:\n    \"\"\"Test new prompt from a partially formatted prompt.\"\"\"\n\n    class TestPromptTextOnly(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"text\"]\n\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = TestPrompt(prompt_txt)\n    prompt_fmt = prompt.partial_format(foo=\"bar\")\n\n    prompt_new =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "3": {"text": "   prompt_new = TestPromptTextOnly.from_prompt(prompt_fmt)\n    assert isinstance(prompt_new, TestPromptTextOnly)\n\n    assert prompt_new.format(text=\"world2\") == \"hello world2 bar\"\n\n\ndef test_from_langchain_prompt() -> None:\n    \"\"\"Test from langchain prompt.\"\"\"\n    prompt_txt = \"hello {text} {foo}\"\n    prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n    prompt_new = TestPrompt.from_langchain_prompt(prompt)\n\n    assert isinstance(prompt_new, TestPrompt)\n    assert prompt_new.prompt == prompt\n    assert prompt_new.format(text=\"world2\", foo=\"bar\") == \"hello world2 bar\"\n\n    # test errors if langchain prompt input var doesn't match\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo} {tmp}\"\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "4": {"text": "\"hello {text} {foo} {tmp}\"\n        prompt = PromptTemplate(\n            input_variables=[\"text\", \"foo\", \"tmp\"], template=prompt_txt\n        )\n        TestPrompt.from_langchain_prompt(prompt)\n\n    # test errors if we specify both template and langchain prompt\n    with pytest.raises(ValueError):\n        prompt_txt = \"hello {text} {foo}\"\n        prompt = PromptTemplate(input_variables=[\"text\", \"foo\"], template=prompt_txt)\n        TestPrompt(template=prompt_txt, langchain_prompt=prompt)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/prompts/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e4b5eca71db3211c5ea203a9274fc6029bb553be", "node_info": null}, "5": {"text": "This code file tests the functionality of the Prompt class from the gpt_index.prompts.base module. It tests the validate, partial_format, from_prompt, and from_langchain_prompt methods. It also tests for errors when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "This code file tests the functionality of the Prompt class from the gpt_index.prompts.base module. It tests the validate, partial_format, from_prompt, and from_langchain_prompt methods. It also tests for errors when the input variables do not match the template or when both a template and a langchain prompt are specified.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}