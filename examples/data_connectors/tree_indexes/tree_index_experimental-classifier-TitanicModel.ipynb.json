{"index_struct": {"text": "\nThis code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The GPT List Index is used to store and query the data, and the get_eval_preds function is used to get the evaluation predictions. The accuracy_score module from sklearn is used to calculate the accuracy of the predictions. The code is designed to provide a way to predict survival on the Titanic with an accuracy of around 80%. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets. The code uses the utils module to get the training and evaluation data, and then uses GPT-3 to prompt the model with a few example inputs. The code also provides a prompt template to demonstrate how GPT-3 can be used to attain ~80% accuracy on the Titanic dataset.", "doc_id": "cd8b0452-85f1-46e1-a754-d56d2ed40f8e", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"id\": \"f445c1d1-acb9-431e-a7ff-50c41f064359\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stderr\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\\n\",\n      \"[nltk_data] Downloading package stopwords to\\n\",\n      \"[nltk_data]     /Users/jerryliu/nltk_data...\\n\",\n      \"[nltk_data]   Package stopwords is already up-to-date!\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"from utils import (\\n\",\n    \"    get_train_str,\\n\",\n    \"    get_train_and_eval_data,\\n\",\n    \"   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 0, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "1": {"text": "   \"    get_eval_preds,\\n\",\n    \"    train_prompt\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"import warnings\\n\",\n    \"warnings.filterwarnings('ignore')\\n\",\n    \"warnings.simplefilter('ignore')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 2,\n   \"id\": \"cf3cbd90-d5e1-4c30-a3bc-8b39fbd85d70\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# load up the titanic data\\n\",\n    \"train_df, train_labels, eval_df, eval_labels = get_train_and_eval_data('data/train.csv')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"fa2634f9-cb33-4f1e-81f9-3a3b285e2580\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Few-shot Prompting with GPT-3 for Titanic Dataset\\n\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 1, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "2": {"text": "Prompting with GPT-3 for Titanic Dataset\\n\",\n    \"In this section, we can show how we can prompt GPT-3 on its own (without using GPT Index) to attain ~80% accuracy on Titanic! \\n\",\n    \"\\n\",\n    \"We can do this by simply providing a few example inputs. Or we can simply provide no example inputs at all (zero-shot). Both achieve the same results.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"id\": \"d0698fd2-1361-49ae-8c17-8124e9b932a4\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"Some example datapoints are given below: \\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 2, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "3": {"text": "\"Some example datapoints are given below: \\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# first demonstrate the prompt template\\n\",\n    \"print(train_prompt.template)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 4,\n   \"id\": \"4b39e2e7-be07-42f8-a27a-3419e84cfb2c\",\n   \"metadata\": {\n    \"scrolled\": true,\n    \"tags\": []\n   },\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Example datapoints in `train_str`: \\n\",\n      \"This is the Data:\\n\",\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 3, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "4": {"text": "\\n\",\n      \"This is the Data:\\n\",\n      \"Age:28.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.8958\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:17.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:2\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:4\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:30.0\\n\",\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 4, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "5": {"text": "     \"Age:30.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:16.1\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:22.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.25\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:45.0\\n\",\n      \"Embarked:S\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 5, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "6": {"text": "     \"Embarked:S\\n\",\n      \"Fare:13.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:25.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:0.0\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:18.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:20.2125\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 6, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "7": {"text": "   \"Fare:20.2125\\n\",\n      \"Parch:1\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:33.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:9.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:24.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:65.0\\n\",\n      \"Parch:2\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 7, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "8": {"text": "     \"Parch:2\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:26.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# Get \\\"training\\\" prompt string \\n\",\n    \"train_n = 10\\n\",\n    \"eval_n = 40\\n\",\n    \"train_str = get_train_str(train_df, train_labels, train_n=train_n)\\n\",\n    \"print(f\\\"Example", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 8, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "9": {"text": "train_n=train_n)\\n\",\n    \"print(f\\\"Example datapoints in `train_str`: \\\\n{train_str}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"819a06f7-3171-4edb-b90c-0a3eae308a04\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with the training prompt string\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"4a7f2202-518c-41a3-80ab-1e98bbcca903\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds = get_eval_preds(train_prompt, train_str, eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 9, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "10": {"text": "  \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"id\": \"64323a4d-6eea-4e40-9eac-b2deed60192b\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"11790d28-8f34-42dd-b11f-6aad21fd5f46\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with no training prompt string! \"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 10, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "11": {"text": "\"code\",\n   \"execution_count\": null,\n   \"id\": \"aaf993e5-c363-4f18-a28f-09761e49cb6d\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds_null = get_eval_preds(train_prompt, \\\"\\\", eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 11,\n   \"id\": \"c3b8bcd5-5972-4ce5-9aa1-57460cdde199\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc_null =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 11, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "12": {"text": "  ],\n   \"source\": [\n    \"acc_null = accuracy_score(eval_label_chunk, np.array(eval_preds_null).round())\\n\",\n    \"print(f'ACCURACY: {acc_null}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"8f0a5e4b-e627-4b47-a807-939813596594\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Extending with GPT List Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"42a1ca28-96e9-4cd2-bd48-0673917ad057\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Build Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 12,\n   \"id\": \"6c59b030-855d-4e27-89c3-74c972d1bf19\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from gpt_index import GPTListIndex\\n\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 12, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "13": {"text": "[\n    \"from gpt_index import GPTListIndex\\n\",\n    \"from gpt_index.readers.schema.base import Document\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 13,\n   \"id\": \"8f9556de-e323-4318-bb71-cff75bf8c3c1\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"index = GPTListIndex([])\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e27720fc-af36-40fd-8c55-41485248aa9f\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# insertion into index \\n\",\n    \"batch_size = 40\\n\",\n    \"num_train_chunks = 5\\n\",\n    \"\\n\",\n    \"for i in range(num_train_chunks):\\n\",\n    \"    print(f\\\"Inserting chunk: {i}/{num_train_chunks}\\\")\\n\",\n    \"    start_idx =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 13, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "14": {"text": "   \"    start_idx = i*batch_size\\n\",\n    \"    end_idx = (i+1)*batch_size\\n\",\n    \"    train_batch = train_df.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    labels_batch = train_labels.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    all_train_str = get_train_str(train_batch, labels_batch, train_n=batch_size)\\n\",\n    \"    index.insert(Document(all_train_str))\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"e78db088-6649-44db-b52a-766316713b96\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Query Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 15,\n   \"id\": \"9cb90564-1de2-412f-8318-d5280855004e\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from utils import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 14, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "15": {"text": "[],\n   \"source\": [\n    \"from utils import query_str, qa_data_prompt, refine_prompt\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 16,\n   \"id\": \"77c1ae36-e0af-47bc-a656-4971af699755\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"'Which is the relationship between these features and predicting survival?'\"\n      ]\n     },\n     \"execution_count\": 16,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"query_str\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 17,\n   \"id\": \"c403710f-d4b3-4287-94f5-e275ea19b476\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 15, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "16": {"text": "\"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"> Starting query: Which is the relationship between these features and predicting survival?\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"response = index.query(\\n\",\n    \"    query_str, \\n\",\n    \"    text_qa_template=qa_data_prompt, \\n\",\n    \"    refine_template=refine_prompt, \\n\",\n    \")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 19,\n   \"id\": \"d2545ab1-980a-4fbd-8add-7ef957801644\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"\\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 16, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "17": {"text": "depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"print(response)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"d0d7d260-2283-49f6-ac40-35c7071cc54d\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Get Predictions and Evaluate\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 26,\n   \"id\": \"e7b98057-957c-48ef-be85-59ff9813d201\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 17, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "18": {"text": "Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"We discovered the following relationship between features and survival:\\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. \\n\",\n      \"Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\",\n      \"\\n\",\n      \"\\n\",\n      \"`train_str`: \\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 18, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "19": {"text": "likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# get eval preds\\n\",\n    \"from utils import train_prompt_with_context\\n\",\n    \"\\n\",\n    \"train_str = response\\n\",\n    \"print(train_prompt_with_context.template)\\n\",\n    \"print(f'\\\\n\\\\n`train_str`: {train_str}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"659c6a3f-1c5d-4314-87dc-908e76d50e4a\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# do evaluation\\n\",\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"eval_n = 40\\n\",\n    \"eval_preds = get_eval_preds(train_prompt_with_context, train_str, eval_df, n=eval_n)\"\n   ]\n  },\n  {\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 19, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "20": {"text": "n=eval_n)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 28,\n   \"id\": \"7424e7d3-2576-42bc-b626-cf8088265004\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.85\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"eval_label_chunk = eval_labels[:eval_n]\\n\",\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e010b497-eeed-4142-a8ac-f5545e85fcc2\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 20, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "21": {"text": " }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"gpt_retrieve_venv\",\n   \"language\": \"python\",\n   \"name\": \"gpt_retrieve_venv\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.4\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 21, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "22": {"text": "This code file is a demonstration of how to use GPT-3 to attain ~80% accuracy on the Titanic dataset. It uses the utils module to get the training and evaluation data, and then uses the train_prompt module to provide a few example inputs. It then uses the get_eval_preds function to get the evaluation predictions and the accuracy_score module from sklearn to calculate the accuracy. Finally, it prints out the example datapoints in the train_str.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses a GPT List Index to store and query data, and uses the sklearn library to calculate accuracy scores. The code builds an index of training data, queries the index with a given prompt string, and then uses the response to make predictions on a set of evaluation data. The accuracy of the predictions is then calculated and printed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ref_doc_id": null, "node_info": null}, "24": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets.", "doc_id": null, "embedding": null, "extra_info": null, "index": 24, "child_indices": [20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file is a demonstration of how to use GPT-3 to attain ~80% accuracy on the Titanic dataset. It uses the utils module to get the training and evaluation data, and then uses the train_prompt module to provide a few example inputs. It then uses the get_eval_preds function to get the evaluation predictions and the accuracy_score module from sklearn to calculate the accuracy. Finally, it prints out the example datapoints in the train_str.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses a GPT List Index to store and query data, and uses the sklearn library to calculate accuracy scores. The code builds an index of training data, queries the index with a given prompt string, and then uses the response to make predictions on a set of evaluation data. The accuracy of the predictions is then calculated and printed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ref_doc_id": null, "node_info": null}, "24": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets.", "doc_id": null, "embedding": null, "extra_info": null, "index": 24, "child_indices": [20, 21], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"09e8676ed9c2cd06b8836e56e3473f5b54e05398": {"text": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"id\": \"f445c1d1-acb9-431e-a7ff-50c41f064359\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stderr\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\\n\",\n      \"[nltk_data] Downloading package stopwords to\\n\",\n      \"[nltk_data]     /Users/jerryliu/nltk_data...\\n\",\n      \"[nltk_data]   Package stopwords is already up-to-date!\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"from utils import (\\n\",\n    \"    get_train_str,\\n\",\n    \"    get_train_and_eval_data,\\n\",\n    \"    get_eval_preds,\\n\",\n    \"    train_prompt\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"import warnings\\n\",\n    \"warnings.filterwarnings('ignore')\\n\",\n    \"warnings.simplefilter('ignore')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 2,\n   \"id\": \"cf3cbd90-d5e1-4c30-a3bc-8b39fbd85d70\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# load up the titanic data\\n\",\n    \"train_df, train_labels, eval_df, eval_labels = get_train_and_eval_data('data/train.csv')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"fa2634f9-cb33-4f1e-81f9-3a3b285e2580\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Few-shot Prompting with GPT-3 for Titanic Dataset\\n\",\n    \"In this section, we can show how we can prompt GPT-3 on its own (without using GPT Index) to attain ~80% accuracy on Titanic! \\n\",\n    \"\\n\",\n    \"We can do this by simply providing a few example inputs. Or we can simply provide no example inputs at all (zero-shot). Both achieve the same results.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"id\": \"d0698fd2-1361-49ae-8c17-8124e9b932a4\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"Some example datapoints are given below: \\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# first demonstrate the prompt template\\n\",\n    \"print(train_prompt.template)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 4,\n   \"id\": \"4b39e2e7-be07-42f8-a27a-3419e84cfb2c\",\n   \"metadata\": {\n    \"scrolled\": true,\n    \"tags\": []\n   },\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Example datapoints in `train_str`: \\n\",\n      \"This is the Data:\\n\",\n      \"Age:28.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.8958\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:17.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:2\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:4\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:30.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:16.1\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:22.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.25\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:45.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:13.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:25.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:0.0\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:18.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:20.2125\\n\",\n      \"Parch:1\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:33.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:9.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:24.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:65.0\\n\",\n      \"Parch:2\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:26.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# Get \\\"training\\\" prompt string \\n\",\n    \"train_n = 10\\n\",\n    \"eval_n = 40\\n\",\n    \"train_str = get_train_str(train_df, train_labels, train_n=train_n)\\n\",\n    \"print(f\\\"Example datapoints in `train_str`: \\\\n{train_str}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"819a06f7-3171-4edb-b90c-0a3eae308a04\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with the training prompt string\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"4a7f2202-518c-41a3-80ab-1e98bbcca903\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds = get_eval_preds(train_prompt, train_str, eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"id\": \"64323a4d-6eea-4e40-9eac-b2deed60192b\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"11790d28-8f34-42dd-b11f-6aad21fd5f46\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with no training prompt string! \"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"aaf993e5-c363-4f18-a28f-09761e49cb6d\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds_null = get_eval_preds(train_prompt, \\\"\\\", eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 11,\n   \"id\": \"c3b8bcd5-5972-4ce5-9aa1-57460cdde199\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc_null = accuracy_score(eval_label_chunk, np.array(eval_preds_null).round())\\n\",\n    \"print(f'ACCURACY: {acc_null}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"8f0a5e4b-e627-4b47-a807-939813596594\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Extending with GPT List Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"42a1ca28-96e9-4cd2-bd48-0673917ad057\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Build Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 12,\n   \"id\": \"6c59b030-855d-4e27-89c3-74c972d1bf19\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from gpt_index import GPTListIndex\\n\",\n    \"from gpt_index.readers.schema.base import Document\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 13,\n   \"id\": \"8f9556de-e323-4318-bb71-cff75bf8c3c1\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"index = GPTListIndex([])\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e27720fc-af36-40fd-8c55-41485248aa9f\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# insertion into index \\n\",\n    \"batch_size = 40\\n\",\n    \"num_train_chunks = 5\\n\",\n    \"\\n\",\n    \"for i in range(num_train_chunks):\\n\",\n    \"    print(f\\\"Inserting chunk: {i}/{num_train_chunks}\\\")\\n\",\n    \"    start_idx = i*batch_size\\n\",\n    \"    end_idx = (i+1)*batch_size\\n\",\n    \"    train_batch = train_df.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    labels_batch = train_labels.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    all_train_str = get_train_str(train_batch, labels_batch, train_n=batch_size)\\n\",\n    \"    index.insert(Document(all_train_str))\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"e78db088-6649-44db-b52a-766316713b96\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Query Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 15,\n   \"id\": \"9cb90564-1de2-412f-8318-d5280855004e\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from utils import query_str, qa_data_prompt, refine_prompt\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 16,\n   \"id\": \"77c1ae36-e0af-47bc-a656-4971af699755\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"'Which is the relationship between these features and predicting survival?'\"\n      ]\n     },\n     \"execution_count\": 16,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"query_str\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 17,\n   \"id\": \"c403710f-d4b3-4287-94f5-e275ea19b476\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"> Starting query: Which is the relationship between these features and predicting survival?\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"response = index.query(\\n\",\n    \"    query_str, \\n\",\n    \"    text_qa_template=qa_data_prompt, \\n\",\n    \"    refine_template=refine_prompt, \\n\",\n    \")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 19,\n   \"id\": \"d2545ab1-980a-4fbd-8add-7ef957801644\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"\\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"print(response)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"d0d7d260-2283-49f6-ac40-35c7071cc54d\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Get Predictions and Evaluate\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 26,\n   \"id\": \"e7b98057-957c-48ef-be85-59ff9813d201\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"We discovered the following relationship between features and survival:\\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. \\n\",\n      \"Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\",\n      \"\\n\",\n      \"\\n\",\n      \"`train_str`: \\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# get eval preds\\n\",\n    \"from utils import train_prompt_with_context\\n\",\n    \"\\n\",\n    \"train_str = response\\n\",\n    \"print(train_prompt_with_context.template)\\n\",\n    \"print(f'\\\\n\\\\n`train_str`: {train_str}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"659c6a3f-1c5d-4314-87dc-908e76d50e4a\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# do evaluation\\n\",\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"eval_n = 40\\n\",\n    \"eval_preds = get_eval_preds(train_prompt_with_context, train_str, eval_df, n=eval_n)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 28,\n   \"id\": \"7424e7d3-2576-42bc-b626-cf8088265004\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.85\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"eval_label_chunk = eval_labels[:eval_n]\\n\",\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e010b497-eeed-4142-a8ac-f5545e85fcc2\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"gpt_retrieve_venv\",\n   \"language\": \"python\",\n   \"name\": \"gpt_retrieve_venv\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.4\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n", "doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "__type__": "Document"}, "cd8b0452-85f1-46e1-a754-d56d2ed40f8e": {"text": "\nThis code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The GPT List Index is used to store and query the data, and the get_eval_preds function is used to get the evaluation predictions. The accuracy_score module from sklearn is used to calculate the accuracy of the predictions. The code is designed to provide a way to predict survival on the Titanic with an accuracy of around 80%. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets. The code uses the utils module to get the training and evaluation data, and then uses GPT-3 to prompt the model with a few example inputs. The code also provides a prompt template to demonstrate how GPT-3 can be used to attain ~80% accuracy on the Titanic dataset.", "doc_id": "cd8b0452-85f1-46e1-a754-d56d2ed40f8e", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"id\": \"f445c1d1-acb9-431e-a7ff-50c41f064359\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stderr\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\\n\",\n      \"[nltk_data] Downloading package stopwords to\\n\",\n      \"[nltk_data]     /Users/jerryliu/nltk_data...\\n\",\n      \"[nltk_data]   Package stopwords is already up-to-date!\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"from utils import (\\n\",\n    \"    get_train_str,\\n\",\n    \"    get_train_and_eval_data,\\n\",\n    \"   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 0, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "1": {"text": "   \"    get_eval_preds,\\n\",\n    \"    train_prompt\\n\",\n    \")\\n\",\n    \"\\n\",\n    \"import warnings\\n\",\n    \"warnings.filterwarnings('ignore')\\n\",\n    \"warnings.simplefilter('ignore')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 2,\n   \"id\": \"cf3cbd90-d5e1-4c30-a3bc-8b39fbd85d70\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# load up the titanic data\\n\",\n    \"train_df, train_labels, eval_df, eval_labels = get_train_and_eval_data('data/train.csv')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"fa2634f9-cb33-4f1e-81f9-3a3b285e2580\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Few-shot Prompting with GPT-3 for Titanic Dataset\\n\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 1, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "2": {"text": "Prompting with GPT-3 for Titanic Dataset\\n\",\n    \"In this section, we can show how we can prompt GPT-3 on its own (without using GPT Index) to attain ~80% accuracy on Titanic! \\n\",\n    \"\\n\",\n    \"We can do this by simply providing a few example inputs. Or we can simply provide no example inputs at all (zero-shot). Both achieve the same results.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"id\": \"d0698fd2-1361-49ae-8c17-8124e9b932a4\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"Some example datapoints are given below: \\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 2, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "3": {"text": "\"Some example datapoints are given below: \\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# first demonstrate the prompt template\\n\",\n    \"print(train_prompt.template)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 4,\n   \"id\": \"4b39e2e7-be07-42f8-a27a-3419e84cfb2c\",\n   \"metadata\": {\n    \"scrolled\": true,\n    \"tags\": []\n   },\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"Example datapoints in `train_str`: \\n\",\n      \"This is the Data:\\n\",\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 3, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "4": {"text": "\\n\",\n      \"This is the Data:\\n\",\n      \"Age:28.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.8958\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:17.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:2\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:4\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:30.0\\n\",\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 4, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "5": {"text": "     \"Age:30.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:16.1\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:22.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.25\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:45.0\\n\",\n      \"Embarked:S\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 5, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "6": {"text": "     \"Embarked:S\\n\",\n      \"Fare:13.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:25.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:0.0\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:18.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:20.2125\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 6, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "7": {"text": "   \"Fare:20.2125\\n\",\n      \"Parch:1\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:33.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:9.5\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:male\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 0\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:24.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:65.0\\n\",\n      \"Parch:2\\n\",\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 7, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "8": {"text": "     \"Parch:2\\n\",\n      \"Pclass:2\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:1\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\",\n      \"\\n\",\n      \"This is the Data:\\n\",\n      \"Age:26.0\\n\",\n      \"Embarked:S\\n\",\n      \"Fare:7.925\\n\",\n      \"Parch:0\\n\",\n      \"Pclass:3\\n\",\n      \"Sex:female\\n\",\n      \"SibSp:0\\n\",\n      \"This is the correct answer:\\n\",\n      \"Survived: 1\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# Get \\\"training\\\" prompt string \\n\",\n    \"train_n = 10\\n\",\n    \"eval_n = 40\\n\",\n    \"train_str = get_train_str(train_df, train_labels, train_n=train_n)\\n\",\n    \"print(f\\\"Example", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 8, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "9": {"text": "train_n=train_n)\\n\",\n    \"print(f\\\"Example datapoints in `train_str`: \\\\n{train_str}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"819a06f7-3171-4edb-b90c-0a3eae308a04\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with the training prompt string\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"4a7f2202-518c-41a3-80ab-1e98bbcca903\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds = get_eval_preds(train_prompt, train_str, eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 9, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "10": {"text": "  \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"id\": \"64323a4d-6eea-4e40-9eac-b2deed60192b\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"11790d28-8f34-42dd-b11f-6aad21fd5f46\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Do evaluation with no training prompt string! \"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 10, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "11": {"text": "\"code\",\n   \"execution_count\": null,\n   \"id\": \"aaf993e5-c363-4f18-a28f-09761e49cb6d\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"\\n\",\n    \"eval_preds_null = get_eval_preds(train_prompt, \\\"\\\", eval_df, n=eval_n)\\n\",\n    \"eval_label_chunk = eval_labels[:eval_n]\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 11,\n   \"id\": \"c3b8bcd5-5972-4ce5-9aa1-57460cdde199\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.8\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"acc_null =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 11, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "12": {"text": "  ],\n   \"source\": [\n    \"acc_null = accuracy_score(eval_label_chunk, np.array(eval_preds_null).round())\\n\",\n    \"print(f'ACCURACY: {acc_null}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"8f0a5e4b-e627-4b47-a807-939813596594\",\n   \"metadata\": {\n    \"tags\": []\n   },\n   \"source\": [\n    \"## Extending with GPT List Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"42a1ca28-96e9-4cd2-bd48-0673917ad057\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Build Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 12,\n   \"id\": \"6c59b030-855d-4e27-89c3-74c972d1bf19\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from gpt_index import GPTListIndex\\n\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 12, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "13": {"text": "[\n    \"from gpt_index import GPTListIndex\\n\",\n    \"from gpt_index.readers.schema.base import Document\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 13,\n   \"id\": \"8f9556de-e323-4318-bb71-cff75bf8c3c1\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"index = GPTListIndex([])\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e27720fc-af36-40fd-8c55-41485248aa9f\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# insertion into index \\n\",\n    \"batch_size = 40\\n\",\n    \"num_train_chunks = 5\\n\",\n    \"\\n\",\n    \"for i in range(num_train_chunks):\\n\",\n    \"    print(f\\\"Inserting chunk: {i}/{num_train_chunks}\\\")\\n\",\n    \"    start_idx =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 13, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "14": {"text": "   \"    start_idx = i*batch_size\\n\",\n    \"    end_idx = (i+1)*batch_size\\n\",\n    \"    train_batch = train_df.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    labels_batch = train_labels.iloc[start_idx:end_idx+batch_size]\\n\",\n    \"    all_train_str = get_train_str(train_batch, labels_batch, train_n=batch_size)\\n\",\n    \"    index.insert(Document(all_train_str))\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"e78db088-6649-44db-b52a-766316713b96\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Query Index\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 15,\n   \"id\": \"9cb90564-1de2-412f-8318-d5280855004e\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"from utils import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 14, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "15": {"text": "[],\n   \"source\": [\n    \"from utils import query_str, qa_data_prompt, refine_prompt\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 16,\n   \"id\": \"77c1ae36-e0af-47bc-a656-4971af699755\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"'Which is the relationship between these features and predicting survival?'\"\n      ]\n     },\n     \"execution_count\": 16,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"query_str\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 17,\n   \"id\": \"c403710f-d4b3-4287-94f5-e275ea19b476\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 15, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "16": {"text": "\"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"> Starting query: Which is the relationship between these features and predicting survival?\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"response = index.query(\\n\",\n    \"    query_str, \\n\",\n    \"    text_qa_template=qa_data_prompt, \\n\",\n    \"    refine_template=refine_prompt, \\n\",\n    \")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 19,\n   \"id\": \"d2545ab1-980a-4fbd-8add-7ef957801644\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"\\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 16, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "17": {"text": "depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"print(response)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"id\": \"d0d7d260-2283-49f6-ac40-35c7071cc54d\",\n   \"metadata\": {},\n   \"source\": [\n    \"#### Get Predictions and Evaluate\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 26,\n   \"id\": \"e7b98057-957c-48ef-be85-59ff9813d201\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"The following structured data is provided in \\\"Feature Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 17, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "18": {"text": "Name\\\":\\\"Feature Value\\\" format.\\n\",\n      \"Each datapoint describes a passenger on the Titanic.\\n\",\n      \"The task is to decide whether the passenger survived.\\n\",\n      \"We discovered the following relationship between features and survival:\\n\",\n      \"-------------------\\n\",\n      \"{train_str}\\n\",\n      \"-------------------\\n\",\n      \"Given this, predict whether the following passenger survived. \\n\",\n      \"Return answer as a number between 0 or 1. \\n\",\n      \"{eval_str}\\n\",\n      \"Survived: \\n\",\n      \"\\n\",\n      \"\\n\",\n      \"`train_str`: \\n\",\n      \"\\n\",\n      \"There is no definitive answer to this question, as the relationship between the features and predicting survival will vary depending on the data. However, some possible relationships include: age (younger passengers are more likely to survive), sex (females are more likely to survive), fare (passengers who paid more for their ticket are more likely to survive), and pclass (passengers in first or second class are more likely to", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 18, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "19": {"text": "likely to survive), and pclass (passengers in first or second class are more likely to survive).\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"# get eval preds\\n\",\n    \"from utils import train_prompt_with_context\\n\",\n    \"\\n\",\n    \"train_str = response\\n\",\n    \"print(train_prompt_with_context.template)\\n\",\n    \"print(f'\\\\n\\\\n`train_str`: {train_str}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"659c6a3f-1c5d-4314-87dc-908e76d50e4a\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"# do evaluation\\n\",\n    \"from sklearn.metrics import accuracy_score\\n\",\n    \"import numpy as np\\n\",\n    \"eval_n = 40\\n\",\n    \"eval_preds = get_eval_preds(train_prompt_with_context, train_str, eval_df, n=eval_n)\"\n   ]\n  },\n  {\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 19, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "20": {"text": "n=eval_n)\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 28,\n   \"id\": \"7424e7d3-2576-42bc-b626-cf8088265004\",\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ACCURACY: 0.85\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"eval_label_chunk = eval_labels[:eval_n]\\n\",\n    \"acc = accuracy_score(eval_label_chunk, np.array(eval_preds).round())\\n\",\n    \"print(f'ACCURACY: {acc}')\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"id\": \"e010b497-eeed-4142-a8ac-f5545e85fcc2\",\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 20, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "21": {"text": " }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"gpt_retrieve_venv\",\n   \"language\": \"python\",\n   \"name\": \"gpt_retrieve_venv\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.4\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 5\n}\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/TitanicModel.ipynb", "file_name": "TitanicModel.ipynb"}, "index": 21, "child_indices": [], "ref_doc_id": "09e8676ed9c2cd06b8836e56e3473f5b54e05398", "node_info": null}, "22": {"text": "This code file is a demonstration of how to use GPT-3 to attain ~80% accuracy on the Titanic dataset. It uses the utils module to get the training and evaluation data, and then uses the train_prompt module to provide a few example inputs. It then uses the get_eval_preds function to get the evaluation predictions and the accuracy_score module from sklearn to calculate the accuracy. Finally, it prints out the example datapoints in the train_str.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses a GPT List Index to store and query data, and uses the sklearn library to calculate accuracy scores. The code builds an index of training data, queries the index with a given prompt string, and then uses the response to make predictions on a set of evaluation data. The accuracy of the predictions is then calculated and printed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ref_doc_id": null, "node_info": null}, "24": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets.", "doc_id": null, "embedding": null, "extra_info": null, "index": 24, "child_indices": [20, 21], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"22": {"text": "This code file is a demonstration of how to use GPT-3 to attain ~80% accuracy on the Titanic dataset. It uses the utils module to get the training and evaluation data, and then uses the train_prompt module to provide a few example inputs. It then uses the get_eval_preds function to get the evaluation predictions and the accuracy_score module from sklearn to calculate the accuracy. Finally, it prints out the example datapoints in the train_str.", "doc_id": null, "embedding": null, "extra_info": null, "index": 22, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "23": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses a GPT List Index to store and query data, and uses the sklearn library to calculate accuracy scores. The code builds an index of training data, queries the index with a given prompt string, and then uses the response to make predictions on a set of evaluation data. The accuracy of the predictions is then calculated and printed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 23, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "ref_doc_id": null, "node_info": null}, "24": {"text": "This code file is a machine learning model for predicting survival on the Titanic. It uses the scikit-learn library to train a logistic regression model on a dataset of Titanic passenger data. The model is evaluated using a test set of data, and the accuracy of the model is printed out. The code also includes functions for loading the data, preprocessing it, and splitting it into training and evaluation sets.", "doc_id": null, "embedding": null, "extra_info": null, "index": 24, "child_indices": [20, 21], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}