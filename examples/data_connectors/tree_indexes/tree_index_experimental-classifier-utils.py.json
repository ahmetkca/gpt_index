{"index_struct": {"text": "\nThis code file provides a framework for running GPT-3 experiments on the Titanic dataset. It contains functions for getting train and eval data, extracting float values from responses, getting eval preds, and creating prompts for GPT-3. Data structures such as dictionaries and pandas DataFrames are used, and algorithms such as train-test split and regular expression matching are employed. The purpose of the code is to provide an easy way to create and run experiments with GPT-3 on the Titanic dataset.", "doc_id": "7fa9b844-5c8e-4863-b230-f6fe5b6703ec", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Helper functions for Titanic GPT-3 experiments.\"\"\"\n\n# form prompt, run GPT\nimport re\nfrom typing import List, Optional, Tuple\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom gpt_index.indices.utils import extract_numbers_given_response\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\n\n\ndef get_train_and_eval_data(\n    csv_path: str,\n) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n    \"\"\"Get train and eval data.\"\"\"\n    df = pd.read_csv(csv_path)\n    label_col = \"Survived\"\n    cols_to_drop = [\"PassengerId\", \"Ticket\", \"Name\", \"Cabin\"]\n    df = df.drop(cols_to_drop, axis=1)\n    labels = df.pop(label_col)\n    train_df, eval_df, train_labels, eval_labels = train_test_split(\n        df, labels, test_size=0.25, random_state=0\n    )\n    return train_df, train_labels, eval_df, eval_labels\n\n\ndef", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "1": {"text": "train_df, train_labels, eval_df, eval_labels\n\n\ndef get_sorted_dict_str(d: dict) -> str:\n    \"\"\"Get sorted dict string.\"\"\"\n    keys = sorted(list(d.keys()))\n    return \"\\n\".join([f\"{k}:{d[k]}\" for k in keys])\n\n\ndef get_label_str(labels: pd.Series, i: int) -> str:\n    \"\"\"Get label string.\"\"\"\n    return f\"{labels.name}: {labels.iloc[i]}\"\n\n\ndef get_train_str(\n    train_df: pd.DataFrame, train_labels: pd.Series, train_n: int = 10\n) -> str:\n    \"\"\"Get train str.\"\"\"\n    dict_list = train_df.to_dict(\"records\")[:train_n]\n    item_list = []\n    for i, d in enumerate(dict_list):\n        dict_str = get_sorted_dict_str(d)\n        label_str = get_label_str(train_labels, i)\n        item_str = (\n            f\"This is the Data:\\n{dict_str}\\nThis is the correct answer:\\n{label_str}\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "2": {"text": "is the correct answer:\\n{label_str}\"\n        )\n        item_list.append(item_str)\n\n    return \"\\n\\n\".join(item_list)\n\n\ndef extract_float_given_response(response: str, n: int = 1) -> Optional[float]:\n    \"\"\"Extract number given the GPT-generated response.\n\n    Used by tree-structured indices.\n\n    \"\"\"\n    numbers = re.findall(r\"\\d+\\.\\d+\", response)\n    if len(numbers) == 0:\n        # if no floats, try extracting ints, and convert to float\n        new_numbers = extract_numbers_given_response(response, n=n)\n        if new_numbers is None:\n            return None\n        else:\n            return float(numbers[0])\n    else:\n        return float(numbers[0])\n\n\ndef get_eval_preds(\n    train_prompt: Prompt, train_str: str, eval_df: pd.DataFrame, n: int = 20\n) -> List:\n    \"\"\"Get eval preds.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "3": {"text": "-> List:\n    \"\"\"Get eval preds.\"\"\"\n    llm_predictor = LLMPredictor()\n    eval_preds = []\n    for i in range(n):\n        eval_str = get_sorted_dict_str(eval_df.iloc[i].to_dict())\n        response, _ = llm_predictor.predict(\n            train_prompt, train_str=train_str, eval_str=eval_str\n        )\n        pred = extract_float_given_response(response)\n        print(f\"Getting preds: {i}/{n}: {pred}\")\n        if pred is None:\n            # something went wrong, impute a 0.5\n            eval_preds.append(0.5)\n        else:\n            eval_preds.append(pred)\n    return eval_preds\n\n\n# default train prompt\n\ntrain_prompt_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "4": {"text": "Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_str\n)\n\n\n# prompt to summarize the data\nquery_str = \"Which is the relationship between these features and predicting survival?\"\nqa_data_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "5": {"text": "given below: \\n\"\n    \"-------------------\\n\"\n    \"{context_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, answer the question: {query_str}\"\n)\n\nqa_data_prompt = Prompt(\n    input_variables=[\"context_str\", \"query_str\"], template=qa_data_str\n)\n\n# prompt to refine the answer\nrefine_str = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more datapoints below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nrefine_prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "6": {"text": "isn't useful, return the original answer.\"\n)\nrefine_prompt = Prompt(\n    input_variables=[\"query_str\", \"existing_answer\", \"context_msg\"],\n    template=refine_str,\n)\n\n\n# train prompt with refined context\n\ntrain_prompt_with_context_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We discovered the following relationship between features and survival:\\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \\n\"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt_with_context = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_with_context_str\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "7": {"text": "This code file contains helper functions for Titanic GPT-3 experiments. It includes functions to get train and eval data, extract float given response, get eval preds, and create prompts for GPT-3. The purpose of the code is to provide a framework for GPT-3 experiments on the Titanic dataset. It uses data structures such as dictionaries and pandas DataFrames, and algorithms such as train-test split and regular expression matching.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains helper functions for Titanic GPT-3 experiments. It includes functions to get train and eval data, extract float given response, get eval preds, and create prompts for GPT-3. The purpose of the code is to provide a framework for GPT-3 experiments on the Titanic dataset. It uses data structures such as dictionaries and pandas DataFrames, and algorithms such as train-test split and regular expression matching.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"ee8ec9935ad93ab3a4e6b42017174b65c2d21de5": {"text": "\"\"\"Helper functions for Titanic GPT-3 experiments.\"\"\"\n\n# form prompt, run GPT\nimport re\nfrom typing import List, Optional, Tuple\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom gpt_index.indices.utils import extract_numbers_given_response\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\n\n\ndef get_train_and_eval_data(\n    csv_path: str,\n) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n    \"\"\"Get train and eval data.\"\"\"\n    df = pd.read_csv(csv_path)\n    label_col = \"Survived\"\n    cols_to_drop = [\"PassengerId\", \"Ticket\", \"Name\", \"Cabin\"]\n    df = df.drop(cols_to_drop, axis=1)\n    labels = df.pop(label_col)\n    train_df, eval_df, train_labels, eval_labels = train_test_split(\n        df, labels, test_size=0.25, random_state=0\n    )\n    return train_df, train_labels, eval_df, eval_labels\n\n\ndef get_sorted_dict_str(d: dict) -> str:\n    \"\"\"Get sorted dict string.\"\"\"\n    keys = sorted(list(d.keys()))\n    return \"\\n\".join([f\"{k}:{d[k]}\" for k in keys])\n\n\ndef get_label_str(labels: pd.Series, i: int) -> str:\n    \"\"\"Get label string.\"\"\"\n    return f\"{labels.name}: {labels.iloc[i]}\"\n\n\ndef get_train_str(\n    train_df: pd.DataFrame, train_labels: pd.Series, train_n: int = 10\n) -> str:\n    \"\"\"Get train str.\"\"\"\n    dict_list = train_df.to_dict(\"records\")[:train_n]\n    item_list = []\n    for i, d in enumerate(dict_list):\n        dict_str = get_sorted_dict_str(d)\n        label_str = get_label_str(train_labels, i)\n        item_str = (\n            f\"This is the Data:\\n{dict_str}\\nThis is the correct answer:\\n{label_str}\"\n        )\n        item_list.append(item_str)\n\n    return \"\\n\\n\".join(item_list)\n\n\ndef extract_float_given_response(response: str, n: int = 1) -> Optional[float]:\n    \"\"\"Extract number given the GPT-generated response.\n\n    Used by tree-structured indices.\n\n    \"\"\"\n    numbers = re.findall(r\"\\d+\\.\\d+\", response)\n    if len(numbers) == 0:\n        # if no floats, try extracting ints, and convert to float\n        new_numbers = extract_numbers_given_response(response, n=n)\n        if new_numbers is None:\n            return None\n        else:\n            return float(numbers[0])\n    else:\n        return float(numbers[0])\n\n\ndef get_eval_preds(\n    train_prompt: Prompt, train_str: str, eval_df: pd.DataFrame, n: int = 20\n) -> List:\n    \"\"\"Get eval preds.\"\"\"\n    llm_predictor = LLMPredictor()\n    eval_preds = []\n    for i in range(n):\n        eval_str = get_sorted_dict_str(eval_df.iloc[i].to_dict())\n        response, _ = llm_predictor.predict(\n            train_prompt, train_str=train_str, eval_str=eval_str\n        )\n        pred = extract_float_given_response(response)\n        print(f\"Getting preds: {i}/{n}: {pred}\")\n        if pred is None:\n            # something went wrong, impute a 0.5\n            eval_preds.append(0.5)\n        else:\n            eval_preds.append(pred)\n    return eval_preds\n\n\n# default train prompt\n\ntrain_prompt_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_str\n)\n\n\n# prompt to summarize the data\nquery_str = \"Which is the relationship between these features and predicting survival?\"\nqa_data_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n    \"{context_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, answer the question: {query_str}\"\n)\n\nqa_data_prompt = Prompt(\n    input_variables=[\"context_str\", \"query_str\"], template=qa_data_str\n)\n\n# prompt to refine the answer\nrefine_str = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more datapoints below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nrefine_prompt = Prompt(\n    input_variables=[\"query_str\", \"existing_answer\", \"context_msg\"],\n    template=refine_str,\n)\n\n\n# train prompt with refined context\n\ntrain_prompt_with_context_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We discovered the following relationship between features and survival:\\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \\n\"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt_with_context = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_with_context_str\n)\n", "doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "__type__": "Document"}, "7fa9b844-5c8e-4863-b230-f6fe5b6703ec": {"text": "\nThis code file provides a framework for running GPT-3 experiments on the Titanic dataset. It contains functions for getting train and eval data, extracting float values from responses, getting eval preds, and creating prompts for GPT-3. Data structures such as dictionaries and pandas DataFrames are used, and algorithms such as train-test split and regular expression matching are employed. The purpose of the code is to provide an easy way to create and run experiments with GPT-3 on the Titanic dataset.", "doc_id": "7fa9b844-5c8e-4863-b230-f6fe5b6703ec", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Helper functions for Titanic GPT-3 experiments.\"\"\"\n\n# form prompt, run GPT\nimport re\nfrom typing import List, Optional, Tuple\n\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfrom gpt_index.indices.utils import extract_numbers_given_response\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\n\n\ndef get_train_and_eval_data(\n    csv_path: str,\n) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n    \"\"\"Get train and eval data.\"\"\"\n    df = pd.read_csv(csv_path)\n    label_col = \"Survived\"\n    cols_to_drop = [\"PassengerId\", \"Ticket\", \"Name\", \"Cabin\"]\n    df = df.drop(cols_to_drop, axis=1)\n    labels = df.pop(label_col)\n    train_df, eval_df, train_labels, eval_labels = train_test_split(\n        df, labels, test_size=0.25, random_state=0\n    )\n    return train_df, train_labels, eval_df, eval_labels\n\n\ndef", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "1": {"text": "train_df, train_labels, eval_df, eval_labels\n\n\ndef get_sorted_dict_str(d: dict) -> str:\n    \"\"\"Get sorted dict string.\"\"\"\n    keys = sorted(list(d.keys()))\n    return \"\\n\".join([f\"{k}:{d[k]}\" for k in keys])\n\n\ndef get_label_str(labels: pd.Series, i: int) -> str:\n    \"\"\"Get label string.\"\"\"\n    return f\"{labels.name}: {labels.iloc[i]}\"\n\n\ndef get_train_str(\n    train_df: pd.DataFrame, train_labels: pd.Series, train_n: int = 10\n) -> str:\n    \"\"\"Get train str.\"\"\"\n    dict_list = train_df.to_dict(\"records\")[:train_n]\n    item_list = []\n    for i, d in enumerate(dict_list):\n        dict_str = get_sorted_dict_str(d)\n        label_str = get_label_str(train_labels, i)\n        item_str = (\n            f\"This is the Data:\\n{dict_str}\\nThis is the correct answer:\\n{label_str}\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "2": {"text": "is the correct answer:\\n{label_str}\"\n        )\n        item_list.append(item_str)\n\n    return \"\\n\\n\".join(item_list)\n\n\ndef extract_float_given_response(response: str, n: int = 1) -> Optional[float]:\n    \"\"\"Extract number given the GPT-generated response.\n\n    Used by tree-structured indices.\n\n    \"\"\"\n    numbers = re.findall(r\"\\d+\\.\\d+\", response)\n    if len(numbers) == 0:\n        # if no floats, try extracting ints, and convert to float\n        new_numbers = extract_numbers_given_response(response, n=n)\n        if new_numbers is None:\n            return None\n        else:\n            return float(numbers[0])\n    else:\n        return float(numbers[0])\n\n\ndef get_eval_preds(\n    train_prompt: Prompt, train_str: str, eval_df: pd.DataFrame, n: int = 20\n) -> List:\n    \"\"\"Get eval preds.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "3": {"text": "-> List:\n    \"\"\"Get eval preds.\"\"\"\n    llm_predictor = LLMPredictor()\n    eval_preds = []\n    for i in range(n):\n        eval_str = get_sorted_dict_str(eval_df.iloc[i].to_dict())\n        response, _ = llm_predictor.predict(\n            train_prompt, train_str=train_str, eval_str=eval_str\n        )\n        pred = extract_float_given_response(response)\n        print(f\"Getting preds: {i}/{n}: {pred}\")\n        if pred is None:\n            # something went wrong, impute a 0.5\n            eval_preds.append(0.5)\n        else:\n            eval_preds.append(pred)\n    return eval_preds\n\n\n# default train prompt\n\ntrain_prompt_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "4": {"text": "Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_str\n)\n\n\n# prompt to summarize the data\nquery_str = \"Which is the relationship between these features and predicting survival?\"\nqa_data_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"Some example datapoints are given below: \\n\"\n    \"-------------------\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "5": {"text": "given below: \\n\"\n    \"-------------------\\n\"\n    \"{context_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, answer the question: {query_str}\"\n)\n\nqa_data_prompt = Prompt(\n    input_variables=[\"context_str\", \"query_str\"], template=qa_data_str\n)\n\n# prompt to refine the answer\nrefine_str = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more datapoints below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nrefine_prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "6": {"text": "isn't useful, return the original answer.\"\n)\nrefine_prompt = Prompt(\n    input_variables=[\"query_str\", \"existing_answer\", \"context_msg\"],\n    template=refine_str,\n)\n\n\n# train prompt with refined context\n\ntrain_prompt_with_context_str = (\n    \"The following structured data is provided in \"\n    '\"Feature Name\":\"Feature Value\" format.\\n'\n    \"Each datapoint describes a passenger on the Titanic.\\n\"\n    \"The task is to decide whether the passenger survived.\\n\"\n    \"We discovered the following relationship between features and survival:\\n\"\n    \"-------------------\\n\"\n    \"{train_str}\\n\"\n    \"-------------------\\n\"\n    \"Given this, predict whether the following passenger survived. \\n\"\n    \"Return answer as a number between 0 or 1. \\n\"\n    \"{eval_str}\\n\"\n    \"Survived: \"\n)\n\ntrain_prompt_with_context = Prompt(\n    input_variables=[\"train_str\", \"eval_str\"], template=train_prompt_with_context_str\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "experimental/classifier/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "ee8ec9935ad93ab3a4e6b42017174b65c2d21de5", "node_info": null}, "7": {"text": "This code file contains helper functions for Titanic GPT-3 experiments. It includes functions to get train and eval data, extract float given response, get eval preds, and create prompts for GPT-3. The purpose of the code is to provide a framework for GPT-3 experiments on the Titanic dataset. It uses data structures such as dictionaries and pandas DataFrames, and algorithms such as train-test split and regular expression matching.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains helper functions for Titanic GPT-3 experiments. It includes functions to get train and eval data, extract float given response, get eval preds, and create prompts for GPT-3. The purpose of the code is to provide a framework for GPT-3 experiments on the Titanic dataset. It uses data structures such as dictionaries and pandas DataFrames, and algorithms such as train-test split and regular expression matching.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}