{"index_struct": {"text": "\nThe code file graph.py contains the ComposableGraph class, which is used to create a graph of indices. It provides methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. The index registry stores the type to struct and type to query fields from the index class, allowing for efficient retrieval of data. The QueryRunner class is used to query the index, the PromptHelper class is used to generate prompts for the query, the LLMPredictor class is used to generate language models for the query, and the OpenAIEmbedding class is used to generate embeddings for the query. The purpose of the code is to provide a way to create a graph of indices, query the index, and save and load the index from a string or disk.", "doc_id": "d8d6ac7d-b92f-4182-a3b8-a04fe61ff8f3", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Composability graphs.\"\"\"\n\nimport json\nfrom typing import Any, Dict, List, Optional, Type, Union\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.docstore import DocumentStore\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.base import BaseGPTIndex\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.query_runner import QueryRunner\nfrom gpt_index.indices.query.schema import QueryConfig\nfrom gpt_index.indices.registry import IndexRegistry\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.indices.vector_store.faiss import GPTFaissIndex\nfrom gpt_index.indices.vector_store.pinecone import GPTPineconeIndex\nfrom gpt_index.indices.vector_store.qdrant import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 0, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "1": {"text": "gpt_index.indices.vector_store.qdrant import GPTQdrantIndex\nfrom gpt_index.indices.vector_store.simple import GPTSimpleVectorIndex\nfrom gpt_index.indices.vector_store.weaviate import GPTWeaviateIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.response.schema import Response\n\n# TMP: refactor query config type\nQUERY_CONFIG_TYPE = Union[Dict, QueryConfig]\n\n\n# this is a map from type to outer index class\n# we extract the type_to_struct and type_to_query\n# fields from the index class\nDEFAULT_INDEX_REGISTRY_MAP: Dict[IndexStructType, Type[BaseGPTIndex]] = {\n    IndexStructType.TREE: GPTTreeIndex,\n    IndexStructType.LIST: GPTListIndex,\n    IndexStructType.KEYWORD_TABLE: GPTKeywordTableIndex,\n    IndexStructType.DICT: GPTFaissIndex,\n    IndexStructType.SIMPLE_DICT: GPTSimpleVectorIndex,\n    IndexStructType.WEAVIATE: GPTWeaviateIndex,\n    IndexStructType.PINECONE: GPTPineconeIndex,\n    IndexStructType.QDRANT: GPTQdrantIndex,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 1, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "2": {"text": " IndexStructType.QDRANT: GPTQdrantIndex,\n    IndexStructType.SQL: GPTSQLStructStoreIndex,\n}\n\n\ndef _get_default_index_registry() -> IndexRegistry:\n    \"\"\"Get default index registry.\"\"\"\n    index_registry = IndexRegistry()\n    for index_type, index_class in DEFAULT_INDEX_REGISTRY_MAP.items():\n        index_registry.type_to_struct[index_type] = index_class.index_struct_cls\n        index_registry.type_to_query[index_type] = index_class.get_query_map()\n    return index_registry\n\n\ndef _safe_get_index_struct(\n    docstore: DocumentStore, index_struct_id: str\n) -> IndexStruct:\n    \"\"\"Try get index struct.\"\"\"\n    index_struct = docstore.get_document(index_struct_id)\n    if not isinstance(index_struct, IndexStruct):\n        raise ValueError(\"Invalid `index_struct_id` - must be an IndexStruct\")\n    return index_struct\n\n\nclass ComposableGraph:\n    \"\"\"Composable graph.\"\"\"\n\n    def __init__(\n        self,\n        docstore:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 2, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "3": {"text": "       self,\n        docstore: DocumentStore,\n        index_registry: IndexRegistry,\n        index_struct: IndexStruct,\n        llm_predictor: Optional[LLMPredictor] = None,\n        prompt_helper: Optional[PromptHelper] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        chunk_size_limit: Optional[int] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        self._docstore = docstore\n        self._index_registry = index_registry\n        # this represents the \"root\" index struct\n        self._index_struct = index_struct\n\n        self._llm_predictor = llm_predictor or LLMPredictor()\n        self._prompt_helper = prompt_helper or PromptHelper.from_llm_predictor(\n            self._llm_predictor, chunk_size_limit=chunk_size_limit\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 3, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "4": {"text": "       )\n        self._embed_model = embed_model or OpenAIEmbedding()\n\n    @classmethod\n    def build_from_index(self, index: BaseGPTIndex) -> \"ComposableGraph\":\n        \"\"\"Build from index.\"\"\"\n        return ComposableGraph(\n            index.docstore,\n            index.index_registry,\n            # this represents the \"root\" index struct\n            index.index_struct,\n            llm_predictor=index.llm_predictor,\n            prompt_helper=index.prompt_helper,\n            embed_model=index.embed_model,\n        )\n\n    def query(\n        self,\n        query_str: str,\n        query_configs: Optional[List[QUERY_CONFIG_TYPE]] = None,\n    ) -> Response:\n        \"\"\"Query the index.\"\"\"\n        # go over all the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 4, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "5": {"text": " \"\"\"Query the index.\"\"\"\n        # go over all the indices and create a registry\n        query_runner = QueryRunner(\n            self._llm_predictor,\n            self._prompt_helper,\n            self._embed_model,\n            self._docstore,\n            self._index_registry,\n            query_configs=query_configs,\n            recursive=True,\n        )\n        return query_runner.query(query_str, self._index_struct)\n\n    def get_index(\n        self, index_struct_id: str, index_cls: Type[BaseGPTIndex], **kwargs: Any\n    ) -> BaseGPTIndex:\n        \"\"\"Get index.\"\"\"\n        index_struct = _safe_get_index_struct(self._docstore, index_struct_id)\n        return index_cls(\n            index_struct=index_struct,\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 5, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "6": {"text": "     index_struct=index_struct,\n            docstore=self._docstore,\n            index_registry=self._index_registry,\n            **kwargs\n        )\n\n    @classmethod\n    def load_from_string(cls, index_string: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from string (in JSON-format).\n\n        This method loads the index from a JSON string. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        result_dict = json.loads(index_string)\n        # TODO: this is hardcoded for now, allow it to be specified by the user\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 6, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "7": {"text": "TODO: this is hardcoded for now, allow it to be specified by the user\n        index_registry = _get_default_index_registry()\n        docstore = DocumentStore.load_from_dict(\n            result_dict[\"docstore\"], index_registry.type_to_struct\n        )\n        index_struct = _safe_get_index_struct(docstore, result_dict[\"index_struct_id\"])\n        return cls(docstore, index_registry, index_struct, **kwargs)\n\n    @classmethod\n    def load_from_disk(cls, save_path: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 7, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "8": {"text": "(str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        with open(save_path, \"r\") as f:\n            file_contents = f.read()\n            return cls.load_from_string(file_contents, **kwargs)\n\n    def save_to_string(self, **save_kwargs: Any) -> str:\n        \"\"\"Save to string.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        out_dict: Dict[str, Any] = {\n            \"index_struct_id\": self._index_struct.get_doc_id(),\n            \"docstore\": self._docstore.serialize_to_dict(),\n        }\n        return json.dumps(out_dict)\n\n    def save_to_disk(self,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 8, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "9": {"text": "   def save_to_disk(self, save_path: str, **save_kwargs: Any) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        index_string = self.save_to_string(**save_kwargs)\n        with open(save_path, \"w\") as f:\n            f.write(index_string)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 9, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "10": {"text": "This code file contains the ComposableGraph class, which is used to create a composable graph of indices. It contains methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. It also contains a map from type to outer index class, which is used to create the index registry. The index registry is used to store the type to struct and type to query fields from the index class.\n", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file contains the ComposableGraph class, which is used to create a composable graph of indices. It contains methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. It also contains a map from type to outer index class, which is used to create the index registry. The index registry is used to store the type to struct and type to query fields from the index class.\n", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"90ca6826baf6988ea1d8f1c91b0cb85badcf00f4": {"text": "\"\"\"Composability graphs.\"\"\"\n\nimport json\nfrom typing import Any, Dict, List, Optional, Type, Union\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.docstore import DocumentStore\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.base import BaseGPTIndex\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.query_runner import QueryRunner\nfrom gpt_index.indices.query.schema import QueryConfig\nfrom gpt_index.indices.registry import IndexRegistry\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.indices.vector_store.faiss import GPTFaissIndex\nfrom gpt_index.indices.vector_store.pinecone import GPTPineconeIndex\nfrom gpt_index.indices.vector_store.qdrant import GPTQdrantIndex\nfrom gpt_index.indices.vector_store.simple import GPTSimpleVectorIndex\nfrom gpt_index.indices.vector_store.weaviate import GPTWeaviateIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.response.schema import Response\n\n# TMP: refactor query config type\nQUERY_CONFIG_TYPE = Union[Dict, QueryConfig]\n\n\n# this is a map from type to outer index class\n# we extract the type_to_struct and type_to_query\n# fields from the index class\nDEFAULT_INDEX_REGISTRY_MAP: Dict[IndexStructType, Type[BaseGPTIndex]] = {\n    IndexStructType.TREE: GPTTreeIndex,\n    IndexStructType.LIST: GPTListIndex,\n    IndexStructType.KEYWORD_TABLE: GPTKeywordTableIndex,\n    IndexStructType.DICT: GPTFaissIndex,\n    IndexStructType.SIMPLE_DICT: GPTSimpleVectorIndex,\n    IndexStructType.WEAVIATE: GPTWeaviateIndex,\n    IndexStructType.PINECONE: GPTPineconeIndex,\n    IndexStructType.QDRANT: GPTQdrantIndex,\n    IndexStructType.SQL: GPTSQLStructStoreIndex,\n}\n\n\ndef _get_default_index_registry() -> IndexRegistry:\n    \"\"\"Get default index registry.\"\"\"\n    index_registry = IndexRegistry()\n    for index_type, index_class in DEFAULT_INDEX_REGISTRY_MAP.items():\n        index_registry.type_to_struct[index_type] = index_class.index_struct_cls\n        index_registry.type_to_query[index_type] = index_class.get_query_map()\n    return index_registry\n\n\ndef _safe_get_index_struct(\n    docstore: DocumentStore, index_struct_id: str\n) -> IndexStruct:\n    \"\"\"Try get index struct.\"\"\"\n    index_struct = docstore.get_document(index_struct_id)\n    if not isinstance(index_struct, IndexStruct):\n        raise ValueError(\"Invalid `index_struct_id` - must be an IndexStruct\")\n    return index_struct\n\n\nclass ComposableGraph:\n    \"\"\"Composable graph.\"\"\"\n\n    def __init__(\n        self,\n        docstore: DocumentStore,\n        index_registry: IndexRegistry,\n        index_struct: IndexStruct,\n        llm_predictor: Optional[LLMPredictor] = None,\n        prompt_helper: Optional[PromptHelper] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        chunk_size_limit: Optional[int] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        self._docstore = docstore\n        self._index_registry = index_registry\n        # this represents the \"root\" index struct\n        self._index_struct = index_struct\n\n        self._llm_predictor = llm_predictor or LLMPredictor()\n        self._prompt_helper = prompt_helper or PromptHelper.from_llm_predictor(\n            self._llm_predictor, chunk_size_limit=chunk_size_limit\n        )\n        self._embed_model = embed_model or OpenAIEmbedding()\n\n    @classmethod\n    def build_from_index(self, index: BaseGPTIndex) -> \"ComposableGraph\":\n        \"\"\"Build from index.\"\"\"\n        return ComposableGraph(\n            index.docstore,\n            index.index_registry,\n            # this represents the \"root\" index struct\n            index.index_struct,\n            llm_predictor=index.llm_predictor,\n            prompt_helper=index.prompt_helper,\n            embed_model=index.embed_model,\n        )\n\n    def query(\n        self,\n        query_str: str,\n        query_configs: Optional[List[QUERY_CONFIG_TYPE]] = None,\n    ) -> Response:\n        \"\"\"Query the index.\"\"\"\n        # go over all the indices and create a registry\n        query_runner = QueryRunner(\n            self._llm_predictor,\n            self._prompt_helper,\n            self._embed_model,\n            self._docstore,\n            self._index_registry,\n            query_configs=query_configs,\n            recursive=True,\n        )\n        return query_runner.query(query_str, self._index_struct)\n\n    def get_index(\n        self, index_struct_id: str, index_cls: Type[BaseGPTIndex], **kwargs: Any\n    ) -> BaseGPTIndex:\n        \"\"\"Get index.\"\"\"\n        index_struct = _safe_get_index_struct(self._docstore, index_struct_id)\n        return index_cls(\n            index_struct=index_struct,\n            docstore=self._docstore,\n            index_registry=self._index_registry,\n            **kwargs\n        )\n\n    @classmethod\n    def load_from_string(cls, index_string: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from string (in JSON-format).\n\n        This method loads the index from a JSON string. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        result_dict = json.loads(index_string)\n        # TODO: this is hardcoded for now, allow it to be specified by the user\n        index_registry = _get_default_index_registry()\n        docstore = DocumentStore.load_from_dict(\n            result_dict[\"docstore\"], index_registry.type_to_struct\n        )\n        index_struct = _safe_get_index_struct(docstore, result_dict[\"index_struct_id\"])\n        return cls(docstore, index_registry, index_struct, **kwargs)\n\n    @classmethod\n    def load_from_disk(cls, save_path: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        with open(save_path, \"r\") as f:\n            file_contents = f.read()\n            return cls.load_from_string(file_contents, **kwargs)\n\n    def save_to_string(self, **save_kwargs: Any) -> str:\n        \"\"\"Save to string.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        out_dict: Dict[str, Any] = {\n            \"index_struct_id\": self._index_struct.get_doc_id(),\n            \"docstore\": self._docstore.serialize_to_dict(),\n        }\n        return json.dumps(out_dict)\n\n    def save_to_disk(self, save_path: str, **save_kwargs: Any) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        index_string = self.save_to_string(**save_kwargs)\n        with open(save_path, \"w\") as f:\n            f.write(index_string)\n", "doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "__type__": "Document"}, "d8d6ac7d-b92f-4182-a3b8-a04fe61ff8f3": {"text": "\nThe code file graph.py contains the ComposableGraph class, which is used to create a graph of indices. It provides methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. The index registry stores the type to struct and type to query fields from the index class, allowing for efficient retrieval of data. The QueryRunner class is used to query the index, the PromptHelper class is used to generate prompts for the query, the LLMPredictor class is used to generate language models for the query, and the OpenAIEmbedding class is used to generate embeddings for the query. The purpose of the code is to provide a way to create a graph of indices, query the index, and save and load the index from a string or disk.", "doc_id": "d8d6ac7d-b92f-4182-a3b8-a04fe61ff8f3", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Composability graphs.\"\"\"\n\nimport json\nfrom typing import Any, Dict, List, Optional, Type, Union\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.data_structs.struct_type import IndexStructType\nfrom gpt_index.docstore import DocumentStore\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.embeddings.openai import OpenAIEmbedding\nfrom gpt_index.indices.base import BaseGPTIndex\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.query_runner import QueryRunner\nfrom gpt_index.indices.query.schema import QueryConfig\nfrom gpt_index.indices.registry import IndexRegistry\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.indices.vector_store.faiss import GPTFaissIndex\nfrom gpt_index.indices.vector_store.pinecone import GPTPineconeIndex\nfrom gpt_index.indices.vector_store.qdrant import", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 0, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "1": {"text": "gpt_index.indices.vector_store.qdrant import GPTQdrantIndex\nfrom gpt_index.indices.vector_store.simple import GPTSimpleVectorIndex\nfrom gpt_index.indices.vector_store.weaviate import GPTWeaviateIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.response.schema import Response\n\n# TMP: refactor query config type\nQUERY_CONFIG_TYPE = Union[Dict, QueryConfig]\n\n\n# this is a map from type to outer index class\n# we extract the type_to_struct and type_to_query\n# fields from the index class\nDEFAULT_INDEX_REGISTRY_MAP: Dict[IndexStructType, Type[BaseGPTIndex]] = {\n    IndexStructType.TREE: GPTTreeIndex,\n    IndexStructType.LIST: GPTListIndex,\n    IndexStructType.KEYWORD_TABLE: GPTKeywordTableIndex,\n    IndexStructType.DICT: GPTFaissIndex,\n    IndexStructType.SIMPLE_DICT: GPTSimpleVectorIndex,\n    IndexStructType.WEAVIATE: GPTWeaviateIndex,\n    IndexStructType.PINECONE: GPTPineconeIndex,\n    IndexStructType.QDRANT: GPTQdrantIndex,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 1, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "2": {"text": " IndexStructType.QDRANT: GPTQdrantIndex,\n    IndexStructType.SQL: GPTSQLStructStoreIndex,\n}\n\n\ndef _get_default_index_registry() -> IndexRegistry:\n    \"\"\"Get default index registry.\"\"\"\n    index_registry = IndexRegistry()\n    for index_type, index_class in DEFAULT_INDEX_REGISTRY_MAP.items():\n        index_registry.type_to_struct[index_type] = index_class.index_struct_cls\n        index_registry.type_to_query[index_type] = index_class.get_query_map()\n    return index_registry\n\n\ndef _safe_get_index_struct(\n    docstore: DocumentStore, index_struct_id: str\n) -> IndexStruct:\n    \"\"\"Try get index struct.\"\"\"\n    index_struct = docstore.get_document(index_struct_id)\n    if not isinstance(index_struct, IndexStruct):\n        raise ValueError(\"Invalid `index_struct_id` - must be an IndexStruct\")\n    return index_struct\n\n\nclass ComposableGraph:\n    \"\"\"Composable graph.\"\"\"\n\n    def __init__(\n        self,\n        docstore:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 2, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "3": {"text": "       self,\n        docstore: DocumentStore,\n        index_registry: IndexRegistry,\n        index_struct: IndexStruct,\n        llm_predictor: Optional[LLMPredictor] = None,\n        prompt_helper: Optional[PromptHelper] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        chunk_size_limit: Optional[int] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        self._docstore = docstore\n        self._index_registry = index_registry\n        # this represents the \"root\" index struct\n        self._index_struct = index_struct\n\n        self._llm_predictor = llm_predictor or LLMPredictor()\n        self._prompt_helper = prompt_helper or PromptHelper.from_llm_predictor(\n            self._llm_predictor, chunk_size_limit=chunk_size_limit\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 3, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "4": {"text": "       )\n        self._embed_model = embed_model or OpenAIEmbedding()\n\n    @classmethod\n    def build_from_index(self, index: BaseGPTIndex) -> \"ComposableGraph\":\n        \"\"\"Build from index.\"\"\"\n        return ComposableGraph(\n            index.docstore,\n            index.index_registry,\n            # this represents the \"root\" index struct\n            index.index_struct,\n            llm_predictor=index.llm_predictor,\n            prompt_helper=index.prompt_helper,\n            embed_model=index.embed_model,\n        )\n\n    def query(\n        self,\n        query_str: str,\n        query_configs: Optional[List[QUERY_CONFIG_TYPE]] = None,\n    ) -> Response:\n        \"\"\"Query the index.\"\"\"\n        # go over all the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 4, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "5": {"text": " \"\"\"Query the index.\"\"\"\n        # go over all the indices and create a registry\n        query_runner = QueryRunner(\n            self._llm_predictor,\n            self._prompt_helper,\n            self._embed_model,\n            self._docstore,\n            self._index_registry,\n            query_configs=query_configs,\n            recursive=True,\n        )\n        return query_runner.query(query_str, self._index_struct)\n\n    def get_index(\n        self, index_struct_id: str, index_cls: Type[BaseGPTIndex], **kwargs: Any\n    ) -> BaseGPTIndex:\n        \"\"\"Get index.\"\"\"\n        index_struct = _safe_get_index_struct(self._docstore, index_struct_id)\n        return index_cls(\n            index_struct=index_struct,\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 5, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "6": {"text": "     index_struct=index_struct,\n            docstore=self._docstore,\n            index_registry=self._index_registry,\n            **kwargs\n        )\n\n    @classmethod\n    def load_from_string(cls, index_string: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from string (in JSON-format).\n\n        This method loads the index from a JSON string. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        result_dict = json.loads(index_string)\n        # TODO: this is hardcoded for now, allow it to be specified by the user\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 6, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "7": {"text": "TODO: this is hardcoded for now, allow it to be specified by the user\n        index_registry = _get_default_index_registry()\n        docstore = DocumentStore.load_from_dict(\n            result_dict[\"docstore\"], index_registry.type_to_struct\n        )\n        index_struct = _safe_get_index_struct(docstore, result_dict[\"index_struct_id\"])\n        return cls(docstore, index_registry, index_struct, **kwargs)\n\n    @classmethod\n    def load_from_disk(cls, save_path: str, **kwargs: Any) -> \"ComposableGraph\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n\n        Args:\n            save_path (str): The save_path of the file.\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 7, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "8": {"text": "(str): The save_path of the file.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        with open(save_path, \"r\") as f:\n            file_contents = f.read()\n            return cls.load_from_string(file_contents, **kwargs)\n\n    def save_to_string(self, **save_kwargs: Any) -> str:\n        \"\"\"Save to string.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        out_dict: Dict[str, Any] = {\n            \"index_struct_id\": self._index_struct.get_doc_id(),\n            \"docstore\": self._docstore.serialize_to_dict(),\n        }\n        return json.dumps(out_dict)\n\n    def save_to_disk(self,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 8, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "9": {"text": "   def save_to_disk(self, save_path: str, **save_kwargs: Any) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n\n        Args:\n            save_path (str): The save_path of the file.\n\n        \"\"\"\n        index_string = self.save_to_string(**save_kwargs)\n        with open(save_path, \"w\") as f:\n            f.write(index_string)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/composability/graph.py", "file_name": "graph.py"}, "index": 9, "child_indices": [], "ref_doc_id": "90ca6826baf6988ea1d8f1c91b0cb85badcf00f4", "node_info": null}, "10": {"text": "This code file contains the ComposableGraph class, which is used to create a composable graph of indices. It contains methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. It also contains a map from type to outer index class, which is used to create the index registry. The index registry is used to store the type to struct and type to query fields from the index class.\n", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file contains the ComposableGraph class, which is used to create a composable graph of indices. It contains methods for querying the index, getting an index, loading from a string or disk, and saving to a string or disk. It also contains a map from type to outer index class, which is used to create the index registry. The index registry is used to store the type to struct and type to query fields from the index class.\n", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}