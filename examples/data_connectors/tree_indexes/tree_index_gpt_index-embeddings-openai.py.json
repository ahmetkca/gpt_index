{"index_struct": {"text": "\nThis code file provides a way to access OpenAI embeddings using the specified parameters. It contains a dictionary mapping the mode and model to the mode model, a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The code also defines several Enums for OpenAI embedding modes, models, and mode models. The purpose of this code is to provide a way to access OpenAI embeddings using the specified parameters.", "doc_id": "876611be-214f-4f1e-aaf9-df5b23e53cd6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"OpenAI embeddings file.\"\"\"\n\nfrom enum import Enum\nfrom typing import List, Optional\n\nimport openai\nfrom tenacity import retry, stop_after_attempt, wait_random_exponential\n\nfrom gpt_index.embeddings.base import BaseEmbedding\n\n\nclass OpenAIEmbeddingMode(str, Enum):\n    \"\"\"OpenAI embedding mode.\"\"\"\n\n    SIMILARITY_MODE = \"similarity\"\n    TEXT_SEARCH_MODE = \"text_search\"\n\n\nclass OpenAIEmbeddingModelType(str, Enum):\n    \"\"\"OpenAI embedding model type.\"\"\"\n\n    DAVINCI = \"davinci\"\n    CURIE = \"curie\"\n    BABBAGE = \"babbage\"\n    ADA = \"ada\"\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\nclass OpenAIEmbeddingModeModel(str, Enum):\n    \"\"\"OpenAI embedding mode model.\"\"\"\n\n    # davinci\n    TEXT_SIMILARITY_DAVINCI = \"text-similarity-davinci-001\"\n    TEXT_SEARCH_DAVINCI_QUERY = \"text-search-davinci-query-001\"\n    TEXT_SEARCH_DAVINCI_DOC =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 0, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "1": {"text": "   TEXT_SEARCH_DAVINCI_DOC = \"text-search-davinci-doc-001\"\n\n    # curie\n    TEXT_SIMILARITY_CURIE = \"text-similarity-curie-001\"\n    TEXT_SEARCH_CURIE_QUERY = \"text-search-curie-query-001\"\n    TEXT_SEARCH_CURIE_DOC = \"text-search-curie-doc-001\"\n\n    # babbage\n    TEXT_SIMILARITY_BABBAGE = \"text-similarity-babbage-001\"\n    TEXT_SEARCH_BABBAGE_QUERY = \"text-search-babbage-query-001\"\n    TEXT_SEARCH_BABBAGE_DOC = \"text-search-babbage-doc-001\"\n\n    # ada\n    TEXT_SIMILARITY_ADA = \"text-similarity-ada-001\"\n    TEXT_SEARCH_ADA_QUERY = \"text-search-ada-query-001\"\n    TEXT_SEARCH_ADA_DOC = \"text-search-ada-doc-001\"\n\n    # text-embedding-ada-002\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\n# convenient shorthand\nOAEM = OpenAIEmbeddingMode\nOAEMT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 1, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "2": {"text": "shorthand\nOAEM = OpenAIEmbeddingMode\nOAEMT = OpenAIEmbeddingModelType\nOAEMM = OpenAIEmbeddingModeModel\n\nEMBED_MAX_TOKEN_LIMIT = 2048\n\n\n_QUERY_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"):", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 2, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "3": {"text": "   (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n_TEXT_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_DOC,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 3, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "4": {"text": "OAEMM.TEXT_SEARCH_DAVINCI_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n\n@retry(wait=wait_random_exponential(min=20, max=60), stop=stop_after_attempt(100))\ndef get_embedding(\n    text: str,\n    engine: Optional[str] = None,\n) -> List[float]:\n    \"\"\"Get embedding.\n\n    NOTE: Copied from OpenAI's embedding utils:\n    https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n\n    Copied here to avoid importing unnecessary dependencies\n    like matplotlib, plotly, scipy, sklearn.\n\n    \"\"\"\n    text = text.replace(\"\\n\", \" \")\n    return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 4, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "5": {"text": "   text = text.replace(\"\\n\", \" \")\n    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n\n\nclass OpenAIEmbedding(BaseEmbedding):\n    \"\"\"OpenAI class for embeddings.\n\n    Args:\n        mode (str): Mode for embedding.\n            Defaults to OpenAIEmbeddingMode.TEXT_SEARCH_MODE.\n            Options are:\n\n            - OpenAIEmbeddingMode.SIMILARITY_MODE\n            - OpenAIEmbeddingMode.TEXT_SEARCH_MODE\n\n        model (str): Model for embedding.\n            Defaults to OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002.\n            Options are:\n\n            - OpenAIEmbeddingModelType.DAVINCI\n            - OpenAIEmbeddingModelType.CURIE\n            - OpenAIEmbeddingModelType.BABBAGE\n         ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 5, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "6": {"text": "           - OpenAIEmbeddingModelType.ADA\n            - OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002\n\n        deployment_name (Optional[str]): Optional deployment of model. Defaults to None.\n            If this value is not None, mode and model will be ignored.\n            Only available for using AzureOpenAI.\n    \"\"\"\n\n    def __init__(\n        self,\n        mode: str = OpenAIEmbeddingMode.TEXT_SEARCH_MODE,\n        model: str = OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002,\n        deployment_name: Optional[str] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__()\n        self.mode = OpenAIEmbeddingMode(mode)\n        self.model = OpenAIEmbeddingModelType(model)\n        self.deployment_name = deployment_name\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 6, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "7": {"text": "  self.deployment_name = deployment_name\n\n    def _get_query_embedding(self, query: str) -> List[float]:\n        \"\"\"Get query embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode, self.model)\n            if key not in _QUERY_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _QUERY_MODE_MODEL_DICT[key]\n        return get_embedding(query, engine=engine)\n\n    def _get_text_embedding(self, text: str) -> List[float]:\n        \"\"\"Get text embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 7, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "8": {"text": "           key = (self.mode, self.model)\n            if key not in _TEXT_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _TEXT_MODE_MODEL_DICT[key]\n        return get_embedding(text, engine=engine)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 8, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "9": {"text": "This code file contains the OpenAI embeddings file. It defines several Enums for OpenAI embedding modes, models, and mode models. It also contains a dictionary mapping the mode and model to the mode model. The code also contains a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The purpose of this code is to provide a way to get embeddings from OpenAI using the specified parameters. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the OpenAI embeddings file. It defines several Enums for OpenAI embedding modes, models, and mode models. It also contains a dictionary mapping the mode and model to the mode model. The code also contains a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The purpose of this code is to provide a way to get embeddings from OpenAI using the specified parameters. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"19f1d4072db017613451127614ed9fec18193f70": {"text": "\"\"\"OpenAI embeddings file.\"\"\"\n\nfrom enum import Enum\nfrom typing import List, Optional\n\nimport openai\nfrom tenacity import retry, stop_after_attempt, wait_random_exponential\n\nfrom gpt_index.embeddings.base import BaseEmbedding\n\n\nclass OpenAIEmbeddingMode(str, Enum):\n    \"\"\"OpenAI embedding mode.\"\"\"\n\n    SIMILARITY_MODE = \"similarity\"\n    TEXT_SEARCH_MODE = \"text_search\"\n\n\nclass OpenAIEmbeddingModelType(str, Enum):\n    \"\"\"OpenAI embedding model type.\"\"\"\n\n    DAVINCI = \"davinci\"\n    CURIE = \"curie\"\n    BABBAGE = \"babbage\"\n    ADA = \"ada\"\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\nclass OpenAIEmbeddingModeModel(str, Enum):\n    \"\"\"OpenAI embedding mode model.\"\"\"\n\n    # davinci\n    TEXT_SIMILARITY_DAVINCI = \"text-similarity-davinci-001\"\n    TEXT_SEARCH_DAVINCI_QUERY = \"text-search-davinci-query-001\"\n    TEXT_SEARCH_DAVINCI_DOC = \"text-search-davinci-doc-001\"\n\n    # curie\n    TEXT_SIMILARITY_CURIE = \"text-similarity-curie-001\"\n    TEXT_SEARCH_CURIE_QUERY = \"text-search-curie-query-001\"\n    TEXT_SEARCH_CURIE_DOC = \"text-search-curie-doc-001\"\n\n    # babbage\n    TEXT_SIMILARITY_BABBAGE = \"text-similarity-babbage-001\"\n    TEXT_SEARCH_BABBAGE_QUERY = \"text-search-babbage-query-001\"\n    TEXT_SEARCH_BABBAGE_DOC = \"text-search-babbage-doc-001\"\n\n    # ada\n    TEXT_SIMILARITY_ADA = \"text-similarity-ada-001\"\n    TEXT_SEARCH_ADA_QUERY = \"text-search-ada-query-001\"\n    TEXT_SEARCH_ADA_DOC = \"text-search-ada-doc-001\"\n\n    # text-embedding-ada-002\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\n# convenient shorthand\nOAEM = OpenAIEmbeddingMode\nOAEMT = OpenAIEmbeddingModelType\nOAEMM = OpenAIEmbeddingModeModel\n\nEMBED_MAX_TOKEN_LIMIT = 2048\n\n\n_QUERY_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n_TEXT_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n\n@retry(wait=wait_random_exponential(min=20, max=60), stop=stop_after_attempt(100))\ndef get_embedding(\n    text: str,\n    engine: Optional[str] = None,\n) -> List[float]:\n    \"\"\"Get embedding.\n\n    NOTE: Copied from OpenAI's embedding utils:\n    https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n\n    Copied here to avoid importing unnecessary dependencies\n    like matplotlib, plotly, scipy, sklearn.\n\n    \"\"\"\n    text = text.replace(\"\\n\", \" \")\n    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n\n\nclass OpenAIEmbedding(BaseEmbedding):\n    \"\"\"OpenAI class for embeddings.\n\n    Args:\n        mode (str): Mode for embedding.\n            Defaults to OpenAIEmbeddingMode.TEXT_SEARCH_MODE.\n            Options are:\n\n            - OpenAIEmbeddingMode.SIMILARITY_MODE\n            - OpenAIEmbeddingMode.TEXT_SEARCH_MODE\n\n        model (str): Model for embedding.\n            Defaults to OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002.\n            Options are:\n\n            - OpenAIEmbeddingModelType.DAVINCI\n            - OpenAIEmbeddingModelType.CURIE\n            - OpenAIEmbeddingModelType.BABBAGE\n            - OpenAIEmbeddingModelType.ADA\n            - OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002\n\n        deployment_name (Optional[str]): Optional deployment of model. Defaults to None.\n            If this value is not None, mode and model will be ignored.\n            Only available for using AzureOpenAI.\n    \"\"\"\n\n    def __init__(\n        self,\n        mode: str = OpenAIEmbeddingMode.TEXT_SEARCH_MODE,\n        model: str = OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002,\n        deployment_name: Optional[str] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__()\n        self.mode = OpenAIEmbeddingMode(mode)\n        self.model = OpenAIEmbeddingModelType(model)\n        self.deployment_name = deployment_name\n\n    def _get_query_embedding(self, query: str) -> List[float]:\n        \"\"\"Get query embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode, self.model)\n            if key not in _QUERY_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _QUERY_MODE_MODEL_DICT[key]\n        return get_embedding(query, engine=engine)\n\n    def _get_text_embedding(self, text: str) -> List[float]:\n        \"\"\"Get text embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode, self.model)\n            if key not in _TEXT_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _TEXT_MODE_MODEL_DICT[key]\n        return get_embedding(text, engine=engine)\n", "doc_id": "19f1d4072db017613451127614ed9fec18193f70", "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "__type__": "Document"}, "876611be-214f-4f1e-aaf9-df5b23e53cd6": {"text": "\nThis code file provides a way to access OpenAI embeddings using the specified parameters. It contains a dictionary mapping the mode and model to the mode model, a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The code also defines several Enums for OpenAI embedding modes, models, and mode models. The purpose of this code is to provide a way to access OpenAI embeddings using the specified parameters.", "doc_id": "876611be-214f-4f1e-aaf9-df5b23e53cd6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"OpenAI embeddings file.\"\"\"\n\nfrom enum import Enum\nfrom typing import List, Optional\n\nimport openai\nfrom tenacity import retry, stop_after_attempt, wait_random_exponential\n\nfrom gpt_index.embeddings.base import BaseEmbedding\n\n\nclass OpenAIEmbeddingMode(str, Enum):\n    \"\"\"OpenAI embedding mode.\"\"\"\n\n    SIMILARITY_MODE = \"similarity\"\n    TEXT_SEARCH_MODE = \"text_search\"\n\n\nclass OpenAIEmbeddingModelType(str, Enum):\n    \"\"\"OpenAI embedding model type.\"\"\"\n\n    DAVINCI = \"davinci\"\n    CURIE = \"curie\"\n    BABBAGE = \"babbage\"\n    ADA = \"ada\"\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\nclass OpenAIEmbeddingModeModel(str, Enum):\n    \"\"\"OpenAI embedding mode model.\"\"\"\n\n    # davinci\n    TEXT_SIMILARITY_DAVINCI = \"text-similarity-davinci-001\"\n    TEXT_SEARCH_DAVINCI_QUERY = \"text-search-davinci-query-001\"\n    TEXT_SEARCH_DAVINCI_DOC =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 0, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "1": {"text": "   TEXT_SEARCH_DAVINCI_DOC = \"text-search-davinci-doc-001\"\n\n    # curie\n    TEXT_SIMILARITY_CURIE = \"text-similarity-curie-001\"\n    TEXT_SEARCH_CURIE_QUERY = \"text-search-curie-query-001\"\n    TEXT_SEARCH_CURIE_DOC = \"text-search-curie-doc-001\"\n\n    # babbage\n    TEXT_SIMILARITY_BABBAGE = \"text-similarity-babbage-001\"\n    TEXT_SEARCH_BABBAGE_QUERY = \"text-search-babbage-query-001\"\n    TEXT_SEARCH_BABBAGE_DOC = \"text-search-babbage-doc-001\"\n\n    # ada\n    TEXT_SIMILARITY_ADA = \"text-similarity-ada-001\"\n    TEXT_SEARCH_ADA_QUERY = \"text-search-ada-query-001\"\n    TEXT_SEARCH_ADA_DOC = \"text-search-ada-doc-001\"\n\n    # text-embedding-ada-002\n    TEXT_EMBED_ADA_002 = \"text-embedding-ada-002\"\n\n\n# convenient shorthand\nOAEM = OpenAIEmbeddingMode\nOAEMT =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 1, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "2": {"text": "shorthand\nOAEM = OpenAIEmbeddingMode\nOAEMT = OpenAIEmbeddingModelType\nOAEMM = OpenAIEmbeddingModeModel\n\nEMBED_MAX_TOKEN_LIMIT = 2048\n\n\n_QUERY_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"):", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 2, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "3": {"text": "   (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_QUERY,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n_TEXT_MODE_MODEL_DICT = {\n    (OAEM.SIMILARITY_MODE, \"davinci\"): OAEMM.TEXT_SIMILARITY_DAVINCI,\n    (OAEM.SIMILARITY_MODE, \"curie\"): OAEMM.TEXT_SIMILARITY_CURIE,\n    (OAEM.SIMILARITY_MODE, \"babbage\"): OAEMM.TEXT_SIMILARITY_BABBAGE,\n    (OAEM.SIMILARITY_MODE, \"ada\"): OAEMM.TEXT_SIMILARITY_ADA,\n    (OAEM.SIMILARITY_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n    (OAEM.TEXT_SEARCH_MODE, \"davinci\"): OAEMM.TEXT_SEARCH_DAVINCI_DOC,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 3, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "4": {"text": "OAEMM.TEXT_SEARCH_DAVINCI_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"curie\"): OAEMM.TEXT_SEARCH_CURIE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"babbage\"): OAEMM.TEXT_SEARCH_BABBAGE_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"ada\"): OAEMM.TEXT_SEARCH_ADA_DOC,\n    (OAEM.TEXT_SEARCH_MODE, \"text-embedding-ada-002\"): OAEMM.TEXT_EMBED_ADA_002,\n}\n\n\n@retry(wait=wait_random_exponential(min=20, max=60), stop=stop_after_attempt(100))\ndef get_embedding(\n    text: str,\n    engine: Optional[str] = None,\n) -> List[float]:\n    \"\"\"Get embedding.\n\n    NOTE: Copied from OpenAI's embedding utils:\n    https://github.com/openai/openai-python/blob/main/openai/embeddings_utils.py\n\n    Copied here to avoid importing unnecessary dependencies\n    like matplotlib, plotly, scipy, sklearn.\n\n    \"\"\"\n    text = text.replace(\"\\n\", \" \")\n    return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 4, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "5": {"text": "   text = text.replace(\"\\n\", \" \")\n    return openai.Embedding.create(input=[text], engine=engine)[\"data\"][0][\"embedding\"]\n\n\nclass OpenAIEmbedding(BaseEmbedding):\n    \"\"\"OpenAI class for embeddings.\n\n    Args:\n        mode (str): Mode for embedding.\n            Defaults to OpenAIEmbeddingMode.TEXT_SEARCH_MODE.\n            Options are:\n\n            - OpenAIEmbeddingMode.SIMILARITY_MODE\n            - OpenAIEmbeddingMode.TEXT_SEARCH_MODE\n\n        model (str): Model for embedding.\n            Defaults to OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002.\n            Options are:\n\n            - OpenAIEmbeddingModelType.DAVINCI\n            - OpenAIEmbeddingModelType.CURIE\n            - OpenAIEmbeddingModelType.BABBAGE\n         ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 5, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "6": {"text": "           - OpenAIEmbeddingModelType.ADA\n            - OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002\n\n        deployment_name (Optional[str]): Optional deployment of model. Defaults to None.\n            If this value is not None, mode and model will be ignored.\n            Only available for using AzureOpenAI.\n    \"\"\"\n\n    def __init__(\n        self,\n        mode: str = OpenAIEmbeddingMode.TEXT_SEARCH_MODE,\n        model: str = OpenAIEmbeddingModelType.TEXT_EMBED_ADA_002,\n        deployment_name: Optional[str] = None,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__()\n        self.mode = OpenAIEmbeddingMode(mode)\n        self.model = OpenAIEmbeddingModelType(model)\n        self.deployment_name = deployment_name\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 6, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "7": {"text": "  self.deployment_name = deployment_name\n\n    def _get_query_embedding(self, query: str) -> List[float]:\n        \"\"\"Get query embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode, self.model)\n            if key not in _QUERY_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _QUERY_MODE_MODEL_DICT[key]\n        return get_embedding(query, engine=engine)\n\n    def _get_text_embedding(self, text: str) -> List[float]:\n        \"\"\"Get text embedding.\"\"\"\n        if self.deployment_name is not None:\n            engine = self.deployment_name\n        else:\n            key = (self.mode,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 7, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "8": {"text": "           key = (self.mode, self.model)\n            if key not in _TEXT_MODE_MODEL_DICT:\n                raise ValueError(f\"Invalid mode, model combination: {key}\")\n            engine = _TEXT_MODE_MODEL_DICT[key]\n        return get_embedding(text, engine=engine)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/embeddings/openai.py", "file_name": "openai.py"}, "index": 8, "child_indices": [], "ref_doc_id": "19f1d4072db017613451127614ed9fec18193f70", "node_info": null}, "9": {"text": "This code file contains the OpenAI embeddings file. It defines several Enums for OpenAI embedding modes, models, and mode models. It also contains a dictionary mapping the mode and model to the mode model. The code also contains a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The purpose of this code is to provide a way to get embeddings from OpenAI using the specified parameters. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the OpenAI embeddings file. It defines several Enums for OpenAI embedding modes, models, and mode models. It also contains a dictionary mapping the mode and model to the mode model. The code also contains a function to get the embedding for a given text and engine, and a class for OpenAI embeddings. The class contains parameters for the mode, model, and deployment name, and functions to get the query and text embeddings. The purpose of this code is to provide a way to get embeddings from OpenAI using the specified parameters. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}