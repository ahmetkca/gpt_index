{"index_struct": {"text": "\nThe GPTTreeIndexBuilder is a helper class used to build a tree-structured index from a set of documents. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. The prompt helper is used to split the text into chunks, and the LLM predictor is used to generate a summary for each chunk. The index is then built from the nodes recursively in a bottoms-up fashion, consolidating chunks and creating a graph object consisting of all nodes and root nodes. The purpose of this code is to provide a way to quickly and accurately build a tree-structured index from a given set of documents.", "doc_id": "0d78980e-42dc-452c-9d7c-eaa75a22a299", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Common classes/functions for tree index operations.\"\"\"\n\n\nimport logging\nfrom typing import Dict, Sequence\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import get_sorted_node_list, truncate_text\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.prompts import SummaryPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTTreeIndexBuilder:\n    \"\"\"GPT tree index builder.\n\n    Helper class to build the tree-structured index,\n    or to synthesize an answer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        num_children: int,\n        summary_prompt: SummaryPrompt,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "1": {"text": "         raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n\n    def _get_nodes_from_document(\n        self, start_idx: int, document: BaseDocument\n    ) -> Dict[int, Node]:\n        \"\"\"Add document to index.\"\"\"\n        # NOTE: summary prompt does not need to be partially formatted\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n        text_chunks = text_splitter.split_text(\n            document.get_text(), extra_info_str=document.extra_info_str\n        )\n        doc_nodes = {\n            (start_idx + i):", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "2": {"text": "           (start_idx + i): Node(\n                text=t,\n                index=(start_idx + i),\n                ref_doc_id=document.get_doc_id(),\n                embedding=document.embedding,\n                extra_info=document.extra_info,\n            )\n            for i, t in enumerate(text_chunks)\n        }\n        return doc_nodes\n\n    def build_from_text(\n        self,\n        documents: Sequence[BaseDocument],\n        build_tree: bool = True,\n    ) -> IndexGraph:\n        \"\"\"Build from text.\n\n        Returns:\n            IndexGraph: graph object consisting of all_nodes, root_nodes\n\n        \"\"\"\n        all_nodes:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "3": {"text": "      \"\"\"\n        all_nodes: Dict[int, Node] = {}\n        for d in documents:\n            all_nodes.update(self._get_nodes_from_document(len(all_nodes), d))\n\n        if build_tree:\n            # instantiate all_nodes from initial text chunks\n            root_nodes = self.build_index_from_nodes(all_nodes, all_nodes)\n        else:\n            # if build_tree is False, then don't surface any root nodes\n            root_nodes = {}\n        return IndexGraph(all_nodes=all_nodes, root_nodes=root_nodes)\n\n    def build_index_from_nodes(\n        self,\n        cur_nodes: Dict[int, Node],\n        all_nodes: Dict[int, Node],\n    ) -> Dict[int, Node]:\n        \"\"\"Consolidates chunks recursively, in a", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "4": {"text": "       \"\"\"Consolidates chunks recursively, in a bottoms-up fashion.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n        cur_index = len(all_nodes)\n        new_node_dict = {}\n        logging.info(\n            f\"> Building index from nodes: {len(cur_nodes) // self.num_children} chunks\"\n        )\n        for i in range(0, len(cur_node_list), self.num_children):\n            cur_nodes_chunk = cur_node_list[i : i + self.num_children]\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_nodes_chunk, prompt=self.summary_prompt\n            )\n\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "5": {"text": "             self.summary_prompt, context_str=text_chunk\n            )\n\n            logging.debug(\n                f\"> {i}/{len(cur_nodes)}, summary: {truncate_text(new_summary, 50)}\"\n            )\n            new_node = Node(\n                text=new_summary,\n                index=cur_index,\n                child_indices={n.index for n in cur_nodes_chunk},\n            )\n            new_node_dict[cur_index] = new_node\n            cur_index += 1\n\n        all_nodes.update(new_node_dict)\n\n        if len(new_node_dict) <= self.num_children:\n            return new_node_dict\n        else:\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "6": {"text": " return new_node_dict\n        else:\n            return self.build_index_from_nodes(new_node_dict, all_nodes)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "7": {"text": "This code file contains the GPTTreeIndexBuilder class, which is a helper class used to build a tree-structured index or to synthesize an answer. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. It then uses the prompt helper to split the text into chunks, and the LLM predictor to generate a summary for each chunk. It then builds the index from the nodes recursively in a bottoms-up fashion.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains the GPTTreeIndexBuilder class, which is a helper class used to build a tree-structured index or to synthesize an answer. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. It then uses the prompt helper to split the text into chunks, and the LLM predictor to generate a summary for each chunk. It then builds the index from the nodes recursively in a bottoms-up fashion.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef": {"text": "\"\"\"Common classes/functions for tree index operations.\"\"\"\n\n\nimport logging\nfrom typing import Dict, Sequence\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import get_sorted_node_list, truncate_text\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.prompts import SummaryPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTTreeIndexBuilder:\n    \"\"\"GPT tree index builder.\n\n    Helper class to build the tree-structured index,\n    or to synthesize an answer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        num_children: int,\n        summary_prompt: SummaryPrompt,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n\n    def _get_nodes_from_document(\n        self, start_idx: int, document: BaseDocument\n    ) -> Dict[int, Node]:\n        \"\"\"Add document to index.\"\"\"\n        # NOTE: summary prompt does not need to be partially formatted\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n        text_chunks = text_splitter.split_text(\n            document.get_text(), extra_info_str=document.extra_info_str\n        )\n        doc_nodes = {\n            (start_idx + i): Node(\n                text=t,\n                index=(start_idx + i),\n                ref_doc_id=document.get_doc_id(),\n                embedding=document.embedding,\n                extra_info=document.extra_info,\n            )\n            for i, t in enumerate(text_chunks)\n        }\n        return doc_nodes\n\n    def build_from_text(\n        self,\n        documents: Sequence[BaseDocument],\n        build_tree: bool = True,\n    ) -> IndexGraph:\n        \"\"\"Build from text.\n\n        Returns:\n            IndexGraph: graph object consisting of all_nodes, root_nodes\n\n        \"\"\"\n        all_nodes: Dict[int, Node] = {}\n        for d in documents:\n            all_nodes.update(self._get_nodes_from_document(len(all_nodes), d))\n\n        if build_tree:\n            # instantiate all_nodes from initial text chunks\n            root_nodes = self.build_index_from_nodes(all_nodes, all_nodes)\n        else:\n            # if build_tree is False, then don't surface any root nodes\n            root_nodes = {}\n        return IndexGraph(all_nodes=all_nodes, root_nodes=root_nodes)\n\n    def build_index_from_nodes(\n        self,\n        cur_nodes: Dict[int, Node],\n        all_nodes: Dict[int, Node],\n    ) -> Dict[int, Node]:\n        \"\"\"Consolidates chunks recursively, in a bottoms-up fashion.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n        cur_index = len(all_nodes)\n        new_node_dict = {}\n        logging.info(\n            f\"> Building index from nodes: {len(cur_nodes) // self.num_children} chunks\"\n        )\n        for i in range(0, len(cur_node_list), self.num_children):\n            cur_nodes_chunk = cur_node_list[i : i + self.num_children]\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_nodes_chunk, prompt=self.summary_prompt\n            )\n\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            logging.debug(\n                f\"> {i}/{len(cur_nodes)}, summary: {truncate_text(new_summary, 50)}\"\n            )\n            new_node = Node(\n                text=new_summary,\n                index=cur_index,\n                child_indices={n.index for n in cur_nodes_chunk},\n            )\n            new_node_dict[cur_index] = new_node\n            cur_index += 1\n\n        all_nodes.update(new_node_dict)\n\n        if len(new_node_dict) <= self.num_children:\n            return new_node_dict\n        else:\n            return self.build_index_from_nodes(new_node_dict, all_nodes)\n", "doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "__type__": "Document"}, "0d78980e-42dc-452c-9d7c-eaa75a22a299": {"text": "\nThe GPTTreeIndexBuilder is a helper class used to build a tree-structured index from a set of documents. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. The prompt helper is used to split the text into chunks, and the LLM predictor is used to generate a summary for each chunk. The index is then built from the nodes recursively in a bottoms-up fashion, consolidating chunks and creating a graph object consisting of all nodes and root nodes. The purpose of this code is to provide a way to quickly and accurately build a tree-structured index from a given set of documents.", "doc_id": "0d78980e-42dc-452c-9d7c-eaa75a22a299", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Common classes/functions for tree index operations.\"\"\"\n\n\nimport logging\nfrom typing import Dict, Sequence\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import get_sorted_node_list, truncate_text\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.prompts import SummaryPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTTreeIndexBuilder:\n    \"\"\"GPT tree index builder.\n\n    Helper class to build the tree-structured index,\n    or to synthesize an answer.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        num_children: int,\n        summary_prompt: SummaryPrompt,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "1": {"text": "         raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n\n    def _get_nodes_from_document(\n        self, start_idx: int, document: BaseDocument\n    ) -> Dict[int, Node]:\n        \"\"\"Add document to index.\"\"\"\n        # NOTE: summary prompt does not need to be partially formatted\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n        text_chunks = text_splitter.split_text(\n            document.get_text(), extra_info_str=document.extra_info_str\n        )\n        doc_nodes = {\n            (start_idx + i):", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "2": {"text": "           (start_idx + i): Node(\n                text=t,\n                index=(start_idx + i),\n                ref_doc_id=document.get_doc_id(),\n                embedding=document.embedding,\n                extra_info=document.extra_info,\n            )\n            for i, t in enumerate(text_chunks)\n        }\n        return doc_nodes\n\n    def build_from_text(\n        self,\n        documents: Sequence[BaseDocument],\n        build_tree: bool = True,\n    ) -> IndexGraph:\n        \"\"\"Build from text.\n\n        Returns:\n            IndexGraph: graph object consisting of all_nodes, root_nodes\n\n        \"\"\"\n        all_nodes:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "3": {"text": "      \"\"\"\n        all_nodes: Dict[int, Node] = {}\n        for d in documents:\n            all_nodes.update(self._get_nodes_from_document(len(all_nodes), d))\n\n        if build_tree:\n            # instantiate all_nodes from initial text chunks\n            root_nodes = self.build_index_from_nodes(all_nodes, all_nodes)\n        else:\n            # if build_tree is False, then don't surface any root nodes\n            root_nodes = {}\n        return IndexGraph(all_nodes=all_nodes, root_nodes=root_nodes)\n\n    def build_index_from_nodes(\n        self,\n        cur_nodes: Dict[int, Node],\n        all_nodes: Dict[int, Node],\n    ) -> Dict[int, Node]:\n        \"\"\"Consolidates chunks recursively, in a", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "4": {"text": "       \"\"\"Consolidates chunks recursively, in a bottoms-up fashion.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n        cur_index = len(all_nodes)\n        new_node_dict = {}\n        logging.info(\n            f\"> Building index from nodes: {len(cur_nodes) // self.num_children} chunks\"\n        )\n        for i in range(0, len(cur_node_list), self.num_children):\n            cur_nodes_chunk = cur_node_list[i : i + self.num_children]\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_nodes_chunk, prompt=self.summary_prompt\n            )\n\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "5": {"text": "             self.summary_prompt, context_str=text_chunk\n            )\n\n            logging.debug(\n                f\"> {i}/{len(cur_nodes)}, summary: {truncate_text(new_summary, 50)}\"\n            )\n            new_node = Node(\n                text=new_summary,\n                index=cur_index,\n                child_indices={n.index for n in cur_nodes_chunk},\n            )\n            new_node_dict[cur_index] = new_node\n            cur_index += 1\n\n        all_nodes.update(new_node_dict)\n\n        if len(new_node_dict) <= self.num_children:\n            return new_node_dict\n        else:\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "6": {"text": " return new_node_dict\n        else:\n            return self.build_index_from_nodes(new_node_dict, all_nodes)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/common/tree/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "cb36bdd5d0c7925d04e4e3fcb9363e168384f0ef", "node_info": null}, "7": {"text": "This code file contains the GPTTreeIndexBuilder class, which is a helper class used to build a tree-structured index or to synthesize an answer. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. It then uses the prompt helper to split the text into chunks, and the LLM predictor to generate a summary for each chunk. It then builds the index from the nodes recursively in a bottoms-up fashion.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains the GPTTreeIndexBuilder class, which is a helper class used to build a tree-structured index or to synthesize an answer. It takes in a number of children, a summary prompt, an LLM predictor, and a prompt helper as parameters. It then uses the prompt helper to split the text into chunks, and the LLM predictor to generate a summary for each chunk. It then builds the index from the nodes recursively in a bottoms-up fashion.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}