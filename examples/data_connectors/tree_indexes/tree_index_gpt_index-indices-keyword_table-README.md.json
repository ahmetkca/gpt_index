{"index_struct": {"text": "\nGPTKeywordIndex is a keyword-based table data structure that enables efficient search of text documents. During index construction, GPT is used to extract relevant keywords from each text chunk, which are then stored in a table. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query and uses them to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords and truncated after a cutoff parameter. There are three query modes: default, simple, and rake. The code file provides a data structure and algorithms to efficiently search text documents. It uses GPT to extract relevant keywords from each text chunk and stores them in a table. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query and uses them to fetch the set of candidate text chunk ID's. The query time is O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query.", "doc_id": "ec905bd9-5272-47f8-ba1a-5bb208ff9dc0", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\n\n\ud83d\udd11 GPTKeywordIndex\n\nGPTKeywordIndex is a keyword-based table data structure (inspired by \"hash tables\").\n\n\n\n\n\nIndex Construction\n\nDuring index construction, GPTKeywordIndex first takes in a dataset of text documents as input, and chunks them up into smaller document chunks. For each text chunk, GPTKeywordIndex uses GPT to extract a set of relevant keywords with a **keyword extraction prompt**. (keywords can include short phrases, like \"new york city\"). These keywords are then stored in a table, referencing the same text chunk.\n\n\n\n\n\nQuery\n\nThere are three query modes: `default`, `simple`, and `rake`.\n\n**Default**\n\nDuring query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same **keyword extraction prompt**. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff $d$, which represents the maximum number of text chunks to consider.\n\nWe construct an answer using the _create and refine_ paradigm. An initial answer to the query is constructed using the first text chunk. The answer is then _refined_ through", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 0, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "1": {"text": "query is constructed using the first text chunk. The answer is then _refined_ through feeding in subsequent text chunks as context. Refinement could mean keeping the original answer, making small edits to the original answer, or rewriting the original answer completely.\n\n**Simple (Regex)**\nInstead of using GPT for keyword extraction, this mode uses a simple regex query to find words, filtering out stopwords.\n\n**RAKE**\nUse the popular RAKE keyword extractor.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTKeywordTableIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTKeywordTableIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_table.json')\n\n\n\n\nload index from disk\nindex = GPTKeywordTableIndex.load_from_disk('index_table.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ/Additional\n\n**Runtime**\n\nWorst-case runtime to execute a query should be $O(k*c)$, where $k$ is the number of extracted keywords, and $c$ is the number of text chunks per query.\n\nHowever the number of queries to GPT is limited by $O(d)$, where $d$ is a\nuser-specified", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 1, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "2": {"text": "is limited by $O(d)$, where $d$ is a\nuser-specified parameter indicating the maximum number of text chunks to query.\n\n**How much does this cost to run?**\n\nAssuming `num_chunks_per_query=10`, then this equates to \\$~0.40 per query.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 2, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "3": {"text": "GPTKeywordIndex is a keyword-based table data structure that takes in a dataset of text documents as input and chunks them up into smaller document chunks. For each text chunk, GPT is used to extract a set of relevant keywords with a keyword extraction prompt. These keywords are then stored in a table, referencing the same text chunk. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same keyword extraction prompt. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff parameter, which represents the maximum number of text chunks to consider. There are three query modes: default, simple, and rake. The worst-case runtime to execute a query should be O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query. Assuming num_chunks_per_query=10, then this equates to ~$0.40 per query.", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"3": {"text": "GPTKeywordIndex is a keyword-based table data structure that takes in a dataset of text documents as input and chunks them up into smaller document chunks. For each text chunk, GPT is used to extract a set of relevant keywords with a keyword extraction prompt. These keywords are then stored in a table, referencing the same text chunk. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same keyword extraction prompt. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff parameter, which represents the maximum number of text chunks to consider. There are three query modes: default, simple, and rake. The worst-case runtime to execute a query should be O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query. Assuming num_chunks_per_query=10, then this equates to ~$0.40 per query.", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"4c51f91a5611ecfd8531f01a74baf77f9f2484cf": {"text": "\n\n\ud83d\udd11 GPTKeywordIndex\n\nGPTKeywordIndex is a keyword-based table data structure (inspired by \"hash tables\").\n\n\n\n\n\nIndex Construction\n\nDuring index construction, GPTKeywordIndex first takes in a dataset of text documents as input, and chunks them up into smaller document chunks. For each text chunk, GPTKeywordIndex uses GPT to extract a set of relevant keywords with a **keyword extraction prompt**. (keywords can include short phrases, like \"new york city\"). These keywords are then stored in a table, referencing the same text chunk.\n\n\n\n\n\nQuery\n\nThere are three query modes: `default`, `simple`, and `rake`.\n\n**Default**\n\nDuring query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same **keyword extraction prompt**. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff $d$, which represents the maximum number of text chunks to consider.\n\nWe construct an answer using the _create and refine_ paradigm. An initial answer to the query is constructed using the first text chunk. The answer is then _refined_ through feeding in subsequent text chunks as context. Refinement could mean keeping the original answer, making small edits to the original answer, or rewriting the original answer completely.\n\n**Simple (Regex)**\nInstead of using GPT for keyword extraction, this mode uses a simple regex query to find words, filtering out stopwords.\n\n**RAKE**\nUse the popular RAKE keyword extractor.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTKeywordTableIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTKeywordTableIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_table.json')\n\n\n\n\nload index from disk\nindex = GPTKeywordTableIndex.load_from_disk('index_table.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ/Additional\n\n**Runtime**\n\nWorst-case runtime to execute a query should be $O(k*c)$, where $k$ is the number of extracted keywords, and $c$ is the number of text chunks per query.\n\nHowever the number of queries to GPT is limited by $O(d)$, where $d$ is a\nuser-specified parameter indicating the maximum number of text chunks to query.\n\n**How much does this cost to run?**\n\nAssuming `num_chunks_per_query=10`, then this equates to \\$~0.40 per query.\n\n", "doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "__type__": "Document"}, "ec905bd9-5272-47f8-ba1a-5bb208ff9dc0": {"text": "\nGPTKeywordIndex is a keyword-based table data structure that enables efficient search of text documents. During index construction, GPT is used to extract relevant keywords from each text chunk, which are then stored in a table. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query and uses them to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords and truncated after a cutoff parameter. There are three query modes: default, simple, and rake. The code file provides a data structure and algorithms to efficiently search text documents. It uses GPT to extract relevant keywords from each text chunk and stores them in a table. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query and uses them to fetch the set of candidate text chunk ID's. The query time is O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query.", "doc_id": "ec905bd9-5272-47f8-ba1a-5bb208ff9dc0", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\n\n\ud83d\udd11 GPTKeywordIndex\n\nGPTKeywordIndex is a keyword-based table data structure (inspired by \"hash tables\").\n\n\n\n\n\nIndex Construction\n\nDuring index construction, GPTKeywordIndex first takes in a dataset of text documents as input, and chunks them up into smaller document chunks. For each text chunk, GPTKeywordIndex uses GPT to extract a set of relevant keywords with a **keyword extraction prompt**. (keywords can include short phrases, like \"new york city\"). These keywords are then stored in a table, referencing the same text chunk.\n\n\n\n\n\nQuery\n\nThere are three query modes: `default`, `simple`, and `rake`.\n\n**Default**\n\nDuring query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same **keyword extraction prompt**. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff $d$, which represents the maximum number of text chunks to consider.\n\nWe construct an answer using the _create and refine_ paradigm. An initial answer to the query is constructed using the first text chunk. The answer is then _refined_ through", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 0, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "1": {"text": "query is constructed using the first text chunk. The answer is then _refined_ through feeding in subsequent text chunks as context. Refinement could mean keeping the original answer, making small edits to the original answer, or rewriting the original answer completely.\n\n**Simple (Regex)**\nInstead of using GPT for keyword extraction, this mode uses a simple regex query to find words, filtering out stopwords.\n\n**RAKE**\nUse the popular RAKE keyword extractor.\n\n\n\n\n\nUsage\n\n```python\nfrom gpt_index import GPTKeywordTableIndex, SimpleDirectoryReader\n\n\n\n\n\nbuild index\ndocuments = SimpleDirectoryReader('data').load_data()\nindex = GPTKeywordTableIndex(documents)\n\n\n\n\nsave index\nindex.save_to_disk('index_table.json')\n\n\n\n\nload index from disk\nindex = GPTKeywordTableIndex.load_from_disk('index_table.json')\n\n\n\n\nquery\nresponse = index.query(\"\", mode=\"default\")\n```\n\n\n\n\n\nFAQ/Additional\n\n**Runtime**\n\nWorst-case runtime to execute a query should be $O(k*c)$, where $k$ is the number of extracted keywords, and $c$ is the number of text chunks per query.\n\nHowever the number of queries to GPT is limited by $O(d)$, where $d$ is a\nuser-specified", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 1, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "2": {"text": "is limited by $O(d)$, where $d$ is a\nuser-specified parameter indicating the maximum number of text chunks to query.\n\n**How much does this cost to run?**\n\nAssuming `num_chunks_per_query=10`, then this equates to \\$~0.40 per query.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/README.md", "file_name": "gpt_index/indices/keyword_table/README.md"}, "index": 2, "child_indices": [], "ref_doc_id": "4c51f91a5611ecfd8531f01a74baf77f9f2484cf", "node_info": null}, "3": {"text": "GPTKeywordIndex is a keyword-based table data structure that takes in a dataset of text documents as input and chunks them up into smaller document chunks. For each text chunk, GPT is used to extract a set of relevant keywords with a keyword extraction prompt. These keywords are then stored in a table, referencing the same text chunk. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same keyword extraction prompt. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff parameter, which represents the maximum number of text chunks to consider. There are three query modes: default, simple, and rake. The worst-case runtime to execute a query should be O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query. Assuming num_chunks_per_query=10, then this equates to ~$0.40 per query.", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"3": {"text": "GPTKeywordIndex is a keyword-based table data structure that takes in a dataset of text documents as input and chunks them up into smaller document chunks. For each text chunk, GPT is used to extract a set of relevant keywords with a keyword extraction prompt. These keywords are then stored in a table, referencing the same text chunk. During query-time, the GPTKeywordIndex extracts a set of relevant keywords from the query using a customized variant of the same keyword extraction prompt. These keywords are then used to fetch the set of candidate text chunk ID's. The text chunk ID's are ordered by number of matching keywords (from highest to lowest), and truncated after a cutoff parameter, which represents the maximum number of text chunks to consider. There are three query modes: default, simple, and rake. The worst-case runtime to execute a query should be O(k*c), where k is the number of extracted keywords, and c is the number of text chunks per query. Assuming num_chunks_per_query=10, then this equates to ~$0.40 per query.", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}