{"index_struct": {"text": "\nThe code file contains classes and functions that are used to build and maintain a GPT Keyword Table Index. This index is a type of hash table that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The code provides functions to insert and delete documents, as well as extract keywords from text using a GPT model. The index supports various query modes such as DEFAULT, SIMPLE, and RAKE. The code file provides the necessary classes and functions to build and maintain the GPT Keyword Table Index.", "doc_id": "4192639d-ad90-458c-82c9-6bfb2ae5ebc9", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Keyword-table based index.\n\nSimilar to a \"hash table\" in concept. GPT Index first tries\nto extract keywords from the source text, and stores the\nkeywords as keys per item. It similarly extracts keywords\nfrom the query text. Then, it tries to match those keywords to\nexisting keywords in the table.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Optional, Sequence, Set, Type\n\nfrom gpt_index.data_structs.data_structs import KeywordTable\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.keyword_table.query import (\n    GPTKeywordTableGPTQuery,\n    GPTKeywordTableRAKEQuery,\n    GPTKeywordTableSimpleQuery,\n)\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "1": {"text": "DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt\nfrom gpt_index.schema import BaseDocument\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableIndex(BaseGPTIndex[KeywordTable]):\n    \"\"\"GPT Keyword Table Index.\n\n    This index extracts keywords from the text, and maps each\n    keyword to the node(s) that it corresponds to. In this sense it mimicks a\n    \"hash table\". During index construction, the keyword table is constructed\n    by extracting keywords from each node and creating an internal mapping.\n\n    During query time, the keywords are extracted from the query text, and these\n    keywords are used to index into the keyword table. The retrieved nodes\n    are then used to answer the query.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "2": {"text": "  Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n\n    \"\"\"\n\n    index_struct_cls = KeywordTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[KeywordTable] = None,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        max_keywords_per_chunk: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.max_keywords_per_chunk = max_keywords_per_chunk\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "3": {"text": "       )\n        # NOTE: Partially format keyword extract template here.\n        self.keyword_extract_template = self.keyword_extract_template.partial_format(\n            max_keywords=self.max_keywords_per_chunk\n        )\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "4": {"text": "return {\n            QueryMode.DEFAULT: GPTKeywordTableGPTQuery,\n            QueryMode.SIMPLE: GPTKeywordTableSimpleQuery,\n            QueryMode.RAKE: GPTKeywordTableRAKEQuery,\n        }\n\n    @abstractmethod\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> KeywordTable:\n        \"\"\"Build the index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n        # do simple concatenation\n        index_struct = KeywordTable(table={})\n        for d in documents:\n            nodes = self._get_nodes_from_document(d, text_splitter)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "5": {"text": "= self._get_nodes_from_document(d, text_splitter)\n            for n in nodes:\n                keywords = self._extract_keywords(n.get_text())\n                index_struct.add_node(list(keywords), n)\n\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        nodes = self._get_nodes_from_document(document, self._text_splitter)\n        for n in nodes:\n            keywords = self._extract_keywords(n.get_text())\n            self._index_struct.add_node(list(keywords), n)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        # get set of ids that correspond to node\n        node_idxs_to_delete = set()\n        for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "6": {"text": "node_idxs_to_delete = set()\n        for node_idx, node in self._index_struct.text_chunks.items():\n            if node.ref_doc_id != doc_id:\n                continue\n            node_idxs_to_delete.add(node_idx)\n        for node_idx in node_idxs_to_delete:\n            del self._index_struct.text_chunks[node_idx]\n\n        # delete node_idxs from keyword to node idxs mapping\n        keywords_to_delete = set()\n        for keyword, node_idxs in self._index_struct.table.items():\n            if node_idxs_to_delete.intersection(node_idxs):\n                self._index_struct.table[keyword] = node_idxs.difference(\n                    node_idxs_to_delete\n                )\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "7": {"text": "             )\n                if not self._index_struct.table[keyword]:\n                    keywords_to_delete.add(keyword)\n\n        for keyword in keywords_to_delete:\n            del self._index_struct.table[keyword]\n\n\nclass GPTKeywordTableIndex(BaseGPTKeywordTableIndex):\n    \"\"\"GPT Keyword Table Index.\n\n    This index uses a GPT model to extract keywords from the text.\n\n    \"\"\"\n\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.keyword_extract_template,\n            text=text,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return keywords\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "8": {"text": "The GPT Keyword Table Index is a type of index that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The GPT Keyword Table Index uses a GPT model to extract keywords from the text. The index also supports various query modes such as DEFAULT, SIMPLE, and RAKE.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"8": {"text": "The GPT Keyword Table Index is a type of index that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The GPT Keyword Table Index uses a GPT model to extract keywords from the text. The index also supports various query modes such as DEFAULT, SIMPLE, and RAKE.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"71bad2125cd5052fdc9fe562d68fc8ecf47ddb51": {"text": "\"\"\"Keyword-table based index.\n\nSimilar to a \"hash table\" in concept. GPT Index first tries\nto extract keywords from the source text, and stores the\nkeywords as keys per item. It similarly extracts keywords\nfrom the query text. Then, it tries to match those keywords to\nexisting keywords in the table.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Optional, Sequence, Set, Type\n\nfrom gpt_index.data_structs.data_structs import KeywordTable\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.keyword_table.query import (\n    GPTKeywordTableGPTQuery,\n    GPTKeywordTableRAKEQuery,\n    GPTKeywordTableSimpleQuery,\n)\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt\nfrom gpt_index.schema import BaseDocument\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableIndex(BaseGPTIndex[KeywordTable]):\n    \"\"\"GPT Keyword Table Index.\n\n    This index extracts keywords from the text, and maps each\n    keyword to the node(s) that it corresponds to. In this sense it mimicks a\n    \"hash table\". During index construction, the keyword table is constructed\n    by extracting keywords from each node and creating an internal mapping.\n\n    During query time, the keywords are extracted from the query text, and these\n    keywords are used to index into the keyword table. The retrieved nodes\n    are then used to answer the query.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n\n    \"\"\"\n\n    index_struct_cls = KeywordTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[KeywordTable] = None,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        max_keywords_per_chunk: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.max_keywords_per_chunk = max_keywords_per_chunk\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n        # NOTE: Partially format keyword extract template here.\n        self.keyword_extract_template = self.keyword_extract_template.partial_format(\n            max_keywords=self.max_keywords_per_chunk\n        )\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTKeywordTableGPTQuery,\n            QueryMode.SIMPLE: GPTKeywordTableSimpleQuery,\n            QueryMode.RAKE: GPTKeywordTableRAKEQuery,\n        }\n\n    @abstractmethod\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> KeywordTable:\n        \"\"\"Build the index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n        # do simple concatenation\n        index_struct = KeywordTable(table={})\n        for d in documents:\n            nodes = self._get_nodes_from_document(d, text_splitter)\n            for n in nodes:\n                keywords = self._extract_keywords(n.get_text())\n                index_struct.add_node(list(keywords), n)\n\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        nodes = self._get_nodes_from_document(document, self._text_splitter)\n        for n in nodes:\n            keywords = self._extract_keywords(n.get_text())\n            self._index_struct.add_node(list(keywords), n)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        # get set of ids that correspond to node\n        node_idxs_to_delete = set()\n        for node_idx, node in self._index_struct.text_chunks.items():\n            if node.ref_doc_id != doc_id:\n                continue\n            node_idxs_to_delete.add(node_idx)\n        for node_idx in node_idxs_to_delete:\n            del self._index_struct.text_chunks[node_idx]\n\n        # delete node_idxs from keyword to node idxs mapping\n        keywords_to_delete = set()\n        for keyword, node_idxs in self._index_struct.table.items():\n            if node_idxs_to_delete.intersection(node_idxs):\n                self._index_struct.table[keyword] = node_idxs.difference(\n                    node_idxs_to_delete\n                )\n                if not self._index_struct.table[keyword]:\n                    keywords_to_delete.add(keyword)\n\n        for keyword in keywords_to_delete:\n            del self._index_struct.table[keyword]\n\n\nclass GPTKeywordTableIndex(BaseGPTKeywordTableIndex):\n    \"\"\"GPT Keyword Table Index.\n\n    This index uses a GPT model to extract keywords from the text.\n\n    \"\"\"\n\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.keyword_extract_template,\n            text=text,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return keywords\n", "doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "__type__": "Document"}, "4192639d-ad90-458c-82c9-6bfb2ae5ebc9": {"text": "\nThe code file contains classes and functions that are used to build and maintain a GPT Keyword Table Index. This index is a type of hash table that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The code provides functions to insert and delete documents, as well as extract keywords from text using a GPT model. The index supports various query modes such as DEFAULT, SIMPLE, and RAKE. The code file provides the necessary classes and functions to build and maintain the GPT Keyword Table Index.", "doc_id": "4192639d-ad90-458c-82c9-6bfb2ae5ebc9", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Keyword-table based index.\n\nSimilar to a \"hash table\" in concept. GPT Index first tries\nto extract keywords from the source text, and stores the\nkeywords as keys per item. It similarly extracts keywords\nfrom the query text. Then, it tries to match those keywords to\nexisting keywords in the table.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Optional, Sequence, Set, Type\n\nfrom gpt_index.data_structs.data_structs import KeywordTable\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.keyword_table.utils import extract_keywords_given_response\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.keyword_table.query import (\n    GPTKeywordTableGPTQuery,\n    GPTKeywordTableRAKEQuery,\n    GPTKeywordTableSimpleQuery,\n)\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "1": {"text": "DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt\nfrom gpt_index.schema import BaseDocument\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableIndex(BaseGPTIndex[KeywordTable]):\n    \"\"\"GPT Keyword Table Index.\n\n    This index extracts keywords from the text, and maps each\n    keyword to the node(s) that it corresponds to. In this sense it mimicks a\n    \"hash table\". During index construction, the keyword table is constructed\n    by extracting keywords from each node and creating an internal mapping.\n\n    During query time, the keywords are extracted from the query text, and these\n    keywords are used to index into the keyword table. The retrieved nodes\n    are then used to answer the query.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "2": {"text": "  Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n\n    \"\"\"\n\n    index_struct_cls = KeywordTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[KeywordTable] = None,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        max_keywords_per_chunk: int = 10,\n        llm_predictor: Optional[LLMPredictor] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # need to set parameters before building index in base class.\n        self.max_keywords_per_chunk = max_keywords_per_chunk\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "3": {"text": "       )\n        # NOTE: Partially format keyword extract template here.\n        self.keyword_extract_template = self.keyword_extract_template.partial_format(\n            max_keywords=self.max_keywords_per_chunk\n        )\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "4": {"text": "return {\n            QueryMode.DEFAULT: GPTKeywordTableGPTQuery,\n            QueryMode.SIMPLE: GPTKeywordTableSimpleQuery,\n            QueryMode.RAKE: GPTKeywordTableRAKEQuery,\n        }\n\n    @abstractmethod\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> KeywordTable:\n        \"\"\"Build the index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.keyword_extract_template, 1\n        )\n        # do simple concatenation\n        index_struct = KeywordTable(table={})\n        for d in documents:\n            nodes = self._get_nodes_from_document(d, text_splitter)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "5": {"text": "= self._get_nodes_from_document(d, text_splitter)\n            for n in nodes:\n                keywords = self._extract_keywords(n.get_text())\n                index_struct.add_node(list(keywords), n)\n\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        nodes = self._get_nodes_from_document(document, self._text_splitter)\n        for n in nodes:\n            keywords = self._extract_keywords(n.get_text())\n            self._index_struct.add_node(list(keywords), n)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        # get set of ids that correspond to node\n        node_idxs_to_delete = set()\n        for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "6": {"text": "node_idxs_to_delete = set()\n        for node_idx, node in self._index_struct.text_chunks.items():\n            if node.ref_doc_id != doc_id:\n                continue\n            node_idxs_to_delete.add(node_idx)\n        for node_idx in node_idxs_to_delete:\n            del self._index_struct.text_chunks[node_idx]\n\n        # delete node_idxs from keyword to node idxs mapping\n        keywords_to_delete = set()\n        for keyword, node_idxs in self._index_struct.table.items():\n            if node_idxs_to_delete.intersection(node_idxs):\n                self._index_struct.table[keyword] = node_idxs.difference(\n                    node_idxs_to_delete\n                )\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "7": {"text": "             )\n                if not self._index_struct.table[keyword]:\n                    keywords_to_delete.add(keyword)\n\n        for keyword in keywords_to_delete:\n            del self._index_struct.table[keyword]\n\n\nclass GPTKeywordTableIndex(BaseGPTKeywordTableIndex):\n    \"\"\"GPT Keyword Table Index.\n\n    This index uses a GPT model to extract keywords from the text.\n\n    \"\"\"\n\n    def _extract_keywords(self, text: str) -> Set[str]:\n        \"\"\"Extract keywords from text.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.keyword_extract_template,\n            text=text,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return keywords\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/keyword_table/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "71bad2125cd5052fdc9fe562d68fc8ecf47ddb51", "node_info": null}, "8": {"text": "The GPT Keyword Table Index is a type of index that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The GPT Keyword Table Index uses a GPT model to extract keywords from the text. The index also supports various query modes such as DEFAULT, SIMPLE, and RAKE.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"8": {"text": "The GPT Keyword Table Index is a type of index that extracts keywords from text and maps them to nodes. During index construction, keywords are extracted from each node and stored in an internal mapping. During query time, keywords are extracted from the query text and used to index into the keyword table. The GPT Keyword Table Index uses a GPT model to extract keywords from the text. The index also supports various query modes such as DEFAULT, SIMPLE, and RAKE.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}