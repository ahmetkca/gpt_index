{"index_struct": {"text": "\nThis code file provides a way to find the most similar embeddings to a given query embedding. It contains a function, get_top_k_embeddings, which takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. It also contains a helper class, SimilarityTracker, which manages node similarities during the lifecycle of a single query. It stores node similarities in a lookup dictionary and has methods to add, find, and get zipped nodes and their corresponding scores. The code uses an embedding model to compare the query embedding to the list of embeddings and find the most similar ones.", "doc_id": "3359f6f9-a916-4d7a-9595-3459024898c6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Embedding utils for queries.\"\"\"\n\nfrom typing import Dict, List, Optional, Tuple\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import BaseEmbedding\n\n\ndef get_top_k_embeddings(\n    embed_model: BaseEmbedding,\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    similarity_top_k: Optional[int] = None,\n    embedding_ids: Optional[List] = None,\n) -> Tuple[List[float], List]:\n    \"\"\"Get top nodes by similarity to the query.\"\"\"\n    if embedding_ids is None:\n        embedding_ids = [i for i in range(len(embeddings))]\n\n    similarities = []\n    for emb in embeddings:\n        similarity = embed_model.similarity(query_embedding, emb)\n        similarities.append(similarity)\n\n    sorted_tups = sorted(\n        zip(similarities, embedding_ids), key=lambda x: x[0], reverse=True\n    )\n    similarity_top_k = similarity_top_k or", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "1": {"text": " )\n    similarity_top_k = similarity_top_k or len(sorted_tups)\n    result_tups = sorted_tups[:similarity_top_k]\n\n    result_similarities = [s for s, _ in result_tups]\n    result_ids = [n for _, n in result_tups]\n\n    return result_similarities, result_ids\n\n\nclass SimilarityTracker:\n    \"\"\"Helper class to manage node similarities during lifecycle of a single query.\"\"\"\n\n    # TODO: smarter way to store this information\n    lookup: Dict[str, float] = {}\n\n    def _hash(self, node: Node) -> str:\n        \"\"\"Generate a unique key for each node.\"\"\"\n        # TODO: Better way to get unique identifier of a node\n        return str(abs(hash(node.get_text())))\n\n    def add(self, node: Node, similarity: float) -> None:\n        \"\"\"Add a node and its similarity score.\"\"\"\n        node_hash = self._hash(node)\n        self.lookup[node_hash] = similarity\n\n    def find(self, node: Node) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "2": {"text": "= similarity\n\n    def find(self, node: Node) -> Optional[float]:\n        \"\"\"Find a node's similarity score.\"\"\"\n        node_hash = self._hash(node)\n        if node_hash not in self.lookup:\n            return None\n        return self.lookup[node_hash]\n\n    def get_zipped_nodes(self, nodes: List[Node]) -> List[Tuple[Node, Optional[float]]]:\n        \"\"\"Get a zipped list of nodes and their corresponding scores.\"\"\"\n        similarities = [self.find(node) for node in nodes]\n        return list(zip(nodes, similarities))\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "3": {"text": "This code file contains functions and classes related to query embeddings. The get_top_k_embeddings function takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. The SimilarityTracker class is a helper class that manages node similarities during the lifecycle of a single query. It has methods to add, find, and get zipped nodes and their corresponding scores.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"3": {"text": "This code file contains functions and classes related to query embeddings. The get_top_k_embeddings function takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. The SimilarityTracker class is a helper class that manages node similarities during the lifecycle of a single query. It has methods to add, find, and get zipped nodes and their corresponding scores.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"f0bab417b4bf90ea4c52f882a52fbf041839974c": {"text": "\"\"\"Embedding utils for queries.\"\"\"\n\nfrom typing import Dict, List, Optional, Tuple\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import BaseEmbedding\n\n\ndef get_top_k_embeddings(\n    embed_model: BaseEmbedding,\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    similarity_top_k: Optional[int] = None,\n    embedding_ids: Optional[List] = None,\n) -> Tuple[List[float], List]:\n    \"\"\"Get top nodes by similarity to the query.\"\"\"\n    if embedding_ids is None:\n        embedding_ids = [i for i in range(len(embeddings))]\n\n    similarities = []\n    for emb in embeddings:\n        similarity = embed_model.similarity(query_embedding, emb)\n        similarities.append(similarity)\n\n    sorted_tups = sorted(\n        zip(similarities, embedding_ids), key=lambda x: x[0], reverse=True\n    )\n    similarity_top_k = similarity_top_k or len(sorted_tups)\n    result_tups = sorted_tups[:similarity_top_k]\n\n    result_similarities = [s for s, _ in result_tups]\n    result_ids = [n for _, n in result_tups]\n\n    return result_similarities, result_ids\n\n\nclass SimilarityTracker:\n    \"\"\"Helper class to manage node similarities during lifecycle of a single query.\"\"\"\n\n    # TODO: smarter way to store this information\n    lookup: Dict[str, float] = {}\n\n    def _hash(self, node: Node) -> str:\n        \"\"\"Generate a unique key for each node.\"\"\"\n        # TODO: Better way to get unique identifier of a node\n        return str(abs(hash(node.get_text())))\n\n    def add(self, node: Node, similarity: float) -> None:\n        \"\"\"Add a node and its similarity score.\"\"\"\n        node_hash = self._hash(node)\n        self.lookup[node_hash] = similarity\n\n    def find(self, node: Node) -> Optional[float]:\n        \"\"\"Find a node's similarity score.\"\"\"\n        node_hash = self._hash(node)\n        if node_hash not in self.lookup:\n            return None\n        return self.lookup[node_hash]\n\n    def get_zipped_nodes(self, nodes: List[Node]) -> List[Tuple[Node, Optional[float]]]:\n        \"\"\"Get a zipped list of nodes and their corresponding scores.\"\"\"\n        similarities = [self.find(node) for node in nodes]\n        return list(zip(nodes, similarities))\n", "doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "__type__": "Document"}, "3359f6f9-a916-4d7a-9595-3459024898c6": {"text": "\nThis code file provides a way to find the most similar embeddings to a given query embedding. It contains a function, get_top_k_embeddings, which takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. It also contains a helper class, SimilarityTracker, which manages node similarities during the lifecycle of a single query. It stores node similarities in a lookup dictionary and has methods to add, find, and get zipped nodes and their corresponding scores. The code uses an embedding model to compare the query embedding to the list of embeddings and find the most similar ones.", "doc_id": "3359f6f9-a916-4d7a-9595-3459024898c6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Embedding utils for queries.\"\"\"\n\nfrom typing import Dict, List, Optional, Tuple\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.embeddings.openai import BaseEmbedding\n\n\ndef get_top_k_embeddings(\n    embed_model: BaseEmbedding,\n    query_embedding: List[float],\n    embeddings: List[List[float]],\n    similarity_top_k: Optional[int] = None,\n    embedding_ids: Optional[List] = None,\n) -> Tuple[List[float], List]:\n    \"\"\"Get top nodes by similarity to the query.\"\"\"\n    if embedding_ids is None:\n        embedding_ids = [i for i in range(len(embeddings))]\n\n    similarities = []\n    for emb in embeddings:\n        similarity = embed_model.similarity(query_embedding, emb)\n        similarities.append(similarity)\n\n    sorted_tups = sorted(\n        zip(similarities, embedding_ids), key=lambda x: x[0], reverse=True\n    )\n    similarity_top_k = similarity_top_k or", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "1": {"text": " )\n    similarity_top_k = similarity_top_k or len(sorted_tups)\n    result_tups = sorted_tups[:similarity_top_k]\n\n    result_similarities = [s for s, _ in result_tups]\n    result_ids = [n for _, n in result_tups]\n\n    return result_similarities, result_ids\n\n\nclass SimilarityTracker:\n    \"\"\"Helper class to manage node similarities during lifecycle of a single query.\"\"\"\n\n    # TODO: smarter way to store this information\n    lookup: Dict[str, float] = {}\n\n    def _hash(self, node: Node) -> str:\n        \"\"\"Generate a unique key for each node.\"\"\"\n        # TODO: Better way to get unique identifier of a node\n        return str(abs(hash(node.get_text())))\n\n    def add(self, node: Node, similarity: float) -> None:\n        \"\"\"Add a node and its similarity score.\"\"\"\n        node_hash = self._hash(node)\n        self.lookup[node_hash] = similarity\n\n    def find(self, node: Node) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "2": {"text": "= similarity\n\n    def find(self, node: Node) -> Optional[float]:\n        \"\"\"Find a node's similarity score.\"\"\"\n        node_hash = self._hash(node)\n        if node_hash not in self.lookup:\n            return None\n        return self.lookup[node_hash]\n\n    def get_zipped_nodes(self, nodes: List[Node]) -> List[Tuple[Node, Optional[float]]]:\n        \"\"\"Get a zipped list of nodes and their corresponding scores.\"\"\"\n        similarities = [self.find(node) for node in nodes]\n        return list(zip(nodes, similarities))\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/embedding_utils.py", "file_name": "embedding_utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "f0bab417b4bf90ea4c52f882a52fbf041839974c", "node_info": null}, "3": {"text": "This code file contains functions and classes related to query embeddings. The get_top_k_embeddings function takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. The SimilarityTracker class is a helper class that manages node similarities during the lifecycle of a single query. It has methods to add, find, and get zipped nodes and their corresponding scores.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"3": {"text": "This code file contains functions and classes related to query embeddings. The get_top_k_embeddings function takes in an embedding model, a query embedding, a list of embeddings, and optional parameters for similarity top k and embedding ids, and returns a list of the top k embeddings and their corresponding ids. The SimilarityTracker class is a helper class that manages node similarities during the lifecycle of a single query. It has methods to add, find, and get zipped nodes and their corresponding scores.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 3, "child_indices": [0, 1, 2], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}