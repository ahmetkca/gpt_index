{"index_struct": {"text": "\nThis code file contains a query class for GPTKeywordTableIndex, which provides a way to query a keyword table index and return the most relevant nodes for a given query. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then uses GPT, a simple regex-based keyword extractor, or RAKE keyword extractor to extract keywords from the query string. The extracted keywords are then used to sort the text chunks in order of most matching keywords. Finally, the sorted nodes are filtered and the nodes for response are returned.", "doc_id": "94bff390-ad7c-4b2e-8922-9a553828958d", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Query for GPTKeywordTableIndex.\"\"\"\nimport logging\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Optional\n\nfrom gpt_index.data_structs.data_structs import KeywordTable, Node\nfrom gpt_index.indices.keyword_table.utils import (\n    extract_keywords_given_response,\n    rake_extract_keywords,\n    simple_extract_keywords,\n)\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.embedding_utils import SimilarityTracker\nfrom gpt_index.indices.utils import truncate_text\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt, QueryKeywordExtractPrompt\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableQuery(BaseGPTIndexQuery[KeywordTable]):\n    \"\"\"Base GPT Keyword Table Index Query.\n\n    Arguments are shared among subclasses.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 0, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "1": {"text": "Keyword Table Index Query.\n\n    Arguments are shared among subclasses.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n        query_keyword_extract_template (Optional[QueryKeywordExtractPrompt]): A Query\n            Keyword Extraction\n            Prompt (see :ref:`Prompt-Templates`).\n        refine_template (Optional[RefinePrompt]): A Refinement Prompt\n            (see :ref:`Prompt-Templates`).\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question Answering Prompt\n            (see :ref:`Prompt-Templates`).\n        max_keywords_per_query (int): Maximum number of keywords to extract from query.\n        num_chunks_per_query (int): Maximum number of text chunks to query.\n\n    \"\"\"\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 1, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "2": {"text": "Maximum number of text chunks to query.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: KeywordTable,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        query_keyword_extract_template: Optional[QueryKeywordExtractPrompt] = None,\n        max_keywords_per_query: int = 10,\n        num_chunks_per_query: int = 10,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct=index_struct, **kwargs)\n        self.max_keywords_per_query = max_keywords_per_query\n        self.num_chunks_per_query = num_chunks_per_query\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 2, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "3": {"text": "       )\n        self.query_keyword_extract_template = query_keyword_extract_template or DQKET\n\n    @abstractmethod\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n\n    def _get_nodes_for_response(\n        self,\n        query_str: str,\n        similarity_tracker: Optional[SimilarityTracker] = None,\n    ) -> List[Node]:\n        \"\"\"Get nodes for response.\"\"\"\n        logging.info(f\"> Starting query: {query_str}\")\n        keywords = self._get_keywords(query_str)\n        logging.info(f\"query keywords: {keywords}\")\n\n        # go through text chunks in order of most matching keywords\n        chunk_indices_count: Dict[int, int] = defaultdict(int)\n        keywords = [k for k in keywords if k in self.index_struct.keywords]\n        logging.info(f\"Extracted", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 3, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "4": {"text": "       logging.info(f\"Extracted keywords: {keywords}\")\n        for k in keywords:\n            for text_chunk_idx in self.index_struct.table[k]:\n                chunk_indices_count[text_chunk_idx] += 1\n        sorted_chunk_indices = sorted(\n            list(chunk_indices_count.keys()),\n            key=lambda x: chunk_indices_count[x],\n            reverse=True,\n        )\n        sorted_chunk_indices = sorted_chunk_indices[: self.num_chunks_per_query]\n        sorted_nodes = [\n            self.index_struct.text_chunks[idx] for idx in sorted_chunk_indices\n        ]\n        # filter sorted nodes\n        sorted_nodes = [node for node in sorted_nodes if", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 4, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "5": {"text": "   sorted_nodes = [node for node in sorted_nodes if self._should_use_node(node)]\n\n        if logging.getLogger(__name__).getEffectiveLevel() == logging.DEBUG:\n            for chunk_idx, node in zip(sorted_chunk_indices, sorted_nodes):\n                logging.debug(\n                    f\"> Querying with idx: {chunk_idx}: \"\n                    f\"{truncate_text(node.get_text(), 50)}\"\n                )\n\n        return sorted_nodes\n\n\nclass GPTKeywordTableGPTQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Query.\n\n    Extracts keywords using GPT. Set when `mode=\"default\"` in `query` method of\n    `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    See BaseGPTKeywordTableQuery for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 5, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "6": {"text": "mode=\"default\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.query_keyword_extract_template,\n            max_keywords=self.max_keywords_per_query,\n            question=query_str,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return list(keywords)\n\n\nclass GPTKeywordTableSimpleQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Simple Query.\n\n    Extracts keywords using simple regex-based keyword extractor.\n    Set when `mode=\"simple\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"simple\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 6, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "7": {"text": "   See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            simple_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n        )\n\n\nclass GPTKeywordTableRAKEQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index RAKE Query.\n\n    Extracts keywords using RAKE keyword extractor.\n    Set when `mode=\"rake\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"rake\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            rake_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 7, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "8": {"text": "max_keywords=self.max_keywords_per_query)\n        )\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 8, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "9": {"text": "This code file contains the query class for GPTKeywordTableIndex. It provides the functionality to query a keyword table index using GPT, a simple regex-based keyword extractor, or RAKE keyword extractor. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then extracts keywords from the query string and sorts the text chunks in order of most matching keywords. It then filters the sorted nodes and returns the nodes for response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the query class for GPTKeywordTableIndex. It provides the functionality to query a keyword table index using GPT, a simple regex-based keyword extractor, or RAKE keyword extractor. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then extracts keywords from the query string and sorts the text chunks in order of most matching keywords. It then filters the sorted nodes and returns the nodes for response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"731a15442e4eb480e1c5653f78dca14695ef8c95": {"text": "\"\"\"Query for GPTKeywordTableIndex.\"\"\"\nimport logging\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Optional\n\nfrom gpt_index.data_structs.data_structs import KeywordTable, Node\nfrom gpt_index.indices.keyword_table.utils import (\n    extract_keywords_given_response,\n    rake_extract_keywords,\n    simple_extract_keywords,\n)\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.embedding_utils import SimilarityTracker\nfrom gpt_index.indices.utils import truncate_text\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt, QueryKeywordExtractPrompt\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableQuery(BaseGPTIndexQuery[KeywordTable]):\n    \"\"\"Base GPT Keyword Table Index Query.\n\n    Arguments are shared among subclasses.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n        query_keyword_extract_template (Optional[QueryKeywordExtractPrompt]): A Query\n            Keyword Extraction\n            Prompt (see :ref:`Prompt-Templates`).\n        refine_template (Optional[RefinePrompt]): A Refinement Prompt\n            (see :ref:`Prompt-Templates`).\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question Answering Prompt\n            (see :ref:`Prompt-Templates`).\n        max_keywords_per_query (int): Maximum number of keywords to extract from query.\n        num_chunks_per_query (int): Maximum number of text chunks to query.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: KeywordTable,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        query_keyword_extract_template: Optional[QueryKeywordExtractPrompt] = None,\n        max_keywords_per_query: int = 10,\n        num_chunks_per_query: int = 10,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct=index_struct, **kwargs)\n        self.max_keywords_per_query = max_keywords_per_query\n        self.num_chunks_per_query = num_chunks_per_query\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n        self.query_keyword_extract_template = query_keyword_extract_template or DQKET\n\n    @abstractmethod\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n\n    def _get_nodes_for_response(\n        self,\n        query_str: str,\n        similarity_tracker: Optional[SimilarityTracker] = None,\n    ) -> List[Node]:\n        \"\"\"Get nodes for response.\"\"\"\n        logging.info(f\"> Starting query: {query_str}\")\n        keywords = self._get_keywords(query_str)\n        logging.info(f\"query keywords: {keywords}\")\n\n        # go through text chunks in order of most matching keywords\n        chunk_indices_count: Dict[int, int] = defaultdict(int)\n        keywords = [k for k in keywords if k in self.index_struct.keywords]\n        logging.info(f\"Extracted keywords: {keywords}\")\n        for k in keywords:\n            for text_chunk_idx in self.index_struct.table[k]:\n                chunk_indices_count[text_chunk_idx] += 1\n        sorted_chunk_indices = sorted(\n            list(chunk_indices_count.keys()),\n            key=lambda x: chunk_indices_count[x],\n            reverse=True,\n        )\n        sorted_chunk_indices = sorted_chunk_indices[: self.num_chunks_per_query]\n        sorted_nodes = [\n            self.index_struct.text_chunks[idx] for idx in sorted_chunk_indices\n        ]\n        # filter sorted nodes\n        sorted_nodes = [node for node in sorted_nodes if self._should_use_node(node)]\n\n        if logging.getLogger(__name__).getEffectiveLevel() == logging.DEBUG:\n            for chunk_idx, node in zip(sorted_chunk_indices, sorted_nodes):\n                logging.debug(\n                    f\"> Querying with idx: {chunk_idx}: \"\n                    f\"{truncate_text(node.get_text(), 50)}\"\n                )\n\n        return sorted_nodes\n\n\nclass GPTKeywordTableGPTQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Query.\n\n    Extracts keywords using GPT. Set when `mode=\"default\"` in `query` method of\n    `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.query_keyword_extract_template,\n            max_keywords=self.max_keywords_per_query,\n            question=query_str,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return list(keywords)\n\n\nclass GPTKeywordTableSimpleQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Simple Query.\n\n    Extracts keywords using simple regex-based keyword extractor.\n    Set when `mode=\"simple\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"simple\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            simple_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n        )\n\n\nclass GPTKeywordTableRAKEQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index RAKE Query.\n\n    Extracts keywords using RAKE keyword extractor.\n    Set when `mode=\"rake\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"rake\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            rake_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n        )\n", "doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "__type__": "Document"}, "94bff390-ad7c-4b2e-8922-9a553828958d": {"text": "\nThis code file contains a query class for GPTKeywordTableIndex, which provides a way to query a keyword table index and return the most relevant nodes for a given query. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then uses GPT, a simple regex-based keyword extractor, or RAKE keyword extractor to extract keywords from the query string. The extracted keywords are then used to sort the text chunks in order of most matching keywords. Finally, the sorted nodes are filtered and the nodes for response are returned.", "doc_id": "94bff390-ad7c-4b2e-8922-9a553828958d", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Query for GPTKeywordTableIndex.\"\"\"\nimport logging\nfrom abc import abstractmethod\nfrom collections import defaultdict\nfrom typing import Any, Dict, List, Optional\n\nfrom gpt_index.data_structs.data_structs import KeywordTable, Node\nfrom gpt_index.indices.keyword_table.utils import (\n    extract_keywords_given_response,\n    rake_extract_keywords,\n    simple_extract_keywords,\n)\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.embedding_utils import SimilarityTracker\nfrom gpt_index.indices.utils import truncate_text\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE,\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE,\n)\nfrom gpt_index.prompts.prompts import KeywordExtractPrompt, QueryKeywordExtractPrompt\n\nDQKET = DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE\n\n\nclass BaseGPTKeywordTableQuery(BaseGPTIndexQuery[KeywordTable]):\n    \"\"\"Base GPT Keyword Table Index Query.\n\n    Arguments are shared among subclasses.\n\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 0, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "1": {"text": "Keyword Table Index Query.\n\n    Arguments are shared among subclasses.\n\n    Args:\n        keyword_extract_template (Optional[KeywordExtractPrompt]): A Keyword\n            Extraction Prompt\n            (see :ref:`Prompt-Templates`).\n        query_keyword_extract_template (Optional[QueryKeywordExtractPrompt]): A Query\n            Keyword Extraction\n            Prompt (see :ref:`Prompt-Templates`).\n        refine_template (Optional[RefinePrompt]): A Refinement Prompt\n            (see :ref:`Prompt-Templates`).\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question Answering Prompt\n            (see :ref:`Prompt-Templates`).\n        max_keywords_per_query (int): Maximum number of keywords to extract from query.\n        num_chunks_per_query (int): Maximum number of text chunks to query.\n\n    \"\"\"\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 1, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "2": {"text": "Maximum number of text chunks to query.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: KeywordTable,\n        keyword_extract_template: Optional[KeywordExtractPrompt] = None,\n        query_keyword_extract_template: Optional[QueryKeywordExtractPrompt] = None,\n        max_keywords_per_query: int = 10,\n        num_chunks_per_query: int = 10,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct=index_struct, **kwargs)\n        self.max_keywords_per_query = max_keywords_per_query\n        self.num_chunks_per_query = num_chunks_per_query\n        self.keyword_extract_template = (\n            keyword_extract_template or DEFAULT_KEYWORD_EXTRACT_TEMPLATE\n        )\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 2, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "3": {"text": "       )\n        self.query_keyword_extract_template = query_keyword_extract_template or DQKET\n\n    @abstractmethod\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n\n    def _get_nodes_for_response(\n        self,\n        query_str: str,\n        similarity_tracker: Optional[SimilarityTracker] = None,\n    ) -> List[Node]:\n        \"\"\"Get nodes for response.\"\"\"\n        logging.info(f\"> Starting query: {query_str}\")\n        keywords = self._get_keywords(query_str)\n        logging.info(f\"query keywords: {keywords}\")\n\n        # go through text chunks in order of most matching keywords\n        chunk_indices_count: Dict[int, int] = defaultdict(int)\n        keywords = [k for k in keywords if k in self.index_struct.keywords]\n        logging.info(f\"Extracted", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 3, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "4": {"text": "       logging.info(f\"Extracted keywords: {keywords}\")\n        for k in keywords:\n            for text_chunk_idx in self.index_struct.table[k]:\n                chunk_indices_count[text_chunk_idx] += 1\n        sorted_chunk_indices = sorted(\n            list(chunk_indices_count.keys()),\n            key=lambda x: chunk_indices_count[x],\n            reverse=True,\n        )\n        sorted_chunk_indices = sorted_chunk_indices[: self.num_chunks_per_query]\n        sorted_nodes = [\n            self.index_struct.text_chunks[idx] for idx in sorted_chunk_indices\n        ]\n        # filter sorted nodes\n        sorted_nodes = [node for node in sorted_nodes if", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 4, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "5": {"text": "   sorted_nodes = [node for node in sorted_nodes if self._should_use_node(node)]\n\n        if logging.getLogger(__name__).getEffectiveLevel() == logging.DEBUG:\n            for chunk_idx, node in zip(sorted_chunk_indices, sorted_nodes):\n                logging.debug(\n                    f\"> Querying with idx: {chunk_idx}: \"\n                    f\"{truncate_text(node.get_text(), 50)}\"\n                )\n\n        return sorted_nodes\n\n\nclass GPTKeywordTableGPTQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Query.\n\n    Extracts keywords using GPT. Set when `mode=\"default\"` in `query` method of\n    `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    See BaseGPTKeywordTableQuery for", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 5, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "6": {"text": "mode=\"default\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        response, _ = self._llm_predictor.predict(\n            self.query_keyword_extract_template,\n            max_keywords=self.max_keywords_per_query,\n            question=query_str,\n        )\n        keywords = extract_keywords_given_response(response, start_token=\"KEYWORDS:\")\n        return list(keywords)\n\n\nclass GPTKeywordTableSimpleQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index Simple Query.\n\n    Extracts keywords using simple regex-based keyword extractor.\n    Set when `mode=\"simple\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"simple\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 6, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "7": {"text": "   See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            simple_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n        )\n\n\nclass GPTKeywordTableRAKEQuery(BaseGPTKeywordTableQuery):\n    \"\"\"GPT Keyword Table Index RAKE Query.\n\n    Extracts keywords using RAKE keyword extractor.\n    Set when `mode=\"rake\"` in `query` method of `GPTKeywordTableIndex`.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"rake\")\n\n    See BaseGPTKeywordTableQuery for arguments.\n\n    \"\"\"\n\n    def _get_keywords(self, query_str: str) -> List[str]:\n        \"\"\"Extract keywords.\"\"\"\n        return list(\n            rake_extract_keywords(query_str, max_keywords=self.max_keywords_per_query)\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 7, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "8": {"text": "max_keywords=self.max_keywords_per_query)\n        )\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/keyword_table/query.py", "file_name": "query.py"}, "index": 8, "child_indices": [], "ref_doc_id": "731a15442e4eb480e1c5653f78dca14695ef8c95", "node_info": null}, "9": {"text": "This code file contains the query class for GPTKeywordTableIndex. It provides the functionality to query a keyword table index using GPT, a simple regex-based keyword extractor, or RAKE keyword extractor. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then extracts keywords from the query string and sorts the text chunks in order of most matching keywords. It then filters the sorted nodes and returns the nodes for response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the query class for GPTKeywordTableIndex. It provides the functionality to query a keyword table index using GPT, a simple regex-based keyword extractor, or RAKE keyword extractor. It takes in arguments such as keyword extraction templates, maximum number of keywords per query, and maximum number of text chunks per query. It then extracts keywords from the query string and sorts the text chunks in order of most matching keywords. It then filters the sorted nodes and returns the nodes for response.", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}