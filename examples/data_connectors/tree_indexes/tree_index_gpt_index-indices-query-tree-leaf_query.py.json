{"index_struct": {"text": "\nleaf_query.py is a Python file that implements a GPT Tree Index leaf query mechanism. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. The code uses a recursive approach to traverse the index graph and search for a leaf node that can best answer the query. It takes in a query template, a query template for multiple selections, and a child branch factor as arguments. The _query_level() method is used to answer a query recursively, prompting the user with a query template and extracting the numbers from the response to select the corresponding node. The query_with_selected_node() method is used to get a response for a selected node, and if a previous response is provided, the response will be updated with the answer. The code also has the ability to refine the response if a previous response is provided. The purpose of the code is to traverse the index graph and search for a leaf node that can best answer a query, and to provide a response for the selected node.", "doc_id": "c2a7f7f9-7c68-4251-9228-f0c3b499e202", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Leaf query mechanism.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional, cast\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.response.builder import ResponseBuilder\nfrom gpt_index.indices.utils import (\n    extract_numbers_given_response,\n    get_sorted_node_list,\n    truncate_text,\n)\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_QUERY_PROMPT,\n    DEFAULT_QUERY_PROMPT_MULTIPLE,\n)\nfrom gpt_index.prompts.prompts import TreeSelectMultiplePrompt, TreeSelectPrompt\nfrom gpt_index.response.schema import Response\n\n\nclass GPTTreeIndexLeafQuery(BaseGPTIndexQuery[IndexGraph]):\n    \"\"\"GPT Tree Index leaf query.\n\n    This class traverses the index graph and searches for a leaf node that can best\n    answer the query.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    Args:\n        query_template", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 0, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "1": {"text": "   Args:\n        query_template (Optional[TreeSelectPrompt]): Tree Select Query Prompt\n            (see :ref:`Prompt-Templates`).\n        query_template_multiple (Optional[TreeSelectMultiplePrompt]): Tree Select\n            Query Prompt (Multiple)\n            (see :ref:`Prompt-Templates`).\n        child_branch_factor (int): Number of child nodes to consider at each level.\n            If child_branch_factor is 1, then the query will only choose one child node\n            to traverse for any given parent node.\n            If child_branch_factor is 2, then the query will choose two child nodes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: IndexGraph,\n        query_template: Optional[TreeSelectPrompt] = None,\n        query_template_multiple: Optional[TreeSelectMultiplePrompt] = None,\n        child_branch_factor: int = 1,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 1, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "2": {"text": "       child_branch_factor: int = 1,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct, **kwargs)\n        self.query_template = query_template or DEFAULT_QUERY_PROMPT\n        self.query_template_multiple = (\n            query_template_multiple or DEFAULT_QUERY_PROMPT_MULTIPLE\n        )\n        self.child_branch_factor = child_branch_factor\n\n    def _query_with_selected_node(\n        self,\n        selected_node: Node,\n        query_str: str,\n        prev_response: Optional[str] = None,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Get response for selected node.\n\n        If not leaf node, it will recursively call _query on the child nodes.\n        If prev_response is provided, we will update prev_response with the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 2, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "3": {"text": "     If prev_response is provided, we will update prev_response with the answer.\n\n        \"\"\"\n        if len(selected_node.child_indices) == 0:\n            response_builder = ResponseBuilder(\n                self._prompt_helper,\n                self._llm_predictor,\n                self.text_qa_template,\n                self.refine_template,\n            )\n            self.response_builder.add_node(selected_node)\n            # use response builder to get answer from node\n            node_text, _ = self._get_text_from_node(\n                query_str, selected_node, level=level\n            )\n            cur_response = response_builder.get_response_over_chunks(\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 3, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "4": {"text": "               query_str, [node_text], prev_response=prev_response\n            )\n            logging.debug(f\">[Level {level}] Current answer response: {cur_response} \")\n        else:\n            cur_response = self._query_level(\n                {\n                    i: self.index_struct.all_nodes[i]\n                    for i in selected_node.child_indices\n                },\n                query_str,\n                level=level + 1,\n            )\n\n        if prev_response is None:\n            return cur_response\n        else:\n            context_msg = \"\\n\".join([selected_node.get_text(), cur_response])\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 4, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "5": {"text": "cur_response])\n            cur_response, formatted_refine_prompt = self._llm_predictor.predict(\n                self.refine_template,\n                query_str=query_str,\n                existing_answer=prev_response,\n                context_msg=context_msg,\n            )\n\n            logging.debug(f\">[Level {level}] Refine prompt: {formatted_refine_prompt}\")\n            logging.debug(f\">[Level {level}] Current refined response: {cur_response} \")\n            return cur_response\n\n    def _query_level(\n        self,\n        cur_nodes: Dict[int, Node],\n        query_str: str,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Answer a query recursively.\"\"\"\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 5, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "6": {"text": "   \"\"\"Answer a query recursively.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n\n        if self.child_branch_factor == 1:\n            query_template = self.query_template.partial_format(\n                num_chunks=len(cur_node_list), query_str=query_str\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template,\n                context_list=numbered_node_text,\n            )\n        else:\n            query_template_multiple =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 6, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "7": {"text": "else:\n            query_template_multiple = self.query_template_multiple.partial_format(\n                num_chunks=len(cur_node_list),\n                query_str=query_str,\n                branching_factor=self.child_branch_factor,\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template_multiple\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template_multiple,\n                context_list=numbered_node_text,\n            )\n\n        logging.debug(\n            f\">[Level {level}] current prompt template:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 7, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "8": {"text": "       f\">[Level {level}] current prompt template: {formatted_query_prompt}\"\n        )\n\n        numbers = extract_numbers_given_response(response, n=self.child_branch_factor)\n        if numbers is None:\n            logging.debug(\n                f\">[Level {level}] Could not retrieve response - no numbers present\"\n            )\n            # just join text from current nodes as response\n            return response\n        result_response = None\n        for number_str in numbers:\n            number = int(number_str)\n            if number > len(cur_node_list):\n                logging.debug(\n                    f\">[Level {level}] Invalid response: {response} - \"\n                    f\"number {number} out of", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 8, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "9": {"text": "            f\"number {number} out of range\"\n                )\n                return response\n\n            # number is 1-indexed, so subtract 1\n            selected_node = cur_node_list[number - 1]\n\n            logging.info(\n                f\">[Level {level}] Selected node: \"\n                f\"[{number}]/[{','.join([str(int(n)) for n in numbers])}]\"\n            )\n            debug_str = \" \".join(selected_node.get_text().splitlines())\n            logging.debug(\n                f\">[Level {level}] Node \"\n                f\"[{number}] Summary text: \"\n                f\"{ truncate_text(debug_str, 100) }\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 9, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "10": {"text": "  f\"{ truncate_text(debug_str, 100) }\"\n            )\n            result_response = self._query_with_selected_node(\n                selected_node,\n                query_str,\n                prev_response=result_response,\n                level=level,\n            )\n        # result_response should not be None\n        return cast(str, result_response)\n\n    def _query(self, query_str: str) -> Response:\n        \"\"\"Answer a query.\"\"\"\n        # NOTE: this overrides the _query method in the base class\n        logging.info(f\"> Starting query: {query_str}\")\n        response_str = self._query_level(\n            self.index_struct.root_nodes,\n            query_str,\n            level=0,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 10, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "11": {"text": "           level=0,\n        ).strip()\n        return Response(response_str, source_nodes=self.response_builder.get_sources())\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 11, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "12": {"text": "This code file implements a GPT Tree Index leaf query mechanism. It traverses the index graph and searches for a leaf node that can best answer the query. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. It also has the ability to refine the response if a previous response is provided. It uses a child branch factor to determine how many child nodes to consider at each level.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "leaf_query.py is a Python file that contains functions for querying a tree-based index structure. It overrides the _query method in the base class to answer a query. It uses a recursive approach to traverse the tree structure and find the best matching node for the query. It then calls the _query_with_selected_node function to query the selected node and return the response. The response is then returned as a Response object with the source nodes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"12": {"text": "This code file implements a GPT Tree Index leaf query mechanism. It traverses the index graph and searches for a leaf node that can best answer the query. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. It also has the ability to refine the response if a previous response is provided. It uses a child branch factor to determine how many child nodes to consider at each level.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "leaf_query.py is a Python file that contains functions for querying a tree-based index structure. It overrides the _query method in the base class to answer a query. It uses a recursive approach to traverse the tree structure and find the best matching node for the query. It then calls the _query_with_selected_node function to query the selected node and return the response. The response is then returned as a Response object with the source nodes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"6317248da78605b9ee03504c5343c039423e3e4b": {"text": "\"\"\"Leaf query mechanism.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional, cast\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.response.builder import ResponseBuilder\nfrom gpt_index.indices.utils import (\n    extract_numbers_given_response,\n    get_sorted_node_list,\n    truncate_text,\n)\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_QUERY_PROMPT,\n    DEFAULT_QUERY_PROMPT_MULTIPLE,\n)\nfrom gpt_index.prompts.prompts import TreeSelectMultiplePrompt, TreeSelectPrompt\nfrom gpt_index.response.schema import Response\n\n\nclass GPTTreeIndexLeafQuery(BaseGPTIndexQuery[IndexGraph]):\n    \"\"\"GPT Tree Index leaf query.\n\n    This class traverses the index graph and searches for a leaf node that can best\n    answer the query.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    Args:\n        query_template (Optional[TreeSelectPrompt]): Tree Select Query Prompt\n            (see :ref:`Prompt-Templates`).\n        query_template_multiple (Optional[TreeSelectMultiplePrompt]): Tree Select\n            Query Prompt (Multiple)\n            (see :ref:`Prompt-Templates`).\n        child_branch_factor (int): Number of child nodes to consider at each level.\n            If child_branch_factor is 1, then the query will only choose one child node\n            to traverse for any given parent node.\n            If child_branch_factor is 2, then the query will choose two child nodes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: IndexGraph,\n        query_template: Optional[TreeSelectPrompt] = None,\n        query_template_multiple: Optional[TreeSelectMultiplePrompt] = None,\n        child_branch_factor: int = 1,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct, **kwargs)\n        self.query_template = query_template or DEFAULT_QUERY_PROMPT\n        self.query_template_multiple = (\n            query_template_multiple or DEFAULT_QUERY_PROMPT_MULTIPLE\n        )\n        self.child_branch_factor = child_branch_factor\n\n    def _query_with_selected_node(\n        self,\n        selected_node: Node,\n        query_str: str,\n        prev_response: Optional[str] = None,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Get response for selected node.\n\n        If not leaf node, it will recursively call _query on the child nodes.\n        If prev_response is provided, we will update prev_response with the answer.\n\n        \"\"\"\n        if len(selected_node.child_indices) == 0:\n            response_builder = ResponseBuilder(\n                self._prompt_helper,\n                self._llm_predictor,\n                self.text_qa_template,\n                self.refine_template,\n            )\n            self.response_builder.add_node(selected_node)\n            # use response builder to get answer from node\n            node_text, _ = self._get_text_from_node(\n                query_str, selected_node, level=level\n            )\n            cur_response = response_builder.get_response_over_chunks(\n                query_str, [node_text], prev_response=prev_response\n            )\n            logging.debug(f\">[Level {level}] Current answer response: {cur_response} \")\n        else:\n            cur_response = self._query_level(\n                {\n                    i: self.index_struct.all_nodes[i]\n                    for i in selected_node.child_indices\n                },\n                query_str,\n                level=level + 1,\n            )\n\n        if prev_response is None:\n            return cur_response\n        else:\n            context_msg = \"\\n\".join([selected_node.get_text(), cur_response])\n            cur_response, formatted_refine_prompt = self._llm_predictor.predict(\n                self.refine_template,\n                query_str=query_str,\n                existing_answer=prev_response,\n                context_msg=context_msg,\n            )\n\n            logging.debug(f\">[Level {level}] Refine prompt: {formatted_refine_prompt}\")\n            logging.debug(f\">[Level {level}] Current refined response: {cur_response} \")\n            return cur_response\n\n    def _query_level(\n        self,\n        cur_nodes: Dict[int, Node],\n        query_str: str,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Answer a query recursively.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n\n        if self.child_branch_factor == 1:\n            query_template = self.query_template.partial_format(\n                num_chunks=len(cur_node_list), query_str=query_str\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template,\n                context_list=numbered_node_text,\n            )\n        else:\n            query_template_multiple = self.query_template_multiple.partial_format(\n                num_chunks=len(cur_node_list),\n                query_str=query_str,\n                branching_factor=self.child_branch_factor,\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template_multiple\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template_multiple,\n                context_list=numbered_node_text,\n            )\n\n        logging.debug(\n            f\">[Level {level}] current prompt template: {formatted_query_prompt}\"\n        )\n\n        numbers = extract_numbers_given_response(response, n=self.child_branch_factor)\n        if numbers is None:\n            logging.debug(\n                f\">[Level {level}] Could not retrieve response - no numbers present\"\n            )\n            # just join text from current nodes as response\n            return response\n        result_response = None\n        for number_str in numbers:\n            number = int(number_str)\n            if number > len(cur_node_list):\n                logging.debug(\n                    f\">[Level {level}] Invalid response: {response} - \"\n                    f\"number {number} out of range\"\n                )\n                return response\n\n            # number is 1-indexed, so subtract 1\n            selected_node = cur_node_list[number - 1]\n\n            logging.info(\n                f\">[Level {level}] Selected node: \"\n                f\"[{number}]/[{','.join([str(int(n)) for n in numbers])}]\"\n            )\n            debug_str = \" \".join(selected_node.get_text().splitlines())\n            logging.debug(\n                f\">[Level {level}] Node \"\n                f\"[{number}] Summary text: \"\n                f\"{ truncate_text(debug_str, 100) }\"\n            )\n            result_response = self._query_with_selected_node(\n                selected_node,\n                query_str,\n                prev_response=result_response,\n                level=level,\n            )\n        # result_response should not be None\n        return cast(str, result_response)\n\n    def _query(self, query_str: str) -> Response:\n        \"\"\"Answer a query.\"\"\"\n        # NOTE: this overrides the _query method in the base class\n        logging.info(f\"> Starting query: {query_str}\")\n        response_str = self._query_level(\n            self.index_struct.root_nodes,\n            query_str,\n            level=0,\n        ).strip()\n        return Response(response_str, source_nodes=self.response_builder.get_sources())\n", "doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "__type__": "Document"}, "c2a7f7f9-7c68-4251-9228-f0c3b499e202": {"text": "\nleaf_query.py is a Python file that implements a GPT Tree Index leaf query mechanism. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. The code uses a recursive approach to traverse the index graph and search for a leaf node that can best answer the query. It takes in a query template, a query template for multiple selections, and a child branch factor as arguments. The _query_level() method is used to answer a query recursively, prompting the user with a query template and extracting the numbers from the response to select the corresponding node. The query_with_selected_node() method is used to get a response for a selected node, and if a previous response is provided, the response will be updated with the answer. The code also has the ability to refine the response if a previous response is provided. The purpose of the code is to traverse the index graph and search for a leaf node that can best answer a query, and to provide a response for the selected node.", "doc_id": "c2a7f7f9-7c68-4251-9228-f0c3b499e202", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Leaf query mechanism.\"\"\"\n\nimport logging\nfrom typing import Any, Dict, Optional, cast\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.response.builder import ResponseBuilder\nfrom gpt_index.indices.utils import (\n    extract_numbers_given_response,\n    get_sorted_node_list,\n    truncate_text,\n)\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_QUERY_PROMPT,\n    DEFAULT_QUERY_PROMPT_MULTIPLE,\n)\nfrom gpt_index.prompts.prompts import TreeSelectMultiplePrompt, TreeSelectPrompt\nfrom gpt_index.response.schema import Response\n\n\nclass GPTTreeIndexLeafQuery(BaseGPTIndexQuery[IndexGraph]):\n    \"\"\"GPT Tree Index leaf query.\n\n    This class traverses the index graph and searches for a leaf node that can best\n    answer the query.\n\n    .. code-block:: python\n\n        response = index.query(\"<query_str>\", mode=\"default\")\n\n    Args:\n        query_template", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 0, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "1": {"text": "   Args:\n        query_template (Optional[TreeSelectPrompt]): Tree Select Query Prompt\n            (see :ref:`Prompt-Templates`).\n        query_template_multiple (Optional[TreeSelectMultiplePrompt]): Tree Select\n            Query Prompt (Multiple)\n            (see :ref:`Prompt-Templates`).\n        child_branch_factor (int): Number of child nodes to consider at each level.\n            If child_branch_factor is 1, then the query will only choose one child node\n            to traverse for any given parent node.\n            If child_branch_factor is 2, then the query will choose two child nodes.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        index_struct: IndexGraph,\n        query_template: Optional[TreeSelectPrompt] = None,\n        query_template_multiple: Optional[TreeSelectMultiplePrompt] = None,\n        child_branch_factor: int = 1,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 1, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "2": {"text": "       child_branch_factor: int = 1,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(index_struct, **kwargs)\n        self.query_template = query_template or DEFAULT_QUERY_PROMPT\n        self.query_template_multiple = (\n            query_template_multiple or DEFAULT_QUERY_PROMPT_MULTIPLE\n        )\n        self.child_branch_factor = child_branch_factor\n\n    def _query_with_selected_node(\n        self,\n        selected_node: Node,\n        query_str: str,\n        prev_response: Optional[str] = None,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Get response for selected node.\n\n        If not leaf node, it will recursively call _query on the child nodes.\n        If prev_response is provided, we will update prev_response with the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 2, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "3": {"text": "     If prev_response is provided, we will update prev_response with the answer.\n\n        \"\"\"\n        if len(selected_node.child_indices) == 0:\n            response_builder = ResponseBuilder(\n                self._prompt_helper,\n                self._llm_predictor,\n                self.text_qa_template,\n                self.refine_template,\n            )\n            self.response_builder.add_node(selected_node)\n            # use response builder to get answer from node\n            node_text, _ = self._get_text_from_node(\n                query_str, selected_node, level=level\n            )\n            cur_response = response_builder.get_response_over_chunks(\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 3, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "4": {"text": "               query_str, [node_text], prev_response=prev_response\n            )\n            logging.debug(f\">[Level {level}] Current answer response: {cur_response} \")\n        else:\n            cur_response = self._query_level(\n                {\n                    i: self.index_struct.all_nodes[i]\n                    for i in selected_node.child_indices\n                },\n                query_str,\n                level=level + 1,\n            )\n\n        if prev_response is None:\n            return cur_response\n        else:\n            context_msg = \"\\n\".join([selected_node.get_text(), cur_response])\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 4, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "5": {"text": "cur_response])\n            cur_response, formatted_refine_prompt = self._llm_predictor.predict(\n                self.refine_template,\n                query_str=query_str,\n                existing_answer=prev_response,\n                context_msg=context_msg,\n            )\n\n            logging.debug(f\">[Level {level}] Refine prompt: {formatted_refine_prompt}\")\n            logging.debug(f\">[Level {level}] Current refined response: {cur_response} \")\n            return cur_response\n\n    def _query_level(\n        self,\n        cur_nodes: Dict[int, Node],\n        query_str: str,\n        level: int = 0,\n    ) -> str:\n        \"\"\"Answer a query recursively.\"\"\"\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 5, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "6": {"text": "   \"\"\"Answer a query recursively.\"\"\"\n        cur_node_list = get_sorted_node_list(cur_nodes)\n\n        if self.child_branch_factor == 1:\n            query_template = self.query_template.partial_format(\n                num_chunks=len(cur_node_list), query_str=query_str\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template,\n                context_list=numbered_node_text,\n            )\n        else:\n            query_template_multiple =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 6, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "7": {"text": "else:\n            query_template_multiple = self.query_template_multiple.partial_format(\n                num_chunks=len(cur_node_list),\n                query_str=query_str,\n                branching_factor=self.child_branch_factor,\n            )\n            numbered_node_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_node_list, prompt=query_template_multiple\n            )\n            response, formatted_query_prompt = self._llm_predictor.predict(\n                query_template_multiple,\n                context_list=numbered_node_text,\n            )\n\n        logging.debug(\n            f\">[Level {level}] current prompt template:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 7, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "8": {"text": "       f\">[Level {level}] current prompt template: {formatted_query_prompt}\"\n        )\n\n        numbers = extract_numbers_given_response(response, n=self.child_branch_factor)\n        if numbers is None:\n            logging.debug(\n                f\">[Level {level}] Could not retrieve response - no numbers present\"\n            )\n            # just join text from current nodes as response\n            return response\n        result_response = None\n        for number_str in numbers:\n            number = int(number_str)\n            if number > len(cur_node_list):\n                logging.debug(\n                    f\">[Level {level}] Invalid response: {response} - \"\n                    f\"number {number} out of", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 8, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "9": {"text": "            f\"number {number} out of range\"\n                )\n                return response\n\n            # number is 1-indexed, so subtract 1\n            selected_node = cur_node_list[number - 1]\n\n            logging.info(\n                f\">[Level {level}] Selected node: \"\n                f\"[{number}]/[{','.join([str(int(n)) for n in numbers])}]\"\n            )\n            debug_str = \" \".join(selected_node.get_text().splitlines())\n            logging.debug(\n                f\">[Level {level}] Node \"\n                f\"[{number}] Summary text: \"\n                f\"{ truncate_text(debug_str, 100) }\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 9, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "10": {"text": "  f\"{ truncate_text(debug_str, 100) }\"\n            )\n            result_response = self._query_with_selected_node(\n                selected_node,\n                query_str,\n                prev_response=result_response,\n                level=level,\n            )\n        # result_response should not be None\n        return cast(str, result_response)\n\n    def _query(self, query_str: str) -> Response:\n        \"\"\"Answer a query.\"\"\"\n        # NOTE: this overrides the _query method in the base class\n        logging.info(f\"> Starting query: {query_str}\")\n        response_str = self._query_level(\n            self.index_struct.root_nodes,\n            query_str,\n            level=0,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 10, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "11": {"text": "           level=0,\n        ).strip()\n        return Response(response_str, source_nodes=self.response_builder.get_sources())\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/query/tree/leaf_query.py", "file_name": "leaf_query.py"}, "index": 11, "child_indices": [], "ref_doc_id": "6317248da78605b9ee03504c5343c039423e3e4b", "node_info": null}, "12": {"text": "This code file implements a GPT Tree Index leaf query mechanism. It traverses the index graph and searches for a leaf node that can best answer the query. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. It also has the ability to refine the response if a previous response is provided. It uses a child branch factor to determine how many child nodes to consider at each level.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "leaf_query.py is a Python file that contains functions for querying a tree-based index structure. It overrides the _query method in the base class to answer a query. It uses a recursive approach to traverse the tree structure and find the best matching node for the query. It then calls the _query_with_selected_node function to query the selected node and return the response. The response is then returned as a Response object with the source nodes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"12": {"text": "This code file implements a GPT Tree Index leaf query mechanism. It traverses the index graph and searches for a leaf node that can best answer the query. It uses a Tree Select Query Prompt to prompt the user for a response, and then uses a ResponseBuilder to get the answer from the node. It also has the ability to refine the response if a previous response is provided. It uses a child branch factor to determine how many child nodes to consider at each level.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "leaf_query.py is a Python file that contains functions for querying a tree-based index structure. It overrides the _query method in the base class to answer a query. It uses a recursive approach to traverse the tree structure and find the best matching node for the query. It then calls the _query_with_selected_node function to query the selected node and return the response. The response is then returned as a Response object with the source nodes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}