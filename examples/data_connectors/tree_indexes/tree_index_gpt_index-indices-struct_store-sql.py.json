{"index_struct": {"text": "\nThe GPTSQLStructStoreIndex is a GPT index that allows users to store and query data from a SQL database. It can be used to infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. The index supports raw SQL queries and natural language queries, as well as context documents and a SQL context builder to build context for the specified table. It also stores the python types of each column in the table. The purpose of the code is to provide a way for users to query data stored in a SQL database using either raw SQL queries or natural language queries, and to store the python types of each column in the table. The class takes in parameters such as a SQLDatabase, table name, table, table context, SQLContextBuilder, and context documents. It also has a method to get the query map, which is used to map query modes to the appropriate query class, and the _insert_datapoint and _preprocess_query methods to insert and preprocess queries, respectively.", "doc_id": "3497c4c7-4c20-459e-a64d-6a6889aee764", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"SQLite structured store.\"\"\"\n\nfrom typing import Any, Dict, List, Optional, Sequence, Type, cast\n\nfrom sqlalchemy import Table\n\nfrom gpt_index.data_structs.table import SQLStructTable, StructDatapoint\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.struct_store.sql import (\n    GPTNLStructStoreIndexQuery,\n    GPTSQLStructStoreIndexQuery,\n)\nfrom gpt_index.indices.struct_store.base import BaseGPTStructStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTSQLStructStoreIndex(BaseGPTStructStoreIndex[SQLStructTable]):\n    \"\"\"Base GPT SQL Struct Store Index.\n\n    The GPTSQLStructStoreIndex is an index that uses a SQL database\n    under the hood. During index construction, the data can be inferred\n    from unstructured documents given a schema extract prompt,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 0, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "1": {"text": "   from unstructured documents given a schema extract prompt,\n    or it can be pre-loaded in the database.\n\n    During query time, the user can either specify a raw SQL query\n    or a natural language query to retrieve their data.\n\n    Args:\n        sql_database (Optional[SQLDatabase]): SQL database to use,\n            including table names to specify.\n            See :ref:`Ref-Struct-Store` for more details.\n        table_name (Optional[str]): Name of the table to use\n            for extracting data.\n            Either table_name or table must be specified.\n        table (Optional[Table]): SQLAlchemy Table object to use.\n            Specifying the Table object explicitly, instead of\n            the table name, allows you to pass in a view.\n            Either table_name or table must be specified.\n        table_context_dict (Optional[Dict[str, str]]): Optional table context to use.\n            If specified,\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 1, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "2": {"text": "          If specified,\n            sql_context_builder and context_documents cannot be specified.\n        sql_context_builder (Optional[SQLContextBuilder]): SQL context builder.\n            If specified, the context builder will be used to build\n            context for the specified table, which will then be used during\n            query-time. Also if specified, context_documents must be specified,\n            and table_context cannot be specified.\n        context_documents_dict (Optional[Dict[str, List[BaseDocument]]]):\n            Optional context\n            documents to inform the sql_context_builder. Must be specified if\n            sql_context_builder is specified. Cannot be specified if table_context\n            is specified.\n\n    \"\"\"\n\n    index_struct_cls = SQLStructTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 2, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "3": {"text": "= None,\n        index_struct: Optional[SQLStructTable] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        sql_database: Optional[SQLDatabase] = None,\n        table_name: Optional[str] = None,\n        table: Optional[Table] = None,\n        ref_doc_id_column: Optional[str] = None,\n        table_context_dict: Optional[Dict[str, str]] = None,\n        sql_context_builder: Optional[SQLContextBuilder] = None,\n        context_documents_dict: Optional[Dict[str, List[BaseDocument]]] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # currently the user must specify a table info\n        if table_name is None and table is None:\n            raise ValueError(\"table_name must be specified\")\n        self.table_name = table_name or cast(Table, table).name\n        if sql_database is None:\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 3, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "4": {"text": "       if sql_database is None:\n            raise ValueError(\"sql_database must be specified\")\n        self.sql_database = sql_database\n        if table is None:\n            table = self.sql_database.metadata_obj.tables[table_name]\n        # if ref_doc_id_column is specified, then we need to check that\n        # it is a valid column in the table\n        col_names = [c.name for c in table.c]\n        if ref_doc_id_column is not None and ref_doc_id_column not in col_names:\n            raise ValueError(\n                f\"ref_doc_id_column {ref_doc_id_column} not in table {table_name}\"\n            )\n        self.ref_doc_id_column = ref_doc_id_column\n        # then store python types of each column\n        self._col_types_map: Dict[str, type] = {\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 4, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "5": {"text": "type] = {\n            c.name: table.c[c.name].type.python_type for c in table.c\n        }\n\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n        # if context builder is specified, then add to context_dict\n        if table_context_dict is not None and (\n            sql_context_builder is not None or context_documents_dict is not None\n        ):\n            raise ValueError(\n                \"Cannot specify both table_context_dict and \"\n                \"sql_context_builder/context_documents_dict\"\n            )\n        if sql_context_builder is not None:\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 5, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "6": {"text": "is not None:\n            if context_documents_dict is None:\n                raise ValueError(\n                    \"context_documents_dict must be specified if \"\n                    \"sql_context_builder is specified\"\n                )\n            context_documents_dict = cast(\n                Dict[str, List[BaseDocument]], context_documents_dict\n            )\n            context_dict: Dict[\n                str, str\n            ] = sql_context_builder.build_all_context_from_documents(\n                context_documents_dict\n            )\n        elif table_context_dict is not None:\n            context_dict = table_context_dict\n        else:\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 6, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "7": {"text": "= table_context_dict\n        else:\n            context_dict = {}\n\n        # validate context_dict keys are valid table names\n        context_keys = set(context_dict.keys())\n        if not context_keys.issubset(set(self.sql_database.get_table_names())):\n            raise ValueError(\n                \"Invalid context table names: \"\n                f\"{context_keys - set(self.sql_database.get_table_names())}\"\n            )\n\n        self._index_struct.context_dict.update(context_dict)\n        self._sql_context_builder = sql_context_builder\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTNLStructStoreIndexQuery,\n            QueryMode.SQL:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 7, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "8": {"text": "           QueryMode.SQL: GPTSQLStructStoreIndexQuery,\n        }\n\n    def _get_col_types_map(self) -> Dict[str, type]:\n        \"\"\"Get col types map for schema.\"\"\"\n        return self._col_types_map\n\n    def _get_schema_text(self) -> str:\n        \"\"\"Insert datapoint into index.\"\"\"\n        return self.sql_database.get_single_table_info(self.table_name)\n\n    def _insert_datapoint(self, datapoint: StructDatapoint) -> None:\n        \"\"\"Insert datapoint into index.\"\"\"\n        datapoint_dict = datapoint.to_dict()[\"fields\"]\n        self.sql_database.insert_into_table(\n            self.table_name, cast(Dict[Any, Any], datapoint_dict)\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 8, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "9": {"text": "      This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along sql_database, table_name\n        query_kwargs[\"sql_database\"] = self.sql_database\n        if mode == QueryMode.DEFAULT:\n            query_kwargs[\"ref_doc_id_column\"] = self.ref_doc_id_column\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 9, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "10": {"text": "The GPTSQLStructStoreIndex is a GPT index that uses a SQL database to store data. It can either infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. During query time, the user can either specify a raw SQL query or a natural language query to retrieve their data. The index also supports context documents and a SQL context builder to build context for the specified table. The index also stores the python types of each column in the table.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "The GPTSQLStructStoreIndex is a GPT index that uses a SQL database to store data. It can either infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. During query time, the user can either specify a raw SQL query or a natural language query to retrieve their data. The index also supports context documents and a SQL context builder to build context for the specified table. The index also stores the python types of each column in the table.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"9b52c03318a639e578f5784857f4fa6403f1c7e2": {"text": "\"\"\"SQLite structured store.\"\"\"\n\nfrom typing import Any, Dict, List, Optional, Sequence, Type, cast\n\nfrom sqlalchemy import Table\n\nfrom gpt_index.data_structs.table import SQLStructTable, StructDatapoint\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.struct_store.sql import (\n    GPTNLStructStoreIndexQuery,\n    GPTSQLStructStoreIndexQuery,\n)\nfrom gpt_index.indices.struct_store.base import BaseGPTStructStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTSQLStructStoreIndex(BaseGPTStructStoreIndex[SQLStructTable]):\n    \"\"\"Base GPT SQL Struct Store Index.\n\n    The GPTSQLStructStoreIndex is an index that uses a SQL database\n    under the hood. During index construction, the data can be inferred\n    from unstructured documents given a schema extract prompt,\n    or it can be pre-loaded in the database.\n\n    During query time, the user can either specify a raw SQL query\n    or a natural language query to retrieve their data.\n\n    Args:\n        sql_database (Optional[SQLDatabase]): SQL database to use,\n            including table names to specify.\n            See :ref:`Ref-Struct-Store` for more details.\n        table_name (Optional[str]): Name of the table to use\n            for extracting data.\n            Either table_name or table must be specified.\n        table (Optional[Table]): SQLAlchemy Table object to use.\n            Specifying the Table object explicitly, instead of\n            the table name, allows you to pass in a view.\n            Either table_name or table must be specified.\n        table_context_dict (Optional[Dict[str, str]]): Optional table context to use.\n            If specified,\n            sql_context_builder and context_documents cannot be specified.\n        sql_context_builder (Optional[SQLContextBuilder]): SQL context builder.\n            If specified, the context builder will be used to build\n            context for the specified table, which will then be used during\n            query-time. Also if specified, context_documents must be specified,\n            and table_context cannot be specified.\n        context_documents_dict (Optional[Dict[str, List[BaseDocument]]]):\n            Optional context\n            documents to inform the sql_context_builder. Must be specified if\n            sql_context_builder is specified. Cannot be specified if table_context\n            is specified.\n\n    \"\"\"\n\n    index_struct_cls = SQLStructTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[SQLStructTable] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        sql_database: Optional[SQLDatabase] = None,\n        table_name: Optional[str] = None,\n        table: Optional[Table] = None,\n        ref_doc_id_column: Optional[str] = None,\n        table_context_dict: Optional[Dict[str, str]] = None,\n        sql_context_builder: Optional[SQLContextBuilder] = None,\n        context_documents_dict: Optional[Dict[str, List[BaseDocument]]] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # currently the user must specify a table info\n        if table_name is None and table is None:\n            raise ValueError(\"table_name must be specified\")\n        self.table_name = table_name or cast(Table, table).name\n        if sql_database is None:\n            raise ValueError(\"sql_database must be specified\")\n        self.sql_database = sql_database\n        if table is None:\n            table = self.sql_database.metadata_obj.tables[table_name]\n        # if ref_doc_id_column is specified, then we need to check that\n        # it is a valid column in the table\n        col_names = [c.name for c in table.c]\n        if ref_doc_id_column is not None and ref_doc_id_column not in col_names:\n            raise ValueError(\n                f\"ref_doc_id_column {ref_doc_id_column} not in table {table_name}\"\n            )\n        self.ref_doc_id_column = ref_doc_id_column\n        # then store python types of each column\n        self._col_types_map: Dict[str, type] = {\n            c.name: table.c[c.name].type.python_type for c in table.c\n        }\n\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n        # if context builder is specified, then add to context_dict\n        if table_context_dict is not None and (\n            sql_context_builder is not None or context_documents_dict is not None\n        ):\n            raise ValueError(\n                \"Cannot specify both table_context_dict and \"\n                \"sql_context_builder/context_documents_dict\"\n            )\n        if sql_context_builder is not None:\n            if context_documents_dict is None:\n                raise ValueError(\n                    \"context_documents_dict must be specified if \"\n                    \"sql_context_builder is specified\"\n                )\n            context_documents_dict = cast(\n                Dict[str, List[BaseDocument]], context_documents_dict\n            )\n            context_dict: Dict[\n                str, str\n            ] = sql_context_builder.build_all_context_from_documents(\n                context_documents_dict\n            )\n        elif table_context_dict is not None:\n            context_dict = table_context_dict\n        else:\n            context_dict = {}\n\n        # validate context_dict keys are valid table names\n        context_keys = set(context_dict.keys())\n        if not context_keys.issubset(set(self.sql_database.get_table_names())):\n            raise ValueError(\n                \"Invalid context table names: \"\n                f\"{context_keys - set(self.sql_database.get_table_names())}\"\n            )\n\n        self._index_struct.context_dict.update(context_dict)\n        self._sql_context_builder = sql_context_builder\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTNLStructStoreIndexQuery,\n            QueryMode.SQL: GPTSQLStructStoreIndexQuery,\n        }\n\n    def _get_col_types_map(self) -> Dict[str, type]:\n        \"\"\"Get col types map for schema.\"\"\"\n        return self._col_types_map\n\n    def _get_schema_text(self) -> str:\n        \"\"\"Insert datapoint into index.\"\"\"\n        return self.sql_database.get_single_table_info(self.table_name)\n\n    def _insert_datapoint(self, datapoint: StructDatapoint) -> None:\n        \"\"\"Insert datapoint into index.\"\"\"\n        datapoint_dict = datapoint.to_dict()[\"fields\"]\n        self.sql_database.insert_into_table(\n            self.table_name, cast(Dict[Any, Any], datapoint_dict)\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along sql_database, table_name\n        query_kwargs[\"sql_database\"] = self.sql_database\n        if mode == QueryMode.DEFAULT:\n            query_kwargs[\"ref_doc_id_column\"] = self.ref_doc_id_column\n", "doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "__type__": "Document"}, "3497c4c7-4c20-459e-a64d-6a6889aee764": {"text": "\nThe GPTSQLStructStoreIndex is a GPT index that allows users to store and query data from a SQL database. It can be used to infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. The index supports raw SQL queries and natural language queries, as well as context documents and a SQL context builder to build context for the specified table. It also stores the python types of each column in the table. The purpose of the code is to provide a way for users to query data stored in a SQL database using either raw SQL queries or natural language queries, and to store the python types of each column in the table. The class takes in parameters such as a SQLDatabase, table name, table, table context, SQLContextBuilder, and context documents. It also has a method to get the query map, which is used to map query modes to the appropriate query class, and the _insert_datapoint and _preprocess_query methods to insert and preprocess queries, respectively.", "doc_id": "3497c4c7-4c20-459e-a64d-6a6889aee764", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"SQLite structured store.\"\"\"\n\nfrom typing import Any, Dict, List, Optional, Sequence, Type, cast\n\nfrom sqlalchemy import Table\n\nfrom gpt_index.data_structs.table import SQLStructTable, StructDatapoint\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.struct_store.sql import (\n    GPTNLStructStoreIndexQuery,\n    GPTSQLStructStoreIndexQuery,\n)\nfrom gpt_index.indices.struct_store.base import BaseGPTStructStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTSQLStructStoreIndex(BaseGPTStructStoreIndex[SQLStructTable]):\n    \"\"\"Base GPT SQL Struct Store Index.\n\n    The GPTSQLStructStoreIndex is an index that uses a SQL database\n    under the hood. During index construction, the data can be inferred\n    from unstructured documents given a schema extract prompt,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 0, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "1": {"text": "   from unstructured documents given a schema extract prompt,\n    or it can be pre-loaded in the database.\n\n    During query time, the user can either specify a raw SQL query\n    or a natural language query to retrieve their data.\n\n    Args:\n        sql_database (Optional[SQLDatabase]): SQL database to use,\n            including table names to specify.\n            See :ref:`Ref-Struct-Store` for more details.\n        table_name (Optional[str]): Name of the table to use\n            for extracting data.\n            Either table_name or table must be specified.\n        table (Optional[Table]): SQLAlchemy Table object to use.\n            Specifying the Table object explicitly, instead of\n            the table name, allows you to pass in a view.\n            Either table_name or table must be specified.\n        table_context_dict (Optional[Dict[str, str]]): Optional table context to use.\n            If specified,\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 1, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "2": {"text": "          If specified,\n            sql_context_builder and context_documents cannot be specified.\n        sql_context_builder (Optional[SQLContextBuilder]): SQL context builder.\n            If specified, the context builder will be used to build\n            context for the specified table, which will then be used during\n            query-time. Also if specified, context_documents must be specified,\n            and table_context cannot be specified.\n        context_documents_dict (Optional[Dict[str, List[BaseDocument]]]):\n            Optional context\n            documents to inform the sql_context_builder. Must be specified if\n            sql_context_builder is specified. Cannot be specified if table_context\n            is specified.\n\n    \"\"\"\n\n    index_struct_cls = SQLStructTable\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 2, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "3": {"text": "= None,\n        index_struct: Optional[SQLStructTable] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        sql_database: Optional[SQLDatabase] = None,\n        table_name: Optional[str] = None,\n        table: Optional[Table] = None,\n        ref_doc_id_column: Optional[str] = None,\n        table_context_dict: Optional[Dict[str, str]] = None,\n        sql_context_builder: Optional[SQLContextBuilder] = None,\n        context_documents_dict: Optional[Dict[str, List[BaseDocument]]] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        # currently the user must specify a table info\n        if table_name is None and table is None:\n            raise ValueError(\"table_name must be specified\")\n        self.table_name = table_name or cast(Table, table).name\n        if sql_database is None:\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 3, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "4": {"text": "       if sql_database is None:\n            raise ValueError(\"sql_database must be specified\")\n        self.sql_database = sql_database\n        if table is None:\n            table = self.sql_database.metadata_obj.tables[table_name]\n        # if ref_doc_id_column is specified, then we need to check that\n        # it is a valid column in the table\n        col_names = [c.name for c in table.c]\n        if ref_doc_id_column is not None and ref_doc_id_column not in col_names:\n            raise ValueError(\n                f\"ref_doc_id_column {ref_doc_id_column} not in table {table_name}\"\n            )\n        self.ref_doc_id_column = ref_doc_id_column\n        # then store python types of each column\n        self._col_types_map: Dict[str, type] = {\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 4, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "5": {"text": "type] = {\n            c.name: table.c[c.name].type.python_type for c in table.c\n        }\n\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            **kwargs,\n        )\n\n        # if context builder is specified, then add to context_dict\n        if table_context_dict is not None and (\n            sql_context_builder is not None or context_documents_dict is not None\n        ):\n            raise ValueError(\n                \"Cannot specify both table_context_dict and \"\n                \"sql_context_builder/context_documents_dict\"\n            )\n        if sql_context_builder is not None:\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 5, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "6": {"text": "is not None:\n            if context_documents_dict is None:\n                raise ValueError(\n                    \"context_documents_dict must be specified if \"\n                    \"sql_context_builder is specified\"\n                )\n            context_documents_dict = cast(\n                Dict[str, List[BaseDocument]], context_documents_dict\n            )\n            context_dict: Dict[\n                str, str\n            ] = sql_context_builder.build_all_context_from_documents(\n                context_documents_dict\n            )\n        elif table_context_dict is not None:\n            context_dict = table_context_dict\n        else:\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 6, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "7": {"text": "= table_context_dict\n        else:\n            context_dict = {}\n\n        # validate context_dict keys are valid table names\n        context_keys = set(context_dict.keys())\n        if not context_keys.issubset(set(self.sql_database.get_table_names())):\n            raise ValueError(\n                \"Invalid context table names: \"\n                f\"{context_keys - set(self.sql_database.get_table_names())}\"\n            )\n\n        self._index_struct.context_dict.update(context_dict)\n        self._sql_context_builder = sql_context_builder\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTNLStructStoreIndexQuery,\n            QueryMode.SQL:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 7, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "8": {"text": "           QueryMode.SQL: GPTSQLStructStoreIndexQuery,\n        }\n\n    def _get_col_types_map(self) -> Dict[str, type]:\n        \"\"\"Get col types map for schema.\"\"\"\n        return self._col_types_map\n\n    def _get_schema_text(self) -> str:\n        \"\"\"Insert datapoint into index.\"\"\"\n        return self.sql_database.get_single_table_info(self.table_name)\n\n    def _insert_datapoint(self, datapoint: StructDatapoint) -> None:\n        \"\"\"Insert datapoint into index.\"\"\"\n        datapoint_dict = datapoint.to_dict()[\"fields\"]\n        self.sql_database.insert_into_table(\n            self.table_name, cast(Dict[Any, Any], datapoint_dict)\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 8, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "9": {"text": "      This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along sql_database, table_name\n        query_kwargs[\"sql_database\"] = self.sql_database\n        if mode == QueryMode.DEFAULT:\n            query_kwargs[\"ref_doc_id_column\"] = self.ref_doc_id_column\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/struct_store/sql.py", "file_name": "sql.py"}, "index": 9, "child_indices": [], "ref_doc_id": "9b52c03318a639e578f5784857f4fa6403f1c7e2", "node_info": null}, "10": {"text": "The GPTSQLStructStoreIndex is a GPT index that uses a SQL database to store data. It can either infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. During query time, the user can either specify a raw SQL query or a natural language query to retrieve their data. The index also supports context documents and a SQL context builder to build context for the specified table. The index also stores the python types of each column in the table.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "The GPTSQLStructStoreIndex is a GPT index that uses a SQL database to store data. It can either infer data from unstructured documents given a schema extract prompt, or it can be pre-loaded in the database. During query time, the user can either specify a raw SQL query or a natural language query to retrieve their data. The index also supports context documents and a SQL context builder to build context for the specified table. The index also stores the python types of each column in the table.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}