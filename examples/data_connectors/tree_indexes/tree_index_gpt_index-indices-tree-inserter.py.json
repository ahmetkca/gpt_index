{"index_struct": {"text": "\nGPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method splits the document into text chunks and inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed. This allows for efficient storage and retrieval of documents in the GPT Tree Index. The class uses a PromptHelper to generate a text summary of the nodes, an LLMPredictor to generate a summary of the text, and a number of children to determine when to consolidate nodes. It also has two prompts, an insert prompt and a summary prompt, which are used to generate the text summary and the summary of the text respectively. The insert_node() and _insert_under_parent_and_consolidate() functions are used to insert a new node into the IndexGraph and consolidate nodes when the number of children exceeds the number of children limit. The _update_summary_for_parent_node() function is used to update the summary for the parent node.", "doc_id": "077ab348-81e6-41c8-8b6b-c6d31c5ecc26", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 0, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "1": {"text": "       summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 1, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "2": {"text": "       \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n            ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 2, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "3": {"text": "     # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 3, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "4": {"text": "       )\n            summary1, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk2\n            )\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 4, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "5": {"text": "          )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n                self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 5, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "6": {"text": "       self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 6, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "7": {"text": "  else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n                self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 7, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "8": {"text": "just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 8, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "9": {"text": "= self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 9, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "10": {"text": "GPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method takes in a BaseDocument and splits it into text chunks. It then inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "GPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method takes in a BaseDocument and splits it into text chunks. It then inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"9fec09d19ce22bfae0b185a7f3c383cc178ef2e7": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n            ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n            summary1, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk2\n            )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n                self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n                self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "__type__": "Document"}, "077ab348-81e6-41c8-8b6b-c6d31c5ecc26": {"text": "\nGPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method splits the document into text chunks and inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed. This allows for efficient storage and retrieval of documents in the GPT Tree Index. The class uses a PromptHelper to generate a text summary of the nodes, an LLMPredictor to generate a summary of the text, and a number of children to determine when to consolidate nodes. It also has two prompts, an insert prompt and a summary prompt, which are used to generate the text summary and the summary of the text respectively. The insert_node() and _insert_under_parent_and_consolidate() functions are used to insert a new node into the IndexGraph and consolidate nodes when the number of children exceeds the number of children limit. The _update_summary_for_parent_node() function is used to update the summary for the parent node.", "doc_id": "077ab348-81e6-41c8-8b6b-c6d31c5ecc26", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"GPT Tree Index inserter.\"\"\"\n\nfrom typing import Optional\n\nfrom gpt_index.data_structs.data_structs import IndexGraph, Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.utils import extract_numbers_given_response, get_sorted_node_list\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.prompts.default_prompts import (\n    DEFAULT_INSERT_PROMPT,\n    DEFAULT_SUMMARY_PROMPT,\n)\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTIndexInserter:\n    \"\"\"GPT Index inserter.\"\"\"\n\n    def __init__(\n        self,\n        index_graph: IndexGraph,\n        llm_predictor: LLMPredictor,\n        prompt_helper: PromptHelper,\n        num_children: int = 10,\n        insert_prompt: Prompt = DEFAULT_INSERT_PROMPT,\n        summary_prompt: Prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 0, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "1": {"text": "       summary_prompt: Prompt = DEFAULT_SUMMARY_PROMPT,\n    ) -> None:\n        \"\"\"Initialize with params.\"\"\"\n        if num_children < 2:\n            raise ValueError(\"Invalid number of children.\")\n        self.num_children = num_children\n        self.summary_prompt = summary_prompt\n        self.insert_prompt = insert_prompt\n        self.index_graph = index_graph\n        self._llm_predictor = llm_predictor\n        self._prompt_helper = prompt_helper\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.summary_prompt, self.num_children\n        )\n\n    def _insert_under_parent_and_consolidate(\n        self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node under parent and consolidate.\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 1, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "2": {"text": "       \"\"\"Insert node under parent and consolidate.\n\n        Consolidation will happen by dividing up child nodes, and creating a new\n        intermediate layer of nodes.\n\n        \"\"\"\n        # perform insertion\n        text_node = Node(\n            text=text_chunk,\n            index=self.index_graph.size,\n            ref_doc_id=doc.get_doc_id(),\n            embedding=doc.embedding,\n            extra_info=doc.extra_info,\n        )\n        self.index_graph.insert_under_parent(text_node, parent_node)\n\n        # if under num_children limit, then we're fine\n        if len(self.index_graph.get_children(parent_node)) <= self.num_children:\n            return\n        else:\n            # perform consolidation\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 2, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "3": {"text": "     # perform consolidation\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            # this layer is all leaf nodes, consolidate and split leaf nodes\n            cur_node_index = self.index_graph.size\n            # consolidate and split leaf nodes in half\n            # TODO: do better splitting (with a GPT prompt etc.)\n            half1 = cur_graph_node_list[: len(cur_graph_nodes) // 2]\n            half2 = cur_graph_node_list[len(cur_graph_nodes) // 2 :]\n\n            text_chunk1 = self._prompt_helper.get_text_from_nodes(\n                half1, prompt=self.summary_prompt\n            )\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 3, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "4": {"text": "       )\n            summary1, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk1\n            )\n            node1 = Node(\n                text=summary1,\n                index=cur_node_index,\n                child_indices={n.index for n in half1},\n            )\n\n            text_chunk2 = self._prompt_helper.get_text_from_nodes(\n                half2, prompt=self.summary_prompt\n            )\n            summary2, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk2\n            )\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 4, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "5": {"text": "          )\n            node2 = Node(\n                text=summary2,\n                index=cur_node_index + 1,\n                child_indices={n.index for n in half2},\n            )\n\n            # insert half1 and half2 as new children of parent_node\n            # first remove child indices from parent node\n            if parent_node is not None:\n                parent_node.child_indices = set()\n            else:\n                self.index_graph.root_nodes = {}\n            self.index_graph.insert_under_parent(node1, parent_node)\n            self.index_graph.insert_under_parent(node2, parent_node)\n\n    def _insert_node(\n        self, text_chunk: str, doc:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 5, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "6": {"text": "       self, text_chunk: str, doc: BaseDocument, parent_node: Optional[Node]\n    ) -> None:\n        \"\"\"Insert node.\"\"\"\n        cur_graph_nodes = self.index_graph.get_children(parent_node)\n        cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n        # if cur_graph_nodes is empty (start with empty graph), then insert under\n        # parent (insert new root node)\n        if len(cur_graph_nodes) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # check if leaf nodes, then just insert under parent\n        elif len(cur_graph_node_list[0].child_indices) == 0:\n            self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n        # else try to find the right summary node to insert under\n        else:\n            numbered_text =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 6, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "7": {"text": "  else:\n            numbered_text = self._prompt_helper.get_numbered_text_from_nodes(\n                cur_graph_node_list, prompt=self.insert_prompt\n            )\n            response, _ = self._llm_predictor.predict(\n                self.insert_prompt,\n                new_chunk_text=text_chunk,\n                num_chunks=len(cur_graph_node_list),\n                context_list=numbered_text,\n            )\n            numbers = extract_numbers_given_response(response)\n            if numbers is None or len(numbers) == 0:\n                # NOTE: if we can't extract a number, then we just insert under parent\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 7, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "8": {"text": "just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            elif int(numbers[0]) > len(cur_graph_node_list):\n                # NOTE: if number is out of range, then we just insert under parent\n                self._insert_under_parent_and_consolidate(text_chunk, doc, parent_node)\n            else:\n                selected_node = cur_graph_node_list[int(numbers[0]) - 1]\n                self._insert_node(text_chunk, doc, selected_node)\n\n        # now we need to update summary for parent node, since we\n        # need to bubble updated summaries up the tree\n        if parent_node is not None:\n            # refetch children\n            cur_graph_nodes = self.index_graph.get_children(parent_node)\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 8, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "9": {"text": "= self.index_graph.get_children(parent_node)\n            cur_graph_node_list = get_sorted_node_list(cur_graph_nodes)\n            text_chunk = self._prompt_helper.get_text_from_nodes(\n                cur_graph_node_list, prompt=self.summary_prompt\n            )\n            new_summary, _ = self._llm_predictor.predict(\n                self.summary_prompt, context_str=text_chunk\n            )\n\n            parent_node.text = new_summary\n\n    def insert(self, doc: BaseDocument) -> None:\n        \"\"\"Insert into index_graph.\"\"\"\n        text_chunks = self._text_splitter.split_text(doc.get_text())\n\n        for text_chunk in text_chunks:\n            self._insert_node(text_chunk, doc, None)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/tree/inserter.py", "file_name": "inserter.py"}, "index": 9, "child_indices": [], "ref_doc_id": "9fec09d19ce22bfae0b185a7f3c383cc178ef2e7", "node_info": null}, "10": {"text": "GPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method takes in a BaseDocument and splits it into text chunks. It then inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "GPTIndexInserter is a class that provides a method to insert a document into a GPT Tree Index. It takes in an IndexGraph, LLMPredictor, PromptHelper, and two Prompts as parameters. The insert() method takes in a BaseDocument and splits it into text chunks. It then inserts each chunk into the IndexGraph, consolidating the nodes if necessary. It also updates the summary of the parent node if needed.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}