{"index_struct": {"text": "\nBaseGPTVectorStoreIndex is a class that provides a base for building a vector store index. It is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It uses a TokenTextSplitter to split text into tokens, and provides methods for building the index from documents, inserting documents, and adding documents to the index. The purpose of this class is to store and retrieve documents based on their embedding similarity. It provides a base for building a vector store index, which can be used to store and retrieve documents based on their embedding similarity.", "doc_id": "42454337-5571-4a3b-8479-95d438314718", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Base vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Generic, Optional, Sequence, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\nBID = TypeVar(\"BID\", bound=IndexStruct)\n\n\nclass BaseGPTVectorStoreIndex(BaseGPTIndex[BID], Generic[BID]):\n    \"\"\"Base GPT Vector Store Index.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "1": {"text": "  embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[BID] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "2": {"text": "          embed_model=embed_model,\n            **kwargs,\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @abstractmethod\n    def _add_document_to_index(\n        self,\n        index_struct: BID,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n\n    def _build_index_from_documents(self, documents: Sequence[BaseDocument]) -> BID:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "3": {"text": "           self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls()\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self._index_struct, document, self._text_splitter)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "4": {"text": "BaseGPTVectorStoreIndex is a class that provides a base GPT Vector Store Index. It is built on top of an existing vector store and is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It has methods for building the index from documents, inserting documents, and adding documents to the index. It also uses a TokenTextSplitter to split text into tokens. The purpose of this class is to provide a base for building a vector store index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 4, "child_indices": [0, 1, 2, 3], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"4": {"text": "BaseGPTVectorStoreIndex is a class that provides a base GPT Vector Store Index. It is built on top of an existing vector store and is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It has methods for building the index from documents, inserting documents, and adding documents to the index. It also uses a TokenTextSplitter to split text into tokens. The purpose of this class is to provide a base for building a vector store index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 4, "child_indices": [0, 1, 2, 3], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"e7576a555defa75d31ec9e716c927ee9b9e97d8f": {"text": "\"\"\"Base vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Generic, Optional, Sequence, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\nBID = TypeVar(\"BID\", bound=IndexStruct)\n\n\nclass BaseGPTVectorStoreIndex(BaseGPTIndex[BID], Generic[BID]):\n    \"\"\"Base GPT Vector Store Index.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[BID] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @abstractmethod\n    def _add_document_to_index(\n        self,\n        index_struct: BID,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n\n    def _build_index_from_documents(self, documents: Sequence[BaseDocument]) -> BID:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls()\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self._index_struct, document, self._text_splitter)\n", "doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "__type__": "Document"}, "42454337-5571-4a3b-8479-95d438314718": {"text": "\nBaseGPTVectorStoreIndex is a class that provides a base for building a vector store index. It is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It uses a TokenTextSplitter to split text into tokens, and provides methods for building the index from documents, inserting documents, and adding documents to the index. The purpose of this class is to store and retrieve documents based on their embedding similarity. It provides a base for building a vector store index, which can be used to store and retrieve documents based on their embedding similarity.", "doc_id": "42454337-5571-4a3b-8479-95d438314718", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Base vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom abc import abstractmethod\nfrom typing import Any, Generic, Optional, Sequence, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\nBID = TypeVar(\"BID\", bound=IndexStruct)\n\n\nclass BaseGPTVectorStoreIndex(BaseGPTIndex[BID], Generic[BID]):\n    \"\"\"Base GPT Vector Store Index.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "1": {"text": "  embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[BID] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "2": {"text": "          embed_model=embed_model,\n            **kwargs,\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @abstractmethod\n    def _add_document_to_index(\n        self,\n        index_struct: BID,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n\n    def _build_index_from_documents(self, documents: Sequence[BaseDocument]) -> BID:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "3": {"text": "           self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls()\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self._index_struct, document, self._text_splitter)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e7576a555defa75d31ec9e716c927ee9b9e97d8f", "node_info": null}, "4": {"text": "BaseGPTVectorStoreIndex is a class that provides a base GPT Vector Store Index. It is built on top of an existing vector store and is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It has methods for building the index from documents, inserting documents, and adding documents to the index. It also uses a TokenTextSplitter to split text into tokens. The purpose of this class is to provide a base for building a vector store index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 4, "child_indices": [0, 1, 2, 3], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"4": {"text": "BaseGPTVectorStoreIndex is a class that provides a base GPT Vector Store Index. It is built on top of an existing vector store and is initialized with parameters such as documents, index_struct, text_qa_template, llm_predictor, and embed_model. It has methods for building the index from documents, inserting documents, and adding documents to the index. It also uses a TokenTextSplitter to split text into tokens. The purpose of this class is to provide a base for building a vector store index.", "doc_id": null, "embedding": null, "extra_info": null, "index": 4, "child_indices": [0, 1, 2, 3], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}