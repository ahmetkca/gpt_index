{"index_struct": {"text": "\nThis code file implements a GPTFaissIndex, a data structure that uses the Faiss index to store document embeddings. The index is constructed by chunking up document texts, converting them to nodes with text, and encoding them in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTFaissIndex class provides methods for initializing the index, adding documents to the index, preprocessing queries, loading the index from disk, and saving the index to disk. The code also includes a delete function, which is not yet implemented for Faiss index. The purpose of the code is to provide an efficient way to store and retrieve similar documents.", "doc_id": "9b03b15f-4d7e-4ddc-b635-ae2f1c7377bf", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Faiss Vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nimport numpy as np\n\nfrom gpt_index.data_structs.data_structs import IndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.faiss import GPTFaissIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTFaissIndex(BaseGPTVectorStoreIndex[IndexDict]):\n    \"\"\"GPT Faiss Index.\n\n    The GPTFaissIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Faiss", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 0, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "1": {"text": "   embeddings, and those embeddings are stored within a Faiss index.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Faiss.\n\n    During query time, the index uses Faiss to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        faiss_index (faiss.Index): A Faiss Index object (required). Note: the index\n            will be reset during index construction.\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = IndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 1, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "2": {"text": "= None,\n        index_struct: Optional[IndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        faiss_index: Optional[Any] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        import_err_msg = \"\"\"\n            `faiss` package not found. For instructions on\n            how to install `faiss` please visit\n            https://github.com/facebookresearch/faiss/wiki/Installing-Faiss\n        \"\"\"\n        try:\n            import faiss  # noqa: F401\n        except ImportError:\n            raise ValueError(import_err_msg)\n\n        if faiss_index is None:\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 2, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "3": {"text": " if faiss_index is None:\n            raise ValueError(\"faiss_index cannot be None.\")\n        if documents is not None and faiss_index.ntotal > 0:\n            raise ValueError(\n                \"If building a GPTFaissIndex from scratch, faiss_index must be empty.\"\n            )\n        self._faiss_index = cast(faiss.Index, faiss_index)\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 3, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "4": {"text": "Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTFaissIndexQuery,\n            QueryMode.EMBEDDING: GPTFaissIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: IndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to FAISS\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 4, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "5": {"text": "               text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            text_embedding_np = np.array(text_embedding, dtype=\"float32\")[np.newaxis, :]\n            new_id = str(self._faiss_index.ntotal)\n            self._faiss_index.add(text_embedding_np)\n\n            # add to index\n            index_struct.add_node(n, text_id=new_id)\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 5, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "6": {"text": "     This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along faiss_index\n        query_kwargs[\"faiss_index\"] = self._faiss_index\n\n    @classmethod\n    def load_from_disk(\n        cls, save_path: str, faiss_index_save_path: Optional[str] = None, **kwargs: Any\n    ) -> \"BaseGPTIndex\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to load faiss index from a file - that\n        way, the user does not have to recreate the faiss index outside\n        of this", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 6, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "7": {"text": "not have to recreate the faiss index outside\n        of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n            **kwargs: Additional kwargs to pass to the index constructor.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss_index = faiss.read_index(faiss_index_save_path)\n            return super().load_from_disk(save_path, faiss_index=faiss_index, **kwargs)\n        else:\n            return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 7, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "8": {"text": "     else:\n            return super().load_from_disk(save_path, **kwargs)\n\n    def save_to_disk(\n        self,\n        save_path: str,\n        faiss_index_save_path: Optional[str] = None,\n        **save_kwargs: Any,\n    ) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to save the faiss index to a file - that\n        way, the user can pass in the same argument in\n        `GPTFaissIndex.load_from_disk` without having to recreate\n        the Faiss index outside of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 8, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "9": {"text": "The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n\n        \"\"\"\n        super().save_to_disk(save_path, **save_kwargs)\n\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss.write_index(self._faiss_index, faiss_index_save_path)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not yet implemented for Faiss index.\")\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 9, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "10": {"text": "The GPTFaissIndex is a data structure that uses the Faiss index to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The index can be saved to and loaded from disk, and additional query kwargs can be passed in to the query class.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "The GPTFaissIndex is a data structure that uses the Faiss index to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The index can be saved to and loaded from disk, and additional query kwargs can be passed in to the query class.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"f211883caf76a36c2a3c024807976f40924947fc": {"text": "\"\"\"Faiss Vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nimport numpy as np\n\nfrom gpt_index.data_structs.data_structs import IndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.faiss import GPTFaissIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTFaissIndex(BaseGPTVectorStoreIndex[IndexDict]):\n    \"\"\"GPT Faiss Index.\n\n    The GPTFaissIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Faiss index.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Faiss.\n\n    During query time, the index uses Faiss to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        faiss_index (faiss.Index): A Faiss Index object (required). Note: the index\n            will be reset during index construction.\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = IndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[IndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        faiss_index: Optional[Any] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        import_err_msg = \"\"\"\n            `faiss` package not found. For instructions on\n            how to install `faiss` please visit\n            https://github.com/facebookresearch/faiss/wiki/Installing-Faiss\n        \"\"\"\n        try:\n            import faiss  # noqa: F401\n        except ImportError:\n            raise ValueError(import_err_msg)\n\n        if faiss_index is None:\n            raise ValueError(\"faiss_index cannot be None.\")\n        if documents is not None and faiss_index.ntotal > 0:\n            raise ValueError(\n                \"If building a GPTFaissIndex from scratch, faiss_index must be empty.\"\n            )\n        self._faiss_index = cast(faiss.Index, faiss_index)\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTFaissIndexQuery,\n            QueryMode.EMBEDDING: GPTFaissIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: IndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to FAISS\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            text_embedding_np = np.array(text_embedding, dtype=\"float32\")[np.newaxis, :]\n            new_id = str(self._faiss_index.ntotal)\n            self._faiss_index.add(text_embedding_np)\n\n            # add to index\n            index_struct.add_node(n, text_id=new_id)\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along faiss_index\n        query_kwargs[\"faiss_index\"] = self._faiss_index\n\n    @classmethod\n    def load_from_disk(\n        cls, save_path: str, faiss_index_save_path: Optional[str] = None, **kwargs: Any\n    ) -> \"BaseGPTIndex\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to load faiss index from a file - that\n        way, the user does not have to recreate the faiss index outside\n        of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n            **kwargs: Additional kwargs to pass to the index constructor.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss_index = faiss.read_index(faiss_index_save_path)\n            return super().load_from_disk(save_path, faiss_index=faiss_index, **kwargs)\n        else:\n            return super().load_from_disk(save_path, **kwargs)\n\n    def save_to_disk(\n        self,\n        save_path: str,\n        faiss_index_save_path: Optional[str] = None,\n        **save_kwargs: Any,\n    ) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to save the faiss index to a file - that\n        way, the user can pass in the same argument in\n        `GPTFaissIndex.load_from_disk` without having to recreate\n        the Faiss index outside of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n\n        \"\"\"\n        super().save_to_disk(save_path, **save_kwargs)\n\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss.write_index(self._faiss_index, faiss_index_save_path)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not yet implemented for Faiss index.\")\n", "doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "__type__": "Document"}, "9b03b15f-4d7e-4ddc-b635-ae2f1c7377bf": {"text": "\nThis code file implements a GPTFaissIndex, a data structure that uses the Faiss index to store document embeddings. The index is constructed by chunking up document texts, converting them to nodes with text, and encoding them in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTFaissIndex class provides methods for initializing the index, adding documents to the index, preprocessing queries, loading the index from disk, and saving the index to disk. The code also includes a delete function, which is not yet implemented for Faiss index. The purpose of the code is to provide an efficient way to store and retrieve similar documents.", "doc_id": "9b03b15f-4d7e-4ddc-b635-ae2f1c7377bf", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Faiss Vector store index.\n\nAn index that that is built on top of an existing vector store.\n\n\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nimport numpy as np\n\nfrom gpt_index.data_structs.data_structs import IndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT, BaseGPTIndex\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.faiss import GPTFaissIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\n\n\nclass GPTFaissIndex(BaseGPTVectorStoreIndex[IndexDict]):\n    \"\"\"GPT Faiss Index.\n\n    The GPTFaissIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Faiss", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 0, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "1": {"text": "   embeddings, and those embeddings are stored within a Faiss index.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Faiss.\n\n    During query time, the index uses Faiss to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        faiss_index (faiss.Index): A Faiss Index object (required). Note: the index\n            will be reset during index construction.\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = IndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 1, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "2": {"text": "= None,\n        index_struct: Optional[IndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        faiss_index: Optional[Any] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        import_err_msg = \"\"\"\n            `faiss` package not found. For instructions on\n            how to install `faiss` please visit\n            https://github.com/facebookresearch/faiss/wiki/Installing-Faiss\n        \"\"\"\n        try:\n            import faiss  # noqa: F401\n        except ImportError:\n            raise ValueError(import_err_msg)\n\n        if faiss_index is None:\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 2, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "3": {"text": " if faiss_index is None:\n            raise ValueError(\"faiss_index cannot be None.\")\n        if documents is not None and faiss_index.ntotal > 0:\n            raise ValueError(\n                \"If building a GPTFaissIndex from scratch, faiss_index must be empty.\"\n            )\n        self._faiss_index = cast(faiss.Index, faiss_index)\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 3, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "4": {"text": "Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTFaissIndexQuery,\n            QueryMode.EMBEDDING: GPTFaissIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: IndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to FAISS\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 4, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "5": {"text": "               text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            text_embedding_np = np.array(text_embedding, dtype=\"float32\")[np.newaxis, :]\n            new_id = str(self._faiss_index.ntotal)\n            self._faiss_index.add(text_embedding_np)\n\n            # add to index\n            index_struct.add_node(n, text_id=new_id)\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Preprocess query.\n\n        This allows subclasses to pass in additional query kwargs\n        to query, for instance arguments that are shared between the\n        index and the query class. By default, this does nothing.\n        This also allows subclasses to do validation.\n\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 5, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "6": {"text": "     This also allows subclasses to do validation.\n\n        \"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # pass along faiss_index\n        query_kwargs[\"faiss_index\"] = self._faiss_index\n\n    @classmethod\n    def load_from_disk(\n        cls, save_path: str, faiss_index_save_path: Optional[str] = None, **kwargs: Any\n    ) -> \"BaseGPTIndex\":\n        \"\"\"Load index from disk.\n\n        This method loads the index from a JSON file stored on disk. The index data\n        structure itself is preserved completely. If the index is defined over\n        subindices, those subindices will also be preserved (and subindices of\n        those subindices, etc.).\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to load faiss index from a file - that\n        way, the user does not have to recreate the faiss index outside\n        of this", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 6, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "7": {"text": "not have to recreate the faiss index outside\n        of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n            **kwargs: Additional kwargs to pass to the index constructor.\n\n        Returns:\n            BaseGPTIndex: The loaded index.\n\n        \"\"\"\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss_index = faiss.read_index(faiss_index_save_path)\n            return super().load_from_disk(save_path, faiss_index=faiss_index, **kwargs)\n        else:\n            return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 7, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "8": {"text": "     else:\n            return super().load_from_disk(save_path, **kwargs)\n\n    def save_to_disk(\n        self,\n        save_path: str,\n        faiss_index_save_path: Optional[str] = None,\n        **save_kwargs: Any,\n    ) -> None:\n        \"\"\"Save to file.\n\n        This method stores the index into a JSON file stored on disk.\n        In GPTFaissIndex, we allow user to specify an additional\n        `faiss_index_save_path` to save the faiss index to a file - that\n        way, the user can pass in the same argument in\n        `GPTFaissIndex.load_from_disk` without having to recreate\n        the Faiss index outside of this class.\n\n        Args:\n            save_path (str): The save_path of the file.\n            faiss_index_save_path (Optional[str]): The save_path of the\n        ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 8, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "9": {"text": "The save_path of the\n                Faiss index file. If not specified, the Faiss index\n                will not be saved to disk.\n\n        \"\"\"\n        super().save_to_disk(save_path, **save_kwargs)\n\n        if faiss_index_save_path is not None:\n            import faiss\n\n            faiss.write_index(self._faiss_index, faiss_index_save_path)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        raise NotImplementedError(\"Delete not yet implemented for Faiss index.\")\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/faiss.py", "file_name": "faiss.py"}, "index": 9, "child_indices": [], "ref_doc_id": "f211883caf76a36c2a3c024807976f40924947fc", "node_info": null}, "10": {"text": "The GPTFaissIndex is a data structure that uses the Faiss index to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The index can be saved to and loaded from disk, and additional query kwargs can be passed in to the query class.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "The GPTFaissIndex is a data structure that uses the Faiss index to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Faiss. During query time, the index uses Faiss to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The index can be saved to and loaded from disk, and additional query kwargs can be passed in to the query class.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}