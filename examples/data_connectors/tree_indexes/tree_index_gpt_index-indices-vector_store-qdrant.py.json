{"index_struct": {"text": "\nqdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The _create_collection() function creates a Qdrant collection with a given collection name and vector size, while the _collection_exists() function checks if a given collection name exists in the Qdrant system. The GPTQdrantIndex class uses the Qdrant collection to store document embeddings. It provides methods for adding documents to the index, building the index from documents, and deleting documents from the index. It also provides a query map that maps query modes to the GPTQdrantIndexQuery class. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The code file uses the Qdrant client library to interact with the Qdrant system, a Question-Answer Prompt to chunk up the document texts, and an embedding model to generate embeddings for the documents.", "doc_id": "5555ac7e-0762-478e-b839-5f5aba2d7352", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Qdrant vector store index.\n\nAn index that is built on top of an existing Qdrant collection.\n\n\"\"\"\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nfrom gpt_index.data_structs.data_structs import QdrantIndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.qdrant import GPTQdrantIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTQdrantIndex(BaseGPTVectorStoreIndex[QdrantIndexStruct]):\n    \"\"\"GPT Qdrant Index.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 0, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "1": {"text": "   \"\"\"GPT Qdrant Index.\n\n    The GPTQdrantIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Qdrant collection.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Qdrant.\n\n    During query time, the index uses Qdrant to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n        client (Optional[Any]): QdrantClient instance from `qdrant-client` package\n        collection_name: (Optional[str]): name of the Qdrant collection\n    \"\"\"\n\n    index_struct_cls = QdrantIndexStruct\n\n    def __init__(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 1, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "2": {"text": "= QdrantIndexStruct\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[QdrantIndexStruct] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        client: Optional[Any] = None,\n        collection_name: Optional[str] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        import_err_msg = (\n            \"`qdrant-client` package not found, please run `pip install qdrant-client`\"\n        )\n        try:\n            import qdrant_client  # noqa: F401\n        except ImportError:\n            raise", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 2, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "3": {"text": "   except ImportError:\n            raise ValueError(import_err_msg)\n\n        if client is None:\n            raise ValueError(\"client cannot be None.\")\n\n        if collection_name is None and index_struct is not None:\n            collection_name = index_struct.collection_name\n        if collection_name is None:\n            raise ValueError(\"collection_name cannot be None.\")\n\n        self._client = cast(qdrant_client.QdrantClient, client)\n        self._collection_name = collection_name\n        self._collection_initialized = self._collection_exists(collection_name)\n\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents,\n            index_struct,\n            text_qa_template,\n            llm_predictor,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 3, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "4": {"text": " llm_predictor,\n            embed_model,\n            **kwargs\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTQdrantIndexQuery,\n            QueryMode.EMBEDDING: GPTQdrantIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: QdrantIndexStruct,\n        document: BaseDocument,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 4, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "5": {"text": "       document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        from qdrant_client.http import models as rest\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            collection_name = index_struct.get_collection_name()\n\n            # Create the Qdrant collection, if it does not exist yet\n            if not self._collection_initialized:\n                self._create_collection(\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 5, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "6": {"text": "  self._create_collection(\n                    collection_name=collection_name,\n                    vector_size=len(text_embedding),\n                )\n                self._collection_initialized = True\n\n            while True:\n                new_id = get_new_id(set())\n                try:\n                    self._client.http.points_api.get_point(\n                        collection_name=collection_name, id=new_id\n                    )\n                except UnexpectedResponse:\n                    break\n\n            payload = {\n                \"doc_id\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 6, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "7": {"text": "               \"doc_id\": document.get_doc_id(),\n                \"text\": n.get_text(),\n                \"index\": n.index,\n            }\n\n            self._client.upsert(\n                collection_name=collection_name,\n                points=[\n                    rest.PointStruct(\n                        id=new_id,\n                        vector=text_embedding,\n                        payload=payload,\n                    )\n                ],\n            )\n\n    def _build_index_from_documents(\n        self,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 7, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "8": {"text": "_build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> QdrantIndexStruct:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls(collection_name=self._collection_name)\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self.index_struct, document, self._text_splitter)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        from qdrant_client.http import models as", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 8, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "9": {"text": "       from qdrant_client.http import models as rest\n\n        self._client.delete(\n            collection_name=self._collection_name,\n            points_selector=rest.Filter(\n                must=[\n                    rest.FieldCondition(\n                        key=\"doc_id\", match=rest.MatchValue(value=doc_id)\n                    )\n                ]\n            ),\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # Pass along Qdrant client instance\n        query_kwargs[\"client\"] = self._client\n\n    def _create_collection(self, collection_name: str,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 9, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "10": {"text": "   def _create_collection(self, collection_name: str, vector_size: int) -> None:\n        \"\"\"Create a Qdrant collection.\"\"\"\n        from qdrant_client.http import models as rest\n\n        self._client.recreate_collection(\n            collection_name=collection_name,\n            vectors_config=rest.VectorParams(\n                size=vector_size,\n                distance=rest.Distance.COSINE,\n            ),\n        )\n\n    def _collection_exists(self, collection_name: str) -> bool:\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        try:\n            response = self._client.http.collections_api.get_collection(collection_name)\n            return response.result is not None\n        except UnexpectedResponse:\n            return False\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 10, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "11": {"text": "The GPTQdrantIndex is a data structure that uses an existing Qdrant collection to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTQdrantIndex class provides methods for adding documents to the index, deleting documents from the index, and creating a collection in Qdrant.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 11, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "12": {"text": "qdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The first function, _create_collection(), creates a Qdrant collection with a given collection name and vector size. The second function, _collection_exists(), checks if a given collection name exists in the Qdrant system. Both functions use the Qdrant client library to interact with the Qdrant system.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [10], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"11": {"text": "The GPTQdrantIndex is a data structure that uses an existing Qdrant collection to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTQdrantIndex class provides methods for adding documents to the index, deleting documents from the index, and creating a collection in Qdrant.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 11, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "12": {"text": "qdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The first function, _create_collection(), creates a Qdrant collection with a given collection name and vector size. The second function, _collection_exists(), checks if a given collection name exists in the Qdrant system. Both functions use the Qdrant client library to interact with the Qdrant system.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [10], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"bf1118e9a20657b90f4e5cbb9ae924330db5f50f": {"text": "\"\"\"Qdrant vector store index.\n\nAn index that is built on top of an existing Qdrant collection.\n\n\"\"\"\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nfrom gpt_index.data_structs.data_structs import QdrantIndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.qdrant import GPTQdrantIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTQdrantIndex(BaseGPTVectorStoreIndex[QdrantIndexStruct]):\n    \"\"\"GPT Qdrant Index.\n\n    The GPTQdrantIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Qdrant collection.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Qdrant.\n\n    During query time, the index uses Qdrant to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n        client (Optional[Any]): QdrantClient instance from `qdrant-client` package\n        collection_name: (Optional[str]): name of the Qdrant collection\n    \"\"\"\n\n    index_struct_cls = QdrantIndexStruct\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[QdrantIndexStruct] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        client: Optional[Any] = None,\n        collection_name: Optional[str] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        import_err_msg = (\n            \"`qdrant-client` package not found, please run `pip install qdrant-client`\"\n        )\n        try:\n            import qdrant_client  # noqa: F401\n        except ImportError:\n            raise ValueError(import_err_msg)\n\n        if client is None:\n            raise ValueError(\"client cannot be None.\")\n\n        if collection_name is None and index_struct is not None:\n            collection_name = index_struct.collection_name\n        if collection_name is None:\n            raise ValueError(\"collection_name cannot be None.\")\n\n        self._client = cast(qdrant_client.QdrantClient, client)\n        self._collection_name = collection_name\n        self._collection_initialized = self._collection_exists(collection_name)\n\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents,\n            index_struct,\n            text_qa_template,\n            llm_predictor,\n            embed_model,\n            **kwargs\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTQdrantIndexQuery,\n            QueryMode.EMBEDDING: GPTQdrantIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: QdrantIndexStruct,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        from qdrant_client.http import models as rest\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            collection_name = index_struct.get_collection_name()\n\n            # Create the Qdrant collection, if it does not exist yet\n            if not self._collection_initialized:\n                self._create_collection(\n                    collection_name=collection_name,\n                    vector_size=len(text_embedding),\n                )\n                self._collection_initialized = True\n\n            while True:\n                new_id = get_new_id(set())\n                try:\n                    self._client.http.points_api.get_point(\n                        collection_name=collection_name, id=new_id\n                    )\n                except UnexpectedResponse:\n                    break\n\n            payload = {\n                \"doc_id\": document.get_doc_id(),\n                \"text\": n.get_text(),\n                \"index\": n.index,\n            }\n\n            self._client.upsert(\n                collection_name=collection_name,\n                points=[\n                    rest.PointStruct(\n                        id=new_id,\n                        vector=text_embedding,\n                        payload=payload,\n                    )\n                ],\n            )\n\n    def _build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> QdrantIndexStruct:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls(collection_name=self._collection_name)\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self.index_struct, document, self._text_splitter)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        from qdrant_client.http import models as rest\n\n        self._client.delete(\n            collection_name=self._collection_name,\n            points_selector=rest.Filter(\n                must=[\n                    rest.FieldCondition(\n                        key=\"doc_id\", match=rest.MatchValue(value=doc_id)\n                    )\n                ]\n            ),\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # Pass along Qdrant client instance\n        query_kwargs[\"client\"] = self._client\n\n    def _create_collection(self, collection_name: str, vector_size: int) -> None:\n        \"\"\"Create a Qdrant collection.\"\"\"\n        from qdrant_client.http import models as rest\n\n        self._client.recreate_collection(\n            collection_name=collection_name,\n            vectors_config=rest.VectorParams(\n                size=vector_size,\n                distance=rest.Distance.COSINE,\n            ),\n        )\n\n    def _collection_exists(self, collection_name: str) -> bool:\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        try:\n            response = self._client.http.collections_api.get_collection(collection_name)\n            return response.result is not None\n        except UnexpectedResponse:\n            return False\n", "doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "__type__": "Document"}, "5555ac7e-0762-478e-b839-5f5aba2d7352": {"text": "\nqdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The _create_collection() function creates a Qdrant collection with a given collection name and vector size, while the _collection_exists() function checks if a given collection name exists in the Qdrant system. The GPTQdrantIndex class uses the Qdrant collection to store document embeddings. It provides methods for adding documents to the index, building the index from documents, and deleting documents from the index. It also provides a query map that maps query modes to the GPTQdrantIndexQuery class. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The code file uses the Qdrant client library to interact with the Qdrant system, a Question-Answer Prompt to chunk up the document texts, and an embedding model to generate embeddings for the documents.", "doc_id": "5555ac7e-0762-478e-b839-5f5aba2d7352", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Qdrant vector store index.\n\nAn index that is built on top of an existing Qdrant collection.\n\n\"\"\"\nfrom typing import Any, Dict, Optional, Sequence, Type, cast\n\nfrom gpt_index.data_structs.data_structs import QdrantIndexStruct\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.qdrant import GPTQdrantIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTQdrantIndex(BaseGPTVectorStoreIndex[QdrantIndexStruct]):\n    \"\"\"GPT Qdrant Index.\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 0, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "1": {"text": "   \"\"\"GPT Qdrant Index.\n\n    The GPTQdrantIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a Qdrant collection.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within Qdrant.\n\n    During query time, the index uses Qdrant to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n        client (Optional[Any]): QdrantClient instance from `qdrant-client` package\n        collection_name: (Optional[str]): name of the Qdrant collection\n    \"\"\"\n\n    index_struct_cls = QdrantIndexStruct\n\n    def __init__(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 1, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "2": {"text": "= QdrantIndexStruct\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[QdrantIndexStruct] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        client: Optional[Any] = None,\n        collection_name: Optional[str] = None,\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        import_err_msg = (\n            \"`qdrant-client` package not found, please run `pip install qdrant-client`\"\n        )\n        try:\n            import qdrant_client  # noqa: F401\n        except ImportError:\n            raise", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 2, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "3": {"text": "   except ImportError:\n            raise ValueError(import_err_msg)\n\n        if client is None:\n            raise ValueError(\"client cannot be None.\")\n\n        if collection_name is None and index_struct is not None:\n            collection_name = index_struct.collection_name\n        if collection_name is None:\n            raise ValueError(\"collection_name cannot be None.\")\n\n        self._client = cast(qdrant_client.QdrantClient, client)\n        self._collection_name = collection_name\n        self._collection_initialized = self._collection_exists(collection_name)\n\n        self.text_qa_template = text_qa_template or DEFAULT_TEXT_QA_PROMPT\n        super().__init__(\n            documents,\n            index_struct,\n            text_qa_template,\n            llm_predictor,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 3, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "4": {"text": " llm_predictor,\n            embed_model,\n            **kwargs\n        )\n        # NOTE: when building the vector store index, text_qa_template is not partially\n        # formatted because we don't know the query ahead of time.\n        self._text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTQdrantIndexQuery,\n            QueryMode.EMBEDDING: GPTQdrantIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: QdrantIndexStruct,\n        document: BaseDocument,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 4, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "5": {"text": "       document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        from qdrant_client.http import models as rest\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n\n            collection_name = index_struct.get_collection_name()\n\n            # Create the Qdrant collection, if it does not exist yet\n            if not self._collection_initialized:\n                self._create_collection(\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 5, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "6": {"text": "  self._create_collection(\n                    collection_name=collection_name,\n                    vector_size=len(text_embedding),\n                )\n                self._collection_initialized = True\n\n            while True:\n                new_id = get_new_id(set())\n                try:\n                    self._client.http.points_api.get_point(\n                        collection_name=collection_name, id=new_id\n                    )\n                except UnexpectedResponse:\n                    break\n\n            payload = {\n                \"doc_id\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 6, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "7": {"text": "               \"doc_id\": document.get_doc_id(),\n                \"text\": n.get_text(),\n                \"index\": n.index,\n            }\n\n            self._client.upsert(\n                collection_name=collection_name,\n                points=[\n                    rest.PointStruct(\n                        id=new_id,\n                        vector=text_embedding,\n                        payload=payload,\n                    )\n                ],\n            )\n\n    def _build_index_from_documents(\n        self,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 7, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "8": {"text": "_build_index_from_documents(\n        self, documents: Sequence[BaseDocument]\n    ) -> QdrantIndexStruct:\n        \"\"\"Build index from documents.\"\"\"\n        text_splitter = self._prompt_helper.get_text_splitter_given_prompt(\n            self.text_qa_template, 1\n        )\n        index_struct = self.index_struct_cls(collection_name=self._collection_name)\n        for d in documents:\n            self._add_document_to_index(index_struct, d, text_splitter)\n        return index_struct\n\n    def _insert(self, document: BaseDocument, **insert_kwargs: Any) -> None:\n        \"\"\"Insert a document.\"\"\"\n        self._add_document_to_index(self.index_struct, document, self._text_splitter)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        from qdrant_client.http import models as", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 8, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "9": {"text": "       from qdrant_client.http import models as rest\n\n        self._client.delete(\n            collection_name=self._collection_name,\n            points_selector=rest.Filter(\n                must=[\n                    rest.FieldCondition(\n                        key=\"doc_id\", match=rest.MatchValue(value=doc_id)\n                    )\n                ]\n            ),\n        )\n\n    def _preprocess_query(self, mode: QueryMode, query_kwargs: Any) -> None:\n        \"\"\"Query mode to class.\"\"\"\n        super()._preprocess_query(mode, query_kwargs)\n        # Pass along Qdrant client instance\n        query_kwargs[\"client\"] = self._client\n\n    def _create_collection(self, collection_name: str,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 9, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "10": {"text": "   def _create_collection(self, collection_name: str, vector_size: int) -> None:\n        \"\"\"Create a Qdrant collection.\"\"\"\n        from qdrant_client.http import models as rest\n\n        self._client.recreate_collection(\n            collection_name=collection_name,\n            vectors_config=rest.VectorParams(\n                size=vector_size,\n                distance=rest.Distance.COSINE,\n            ),\n        )\n\n    def _collection_exists(self, collection_name: str) -> bool:\n        from qdrant_client.http.exceptions import UnexpectedResponse\n\n        try:\n            response = self._client.http.collections_api.get_collection(collection_name)\n            return response.result is not None\n        except UnexpectedResponse:\n            return False\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/qdrant.py", "file_name": "qdrant.py"}, "index": 10, "child_indices": [], "ref_doc_id": "bf1118e9a20657b90f4e5cbb9ae924330db5f50f", "node_info": null}, "11": {"text": "The GPTQdrantIndex is a data structure that uses an existing Qdrant collection to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTQdrantIndex class provides methods for adding documents to the index, deleting documents from the index, and creating a collection in Qdrant.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 11, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "12": {"text": "qdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The first function, _create_collection(), creates a Qdrant collection with a given collection name and vector size. The second function, _collection_exists(), checks if a given collection name exists in the Qdrant system. Both functions use the Qdrant client library to interact with the Qdrant system.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [10], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"11": {"text": "The GPTQdrantIndex is a data structure that uses an existing Qdrant collection to store document embeddings. During index construction, the document texts are chunked up, converted to nodes with text, and then encoded in document embeddings stored within Qdrant. During query time, the index uses Qdrant to query for the top k most similar nodes, and synthesizes an answer from the retrieved nodes. The GPTQdrantIndex class provides methods for adding documents to the index, deleting documents from the index, and creating a collection in Qdrant.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 11, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "12": {"text": "qdrant.py is a Python file that contains two functions related to the Qdrant indexing system. The first function, _create_collection(), creates a Qdrant collection with a given collection name and vector size. The second function, _collection_exists(), checks if a given collection name exists in the Qdrant system. Both functions use the Qdrant client library to interact with the Qdrant system.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [10], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}