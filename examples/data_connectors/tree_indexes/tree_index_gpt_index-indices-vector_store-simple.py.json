{"index_struct": {"text": "\nThe GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. It is used to query for the top k most similar nodes and synthesize an answer from the retrieved nodes. The code file contains functions and classes that are used to initialize the index with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() function is used to add documents to the index, and the _delete() function is used to delete documents from the index. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. The purpose of the code is to provide a way to quickly query for the top k most similar nodes and synthesize an answer from the retrieved nodes.", "doc_id": "9dffd0bd-d959-4ddf-906e-19ba01a5ebae", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Simple vector store index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import SimpleIndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.simple import GPTSimpleVectorIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTSimpleVectorIndex(BaseGPTVectorStoreIndex[SimpleIndexDict]):\n    \"\"\"GPT Simple Vector Index.\n\n    The GPTSimpleVectorIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a simple dictionary.\n    During index construction, the document texts are chunked", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 0, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "1": {"text": "dictionary.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within the dict.\n\n    During query time, the index uses the dict to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = SimpleIndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[SimpleIndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 1, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "2": {"text": "Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTSimpleVectorIndexQuery,\n            QueryMode.EMBEDDING: GPTSimpleVectorIndexQuery,\n        }\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 2, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "3": {"text": "       }\n\n    def _add_document_to_index(\n        self,\n        index_struct: SimpleIndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to in-memory dict\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n            new_id = get_new_id(set(index_struct.nodes_dict.keys()))\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 3, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "4": {"text": "           # add to index\n            index_struct.add_node(n, text_id=new_id)\n            # TODO: deprecate\n            index_struct.add_to_embedding_dict(new_id, text_embedding)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        text_ids_to_delete = set()\n        int_ids_to_delete = set()\n        for text_id, int_id in self.index_struct.id_map.items():\n            node = self.index_struct.nodes_dict[int_id]\n            if node.ref_doc_id != doc_id:\n                continue\n            text_ids_to_delete.add(text_id)\n            int_ids_to_delete.add(int_id)\n\n        for int_id, text_id in", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 4, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "5": {"text": "       for int_id, text_id in zip(int_ids_to_delete, text_ids_to_delete):\n            del self.index_struct.nodes_dict[int_id]\n            del self.index_struct.id_map[text_id]\n            del self.index_struct.embedding_dict[text_id]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 5, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "6": {"text": "The GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. During query time, the index uses the dict to query for the top k most similar nodes and synthesizes an answer from the retrieved nodes. The index is initialized with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() and _delete() functions are used to add and delete documents from the index, respectively.", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "The GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. During query time, the index uses the dict to query for the top k most similar nodes and synthesizes an answer from the retrieved nodes. The index is initialized with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() and _delete() functions are used to add and delete documents from the index, respectively.", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"b901531911d54b57fd5436cb636d971e68fea306": {"text": "\"\"\"Simple vector store index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import SimpleIndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.simple import GPTSimpleVectorIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTSimpleVectorIndex(BaseGPTVectorStoreIndex[SimpleIndexDict]):\n    \"\"\"GPT Simple Vector Index.\n\n    The GPTSimpleVectorIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a simple dictionary.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within the dict.\n\n    During query time, the index uses the dict to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = SimpleIndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[SimpleIndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTSimpleVectorIndexQuery,\n            QueryMode.EMBEDDING: GPTSimpleVectorIndexQuery,\n        }\n\n    def _add_document_to_index(\n        self,\n        index_struct: SimpleIndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to in-memory dict\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n            new_id = get_new_id(set(index_struct.nodes_dict.keys()))\n\n            # add to index\n            index_struct.add_node(n, text_id=new_id)\n            # TODO: deprecate\n            index_struct.add_to_embedding_dict(new_id, text_embedding)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        text_ids_to_delete = set()\n        int_ids_to_delete = set()\n        for text_id, int_id in self.index_struct.id_map.items():\n            node = self.index_struct.nodes_dict[int_id]\n            if node.ref_doc_id != doc_id:\n                continue\n            text_ids_to_delete.add(text_id)\n            int_ids_to_delete.add(int_id)\n\n        for int_id, text_id in zip(int_ids_to_delete, text_ids_to_delete):\n            del self.index_struct.nodes_dict[int_id]\n            del self.index_struct.id_map[text_id]\n            del self.index_struct.embedding_dict[text_id]\n", "doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "__type__": "Document"}, "9dffd0bd-d959-4ddf-906e-19ba01a5ebae": {"text": "\nThe GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. It is used to query for the top k most similar nodes and synthesize an answer from the retrieved nodes. The code file contains functions and classes that are used to initialize the index with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() function is used to add documents to the index, and the _delete() function is used to delete documents from the index. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. The purpose of the code is to provide a way to quickly query for the top k most similar nodes and synthesize an answer from the retrieved nodes.", "doc_id": "9dffd0bd-d959-4ddf-906e-19ba01a5ebae", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Simple vector store index.\"\"\"\n\nfrom typing import Any, Dict, Optional, Sequence, Type\n\nfrom gpt_index.data_structs.data_structs import SimpleIndexDict\nfrom gpt_index.embeddings.base import BaseEmbedding\nfrom gpt_index.indices.base import DOCUMENTS_INPUT\nfrom gpt_index.indices.query.base import BaseGPTIndexQuery\nfrom gpt_index.indices.query.schema import QueryMode\nfrom gpt_index.indices.query.vector_store.simple import GPTSimpleVectorIndexQuery\nfrom gpt_index.indices.vector_store.base import BaseGPTVectorStoreIndex\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.prompts import QuestionAnswerPrompt\nfrom gpt_index.schema import BaseDocument\nfrom gpt_index.utils import get_new_id\n\n\nclass GPTSimpleVectorIndex(BaseGPTVectorStoreIndex[SimpleIndexDict]):\n    \"\"\"GPT Simple Vector Index.\n\n    The GPTSimpleVectorIndex is a data structure where nodes are keyed by\n    embeddings, and those embeddings are stored within a simple dictionary.\n    During index construction, the document texts are chunked", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 0, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "1": {"text": "dictionary.\n    During index construction, the document texts are chunked up,\n    converted to nodes with text; they are then encoded in\n    document embeddings stored within the dict.\n\n    During query time, the index uses the dict to query for the top\n    k most similar nodes, and synthesizes an answer from the\n    retrieved nodes.\n\n    Args:\n        text_qa_template (Optional[QuestionAnswerPrompt]): A Question-Answer Prompt\n            (see :ref:`Prompt-Templates`).\n        embed_model (Optional[BaseEmbedding]): Embedding model to use for\n            embedding similarity.\n    \"\"\"\n\n    index_struct_cls = SimpleIndexDict\n\n    def __init__(\n        self,\n        documents: Optional[Sequence[DOCUMENTS_INPUT]] = None,\n        index_struct: Optional[SimpleIndexDict] = None,\n        text_qa_template: Optional[QuestionAnswerPrompt] = None,\n        llm_predictor: Optional[LLMPredictor] = None,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 1, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "2": {"text": "Optional[LLMPredictor] = None,\n        embed_model: Optional[BaseEmbedding] = None,\n        **kwargs: Any,\n    ) -> None:\n        \"\"\"Initialize params.\"\"\"\n        super().__init__(\n            documents=documents,\n            index_struct=index_struct,\n            text_qa_template=text_qa_template,\n            llm_predictor=llm_predictor,\n            embed_model=embed_model,\n            **kwargs,\n        )\n\n    @classmethod\n    def get_query_map(self) -> Dict[str, Type[BaseGPTIndexQuery]]:\n        \"\"\"Get query map.\"\"\"\n        return {\n            QueryMode.DEFAULT: GPTSimpleVectorIndexQuery,\n            QueryMode.EMBEDDING: GPTSimpleVectorIndexQuery,\n        }\n\n    def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 2, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "3": {"text": "       }\n\n    def _add_document_to_index(\n        self,\n        index_struct: SimpleIndexDict,\n        document: BaseDocument,\n        text_splitter: TokenTextSplitter,\n    ) -> None:\n        \"\"\"Add document to index.\"\"\"\n        nodes = self._get_nodes_from_document(document, text_splitter)\n        for n in nodes:\n            # add to in-memory dict\n            # NOTE: embeddings won't be stored in Node but rather in underlying\n            # Faiss store\n            if n.embedding is None:\n                text_embedding = self._embed_model.get_text_embedding(n.get_text())\n            else:\n                text_embedding = n.embedding\n            new_id = get_new_id(set(index_struct.nodes_dict.keys()))\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 3, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "4": {"text": "           # add to index\n            index_struct.add_node(n, text_id=new_id)\n            # TODO: deprecate\n            index_struct.add_to_embedding_dict(new_id, text_embedding)\n\n    def _delete(self, doc_id: str, **delete_kwargs: Any) -> None:\n        \"\"\"Delete a document.\"\"\"\n        text_ids_to_delete = set()\n        int_ids_to_delete = set()\n        for text_id, int_id in self.index_struct.id_map.items():\n            node = self.index_struct.nodes_dict[int_id]\n            if node.ref_doc_id != doc_id:\n                continue\n            text_ids_to_delete.add(text_id)\n            int_ids_to_delete.add(int_id)\n\n        for int_id, text_id in", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 4, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "5": {"text": "       for int_id, text_id in zip(int_ids_to_delete, text_ids_to_delete):\n            del self.index_struct.nodes_dict[int_id]\n            del self.index_struct.id_map[text_id]\n            del self.index_struct.embedding_dict[text_id]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/indices/vector_store/simple.py", "file_name": "simple.py"}, "index": 5, "child_indices": [], "ref_doc_id": "b901531911d54b57fd5436cb636d971e68fea306", "node_info": null}, "6": {"text": "The GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. During query time, the index uses the dict to query for the top k most similar nodes and synthesizes an answer from the retrieved nodes. The index is initialized with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() and _delete() functions are used to add and delete documents from the index, respectively.", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "The GPTSimpleVectorIndex is a data structure that stores nodes keyed by embeddings in a simple dictionary. During index construction, the document texts are chunked up, converted to nodes with text, and encoded in document embeddings stored within the dict. During query time, the index uses the dict to query for the top k most similar nodes and synthesizes an answer from the retrieved nodes. The index is initialized with documents, an index structure, a Question-Answer Prompt, an LLM Predictor, and an Embedding model. The _add_document_to_index() and _delete() functions are used to add and delete documents from the index, respectively.", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}