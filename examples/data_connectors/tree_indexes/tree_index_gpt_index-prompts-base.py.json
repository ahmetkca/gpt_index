{"index_struct": {"text": "\nThis code file provides a wrapper around the Langchain Prompt class to create and manage prompts for GPT Index. It adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt. The code uses the Formatter class to parse the template string and extract the input variables, and the deepcopy function to create a copy of the prompt object. The purpose of the code is to provide a way to create and manage prompts for GPT Index, allowing users to enforce certain prompt types and partially fill values.", "doc_id": "4fda54ff-858f-4d5d-a5d1-89912549d092", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "1": {"text": "           raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "2": {"text": "        input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "3": {"text": "       self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "4": {"text": "           )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n        return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] = f\"{{{var}}}\"\n\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "5": {"text": " format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "6": {"text": "This code file contains the base module for prompts used in GPT Index. It is a wrapper around the Langchain Prompt class, and adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt.\n\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "This code file contains the base module for prompts used in GPT Index. It is a wrapper around the Langchain Prompt class, and adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt.\n\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"7d31d14e71a85ec7b6245e0d2ffd714cce527961": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n        return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "__type__": "Document"}, "4fda54ff-858f-4d5d-a5d1-89912549d092": {"text": "\nThis code file provides a wrapper around the Langchain Prompt class to create and manage prompts for GPT Index. It adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt. The code uses the Formatter class to parse the template string and extract the input variables, and the deepcopy function to create a copy of the prompt object. The purpose of the code is to provide a way to create and manage prompts for GPT Index, allowing users to enforce certain prompt types and partially fill values.", "doc_id": "4fda54ff-858f-4d5d-a5d1-89912549d092", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Base module for prompts.\"\"\"\nfrom copy import deepcopy\nfrom string import Formatter\nfrom typing import Any, Dict, List, Optional, Type, TypeVar\n\nfrom langchain import PromptTemplate as LangchainPrompt\n\nfrom gpt_index.prompts.prompt_type import PromptType\n\nPMT = TypeVar(\"PMT\", bound=\"Prompt\")\n\n\nclass Prompt:\n    \"\"\"Prompt class for GPT Index.\n\n    Wrapper around langchain's prompt class. Adds ability to:\n        - enforce certain prompt types\n        - partially fill values\n\n    \"\"\"\n\n    input_variables: List[str]\n    prompt_type: PromptType = PromptType.CUSTOM\n\n    def __init__(\n        self,\n        template: Optional[str] = None,\n        langchain_prompt: Optional[LangchainPrompt] = None,\n        **prompt_kwargs: Any,\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        if langchain_prompt is None:\n            if template is None:\n                raise ValueError(\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "1": {"text": "           raise ValueError(\n                    \"`template` must be specified if `langchain_prompt` is None\"\n                )\n            # validate\n            tmpl_vars = {\n                v for _, v, _, _ in Formatter().parse(template) if v is not None\n            }\n            if tmpl_vars != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid template: {template}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n\n            self.prompt: LangchainPrompt = LangchainPrompt(\n                input_variables=self.input_variables,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "2": {"text": "        input_variables=self.input_variables, template=template, **prompt_kwargs\n            )\n        else:\n            if template:\n                raise ValueError(\n                    f\"Both template ({template}) and langchain_prompt \"\n                    f\"({langchain_prompt}) are provided, only one should be.\"\n                )\n            if set(langchain_prompt.input_variables) != set(self.input_variables):\n                raise ValueError(\n                    f\"Invalid prompt: {langchain_prompt}, variables do not match the \"\n                    f\"required input_variables: {self.input_variables}\"\n                )\n            self.prompt = langchain_prompt\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "3": {"text": "       self.prompt = langchain_prompt\n        self.partial_dict: Dict[str, Any] = {}\n        self.prompt_kwargs = prompt_kwargs\n\n    @classmethod\n    def from_langchain_prompt(\n        cls: Type[PMT], prompt: LangchainPrompt, **kwargs: Any\n    ) -> PMT:\n        \"\"\"Load prompt from LangChain prompt.\"\"\"\n        return cls(langchain_prompt=prompt, **kwargs)\n\n    def partial_format(self: PMT, **kwargs: Any) -> PMT:\n        \"\"\"Format the prompt partially.\n\n        Return an instance of itself.\n\n        \"\"\"\n        for k in kwargs.keys():\n            if k not in self.input_variables:\n                raise ValueError(\n                    f\"Invalid input variable: {k}, not found in input_variables\"\n                )\n\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "4": {"text": "           )\n\n        copy_obj = deepcopy(self)\n        copy_obj.partial_dict.update(kwargs)\n        return copy_obj\n\n    @classmethod\n    def from_prompt(cls: Type[PMT], prompt: \"Prompt\") -> PMT:\n        \"\"\"Create a prompt from an existing prompt.\n\n        Use case: If the existing prompt is already partially filled,\n        and the remaining fields satisfy the requirements of the\n        prompt class, then we can create a new prompt from the existing\n        partially filled prompt.\n\n        \"\"\"\n        template = prompt.prompt.template\n        tmpl_vars = {v for _, v, _, _ in Formatter().parse(template) if v is not None}\n        format_dict = {}\n        for var in tmpl_vars:\n            if var not in prompt.partial_dict:\n                format_dict[var] = f\"{{{var}}}\"\n\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "5": {"text": " format_dict[var] = f\"{{{var}}}\"\n\n        template_str = prompt.format(**format_dict)\n        cls_obj: PMT = cls(template_str, **prompt.prompt_kwargs)\n        return cls_obj\n\n    def get_langchain_prompt(self) -> LangchainPrompt:\n        \"\"\"Get langchain prompt.\"\"\"\n        return self.prompt\n\n    def format(self, **kwargs: Any) -> str:\n        \"\"\"Format the prompt.\"\"\"\n        kwargs.update(self.partial_dict)\n        return self.prompt.format(**kwargs)\n\n    def get_full_format_args(self, kwargs: Dict) -> Dict[str, Any]:\n        \"\"\"Get dict of all format args.\n\n        Hack to pass into Langchain to pass validation.\n\n        \"\"\"\n        kwargs.update(self.partial_dict)\n        return kwargs\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "7d31d14e71a85ec7b6245e0d2ffd714cce527961", "node_info": null}, "6": {"text": "This code file contains the base module for prompts used in GPT Index. It is a wrapper around the Langchain Prompt class, and adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt.\n\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "This code file contains the base module for prompts used in GPT Index. It is a wrapper around the Langchain Prompt class, and adds the ability to enforce certain prompt types and partially fill values. It contains methods for initializing, partially formatting, and creating a prompt from an existing prompt. It also contains methods for getting the Langchain prompt and formatting the prompt.\n\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}