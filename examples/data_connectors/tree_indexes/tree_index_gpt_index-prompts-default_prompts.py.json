{"index_struct": {"text": "\nThe code file contains a set of default prompts used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions. These prompts are generated using templates that contain placeholders for context information, query strings, and other relevant information. The code file provides a set of default prompts that can be used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions. The code utilizes algorithms and data structures to create the prompts and store the relevant information. The code also contains functions, classes, and variables that are used to generate the prompts and store the relevant information. The purpose of the code is to provide a set of default prompts that can be used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions.", "doc_id": "be2bd014-a077-434a-839a-d713ac6a86fd", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 0, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "1": {"text": "= (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT = TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 1, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "2": {"text": "above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 2, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "3": {"text": "and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 3, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "4": {"text": "   \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 4, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "5": {"text": "= (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 5, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "6": {"text": "   \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n# NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 6, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "7": {"text": " \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 7, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "8": {"text": " \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT = TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 8, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "9": {"text": "= RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 9, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "10": {"text": "This code file contains a set of default prompts used for various tasks such as summarizing text, extracting keywords, and answering questions. It includes prompts for tasks such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, QuestionAnswerPrompt, RefinePrompt, RefineTableContextPrompt, SchemaExtractPrompt, TextToSQLPrompt, and TableContextPrompt. Each prompt contains a template that is used to generate the prompt. The templates contain placeholders for context information, query strings, and other relevant information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file contains a set of default prompts used for various tasks such as summarizing text, extracting keywords, and answering questions. It includes prompts for tasks such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, QuestionAnswerPrompt, RefinePrompt, RefineTableContextPrompt, SchemaExtractPrompt, TextToSQLPrompt, and TableContextPrompt. Each prompt contains a template that is used to generate the prompt. The templates contain placeholders for context information, query strings, and other relevant information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"67d318229cee08ef396c5183c85a937be9a1a2db": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT = TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n# NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT = TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "__type__": "Document"}, "be2bd014-a077-434a-839a-d713ac6a86fd": {"text": "\nThe code file contains a set of default prompts used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions. These prompts are generated using templates that contain placeholders for context information, query strings, and other relevant information. The code file provides a set of default prompts that can be used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions. The code utilizes algorithms and data structures to create the prompts and store the relevant information. The code also contains functions, classes, and variables that are used to generate the prompts and store the relevant information. The purpose of the code is to provide a set of default prompts that can be used to generate tasks for various tasks such as summarizing text, extracting keywords, and answering questions.", "doc_id": "be2bd014-a077-434a-839a-d713ac6a86fd", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Set of default prompts.\"\"\"\n\nfrom gpt_index.prompts.prompts import (\n    KeywordExtractPrompt,\n    QueryKeywordExtractPrompt,\n    QuestionAnswerPrompt,\n    RefinePrompt,\n    RefineTableContextPrompt,\n    SchemaExtractPrompt,\n    SummaryPrompt,\n    TableContextPrompt,\n    TextToSQLPrompt,\n    TreeInsertPrompt,\n    TreeSelectMultiplePrompt,\n    TreeSelectPrompt,\n)\n\n############################################\n# Tree\n############################################\n\nDEFAULT_SUMMARY_PROMPT_TMPL = (\n    \"Write a summary of the following. Try to use only the \"\n    \"information provided. \"\n    \"Try to include as many key details as possible.\\n\"\n    \"\\n\"\n    \"\\n\"\n    \"{context_str}\\n\"\n    \"\\n\"\n    \"\\n\"\n    'SUMMARY:\"\"\"\\n'\n)\n\nDEFAULT_SUMMARY_PROMPT = SummaryPrompt(DEFAULT_SUMMARY_PROMPT_TMPL)\n\n# insert prompts\nDEFAULT_INSERT_PROMPT_TMPL = (\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 0, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "1": {"text": "= (\n    \"Context information is below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"---------------------\\n\"\n    \"Given the context information, here is a new piece of \"\n    \"information: {new_chunk_text}\\n\"\n    \"Answer with the number corresponding to the summary that should be updated. \"\n    \"The answer should be the number corresponding to the \"\n    \"summary that is most relevant to the question.\\n\"\n)\nDEFAULT_INSERT_PROMPT = TreeInsertPrompt(DEFAULT_INSERT_PROMPT_TMPL)\n\n\n# # single choice\nDEFAULT_QUERY_PROMPT_TMPL = (\n    \"Some choices are given below. It is provided in a numbered list \"\n    \"(1 to {num_chunks}),\"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return \"\n    \"the choice that is most relevant", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 1, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "2": {"text": "above and not prior knowledge, return \"\n    \"the choice that is most relevant to the question: '{query_str}'\\n\"\n    \"Provide choice in the following format: 'ANSWER: <number>' and explain why \"\n    \"this summary was selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT = TreeSelectPrompt(DEFAULT_QUERY_PROMPT_TMPL)\n\n# multiple choice\nDEFAULT_QUERY_PROMPT_MULTIPLE_TMPL = (\n    \"Some choices are given below. It is provided in a numbered \"\n    \"list (1 to {num_chunks}), \"\n    \"where each item in the list corresponds to a summary.\\n\"\n    \"---------------------\\n\"\n    \"{context_list}\"\n    \"\\n---------------------\\n\"\n    \"Using only the choices above and not prior knowledge, return the top choices \"\n    \"(no more than {branching_factor}, ranked by most relevant to least) that \"\n    \"are most relevant to the question: '{query_str}'\\n\"\n    \"Provide choices in the following format: 'ANSWER: <numbers>' and explain why \"\n    \"these summaries were selected in relation to the", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 2, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "3": {"text": "and explain why \"\n    \"these summaries were selected in relation to the question.\\n\"\n)\nDEFAULT_QUERY_PROMPT_MULTIPLE = TreeSelectMultiplePrompt(\n    DEFAULT_QUERY_PROMPT_MULTIPLE_TMPL\n)\n\n\nDEFAULT_REFINE_PROMPT_TMPL = (\n    \"The original question is as follows: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"We have the opportunity to refine the existing answer\"\n    \"(only if needed) with some more context below.\\n\"\n    \"------------\\n\"\n    \"{context_msg}\\n\"\n    \"------------\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_PROMPT = RefinePrompt(DEFAULT_REFINE_PROMPT_TMPL)\n\n\nDEFAULT_TEXT_QA_PROMPT_TMPL = (\n    \"Context information is below. \\n\"\n    \"---------------------\\n\"\n    \"{context_str}\"\n    \"\\n---------------------\\n\"\n    \"Given the context information", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 3, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "4": {"text": "   \"\\n---------------------\\n\"\n    \"Given the context information and not prior knowledge, \"\n    \"answer the question: {query_str}\\n\"\n)\nDEFAULT_TEXT_QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)\n\n\n############################################\n# Keyword Table\n############################################\n\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"Some text is provided below. Given the text, extract up to {max_keywords} \"\n    \"keywords from the text. Avoid stopwords.\"\n    \"---------------------\\n\"\n    \"{text}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_KEYWORD_EXTRACT_TEMPLATE = KeywordExtractPrompt(\n    DEFAULT_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n# NOTE: the keyword extraction for queries can be the same as\n# the one used to build the index, but here we tune it to see if performance is better.\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL = (\n    \"A question is provided", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 4, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "5": {"text": "= (\n    \"A question is provided below. Given the question, extract up to {max_keywords} \"\n    \"keywords from the text. Focus on extracting the keywords that we can use \"\n    \"to best lookup answers to the question. Avoid stopwords.\\n\"\n    \"---------------------\\n\"\n    \"{question}\\n\"\n    \"---------------------\\n\"\n    \"Provide keywords in the following comma-separated format: 'KEYWORDS: <keywords>'\\n\"\n)\nDEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE = QueryKeywordExtractPrompt(\n    DEFAULT_QUERY_KEYWORD_EXTRACT_TEMPLATE_TMPL\n)\n\n\n############################################\n# Structured Store\n############################################\n\nDEFAULT_SCHEMA_EXTRACT_TMPL = (\n    \"We wish to extract relevant fields from an unstructured text chunk into \"\n    \"a structured schema. We first provide the unstructured text, and then \"\n    \"we provide the schema that we wish to extract. \"\n    \"-----------text-----------\\n\"\n    \"{text}\\n\"\n    \"-----------schema-----------\\n\"\n    \"{schema}\\n\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 5, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "6": {"text": "   \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Given the text and schema, extract the relevant fields from the text in \"\n    \"the following format: \"\n    \"field1: <value>\\nfield2: <value>\\n...\\n\\n\"\n    \"If a field is not present in the text, don't include it in the output.\"\n    \"If no fields are present in the text, return a blank string.\\n\"\n    \"Fields: \"\n)\nDEFAULT_SCHEMA_EXTRACT_PROMPT = SchemaExtractPrompt(DEFAULT_SCHEMA_EXTRACT_TMPL)\n\n# NOTE: taken from langchain and adapted\n# https://tinyurl.com/b772sd77\nDEFAULT_TEXT_TO_SQL_TMPL = (\n    \"Given an input question, first create a syntactically correct SQL query \"\n    \"to run, then look at the results of the query and return the answer.\\n\"\n    \"Use the following format:\\n\"\n    'Question: \"Question here\"\\n'\n    'SQLQuery: \"SQL Query to run\"\\n'\n    \"The following is a schema of the table:\\n\"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 6, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "7": {"text": " \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"Question: {query_str}\\n\"\n    \"SQLQuery: \"\n)\n\nDEFAULT_TEXT_TO_SQL_PROMPT = TextToSQLPrompt(DEFAULT_TEXT_TO_SQL_TMPL)\n\n\n# NOTE: by partially filling schema, we can reduce to a QuestionAnswer prompt\n# that we can feed to ur table\nDEFAULT_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided context information below. \"\n    \"{context_str}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\"\n)\n\nDEFAULT_TABLE_CONTEXT_QUERY = (\n    \"Provide a high-level description of the table, \"\n    \"as well as a description of each column in the table. \"\n    \"Provide answers in the following format:\\n\"\n    \"TableDescription: <description>\\n\"\n    \"Column1Description:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 7, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "8": {"text": " \"TableDescription: <description>\\n\"\n    \"Column1Description: <description>\\n\"\n    \"Column2Description: <description>\\n\"\n    \"...\\n\\n\"\n)\n\nDEFAULT_TABLE_CONTEXT_PROMPT = TableContextPrompt(DEFAULT_TABLE_CONTEXT_TMPL)\n\n# NOTE: by partially filling schema, we can reduce to a RefinePrompt\n# that we can feed to ur table\nDEFAULT_REFINE_TABLE_CONTEXT_TMPL = (\n    \"We have provided a table schema below. \"\n    \"---------------------\\n\"\n    \"{schema}\\n\"\n    \"---------------------\\n\"\n    \"We have also provided some context information below. \"\n    \"{context_msg}\\n\"\n    \"---------------------\\n\"\n    \"Given the context information and the table schema, \"\n    \"give a response to the following task: {query_str}\\n\"\n    \"We have provided an existing answer: {existing_answer}\\n\"\n    \"Given the new context, refine the original answer to better \"\n    \"answer the question. \"\n    \"If the context isn't useful, return the original answer.\"\n)\nDEFAULT_REFINE_TABLE_CONTEXT_PROMPT = RefineTableContextPrompt(\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 8, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "9": {"text": "= RefineTableContextPrompt(\n    DEFAULT_REFINE_TABLE_CONTEXT_TMPL\n)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/prompts/default_prompts.py", "file_name": "default_prompts.py"}, "index": 9, "child_indices": [], "ref_doc_id": "67d318229cee08ef396c5183c85a937be9a1a2db", "node_info": null}, "10": {"text": "This code file contains a set of default prompts used for various tasks such as summarizing text, extracting keywords, and answering questions. It includes prompts for tasks such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, QuestionAnswerPrompt, RefinePrompt, RefineTableContextPrompt, SchemaExtractPrompt, TextToSQLPrompt, and TableContextPrompt. Each prompt contains a template that is used to generate the prompt. The templates contain placeholders for context information, query strings, and other relevant information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file contains a set of default prompts used for various tasks such as summarizing text, extracting keywords, and answering questions. It includes prompts for tasks such as SummaryPrompt, TreeInsertPrompt, TreeSelectPrompt, TreeSelectMultiplePrompt, KeywordExtractPrompt, QueryKeywordExtractPrompt, QuestionAnswerPrompt, RefinePrompt, RefineTableContextPrompt, SchemaExtractPrompt, TextToSQLPrompt, and TableContextPrompt. Each prompt contains a template that is used to generate the prompt. The templates contain placeholders for context information, query strings, and other relevant information.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}