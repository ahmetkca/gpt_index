{"index_struct": {"text": "\nThe SimpleDirectoryReader class is used to read files from a directory and convert them to text. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files. It can also recursively search in subdirectories, exclude hidden files, and limit the number of files read. Additionally, it can concatenate all files into one document, and optionally take in a function to extract metadata from the files. The class also contains a DEFAULT_FILE_EXTRACTOR dictionary which maps file extensions to a BaseParser class that specifies how to convert the file to text. The purpose of the code is to provide an easy way to read and convert files of different formats from a directory.", "doc_id": "082ceb8e-d59c-4706-a3e3-55dcf58cb6d5", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Simple reader that reads files of different formats from a directory.\"\"\"\nimport logging\nfrom pathlib import Path\nfrom typing import Callable, Dict, List, Optional, Union\n\nfrom gpt_index.readers.base import BaseReader\nfrom gpt_index.readers.file.base_parser import BaseParser\nfrom gpt_index.readers.file.docs_parser import DocxParser, PDFParser\nfrom gpt_index.readers.file.epub_parser import EpubParser\nfrom gpt_index.readers.file.image_parser import ImageParser\nfrom gpt_index.readers.file.markdown_parser import MarkdownParser\nfrom gpt_index.readers.file.mbox_parser import MboxParser\nfrom gpt_index.readers.file.slides_parser import PptxParser\nfrom gpt_index.readers.file.tabular_parser import PandasCSVParser\nfrom gpt_index.readers.file.video_audio import VideoAudioParser\nfrom gpt_index.readers.schema.base import Document\n\nDEFAULT_FILE_EXTRACTOR: Dict[str, BaseParser] = {\n    \".pdf\": PDFParser(),\n    \".docx\": DocxParser(),\n    \".pptx\": PptxParser(),\n    \".jpg\": ImageParser(),\n    \".png\": ImageParser(),\n    \".jpeg\": ImageParser(),\n    \".mp3\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "1": {"text": "   \".jpeg\": ImageParser(),\n    \".mp3\": VideoAudioParser(),\n    \".mp4\": VideoAudioParser(),\n    \".csv\": PandasCSVParser(),\n    \".epub\": EpubParser(),\n    \".md\": MarkdownParser(),\n    \".mbox\": MboxParser(),\n}\n\n\nclass SimpleDirectoryReader(BaseReader):\n    \"\"\"Simple directory reader.\n\n    Can read files into separate documents, or concatenates\n    files into one document text.\n\n    Args:\n        input_dir (str): Path to the directory.\n        input_files (List): List of file paths to read (Optional; overrides input_dir)\n        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n        errors (str): how encoding and decoding errors are to be handled,\n              see https://docs.python.org/3/library/functions.html#open\n        recursive (bool): Whether to recursively search in subdirectories.\n            False by default.\n        required_exts (Optional[List[str]]): List of required extensions.\n            Default is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "2": {"text": "List of required extensions.\n            Default is None.\n        file_extractor (Optional[Dict[str, BaseParser]]): A mapping of file\n            extension to a BaseParser class that specifies how to convert that file\n            to text. See DEFAULT_FILE_EXTRACTOR.\n        num_files_limit (Optional[int]): Maximum number of files to read.\n            Default is None.\n        file_metadata (Optional[Callable[str, Dict]]): A function that takes\n            in a filename and returns a Dict of metadata for the Document.\n            Default is None.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dir: Optional[str] = None,\n        input_files: Optional[List] = None,\n        exclude_hidden: bool = True,\n        errors: str = \"ignore\",\n        recursive: bool = False,\n        required_exts: Optional[List[str]] = None,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "3": {"text": "     required_exts: Optional[List[str]] = None,\n        file_extractor: Optional[Dict[str, BaseParser]] = None,\n        num_files_limit: Optional[int] = None,\n        file_metadata: Optional[Callable[[str], Dict]] = None,\n    ) -> None:\n        \"\"\"Initialize with parameters.\"\"\"\n        super().__init__()\n\n        if not input_dir and not input_files:\n            raise ValueError(\"Must provide either `input_dir` or `input_files`.\")\n\n        self.errors = errors\n\n        self.recursive = recursive\n        self.exclude_hidden = exclude_hidden\n        self.required_exts = required_exts\n        self.num_files_limit = num_files_limit\n\n        if input_files:\n            self.input_files = []\n            for path in input_files:\n                input_file = Path(path)\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "4": {"text": "    input_file = Path(path)\n                self.input_files.append(input_file)\n        elif input_dir:\n            self.input_dir = Path(input_dir)\n            self.input_files = self._add_files(self.input_dir)\n\n        self.file_extractor = file_extractor or DEFAULT_FILE_EXTRACTOR\n        self.file_metadata = file_metadata\n\n    def _add_files(self, input_dir: Path) -> List[Path]:\n        \"\"\"Add files.\"\"\"\n        input_files = sorted(input_dir.iterdir())\n        new_input_files = []\n        dirs_to_explore = []\n        for input_file in input_files:\n            if input_file.is_dir():\n                if self.recursive:\n                    dirs_to_explore.append(input_file)\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "5": {"text": "           elif self.exclude_hidden and input_file.name.startswith(\".\"):\n                continue\n            elif (\n                self.required_exts is not None\n                and input_file.suffix not in self.required_exts\n            ):\n                continue\n            else:\n                new_input_files.append(input_file)\n\n        for dir_to_explore in dirs_to_explore:\n            sub_input_files = self._add_files(dir_to_explore)\n            new_input_files.extend(sub_input_files)\n\n        if self.num_files_limit is not None and self.num_files_limit > 0:\n            new_input_files = new_input_files[0 : self.num_files_limit]\n\n        # print total number", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "6": {"text": "self.num_files_limit]\n\n        # print total number of files added\n        logging.debug(\n            f\"> [SimpleDirectoryReader] Total files added: {len(new_input_files)}\"\n        )\n\n        return new_input_files\n\n    def load_data(self, concatenate: bool = False) -> List[Document]:\n        \"\"\"Load data from the input directory.\n\n        Args:\n            concatenate (bool): whether to concatenate all files into one document.\n                If set to True, file metadata is ignored.\n                False by default.\n\n        Returns:\n            List[Document]: A list of documents.\n\n        \"\"\"\n        data: Union[str, List[str]] = \"\"\n        data_list: List[str] = []\n        metadata_list = []\n        for input_file in self.input_files:\n            if", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "7": {"text": "in self.input_files:\n            if input_file.suffix in self.file_extractor:\n                parser = self.file_extractor[input_file.suffix]\n                if not parser.parser_config_set:\n                    parser.init_parser()\n                data = parser.parse_file(input_file, errors=self.errors)\n            else:\n                # do standard read\n                with open(input_file, \"r\", errors=self.errors) as f:\n                    data = f.read()\n            if isinstance(data, List):\n                data_list.extend(data)\n            else:\n                data_list.append(str(data))\n            if self.file_metadata", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "8": {"text": "           if self.file_metadata is not None:\n                metadata_list.append(self.file_metadata(str(input_file)))\n\n        if concatenate:\n            return [Document(\"\\n\".join(data_list))]\n        elif self.file_metadata is not None:\n            return [Document(d, extra_info=m) for d, m in zip(data_list, metadata_list)]\n        else:\n            return [Document(d) for d in data_list]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "9": {"text": "This code file contains the SimpleDirectoryReader class, which is used to read files of different formats from a directory. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files and convert them to text. It also has the option to recursively search in subdirectories, exclude hidden files, and limit the number of files read. It can also concatenate all files into one document, and optionally take in a function to extract metadata from the files.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the SimpleDirectoryReader class, which is used to read files of different formats from a directory. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files and convert them to text. It also has the option to recursively search in subdirectories, exclude hidden files, and limit the number of files read. It can also concatenate all files into one document, and optionally take in a function to extract metadata from the files.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"d0027a089853c5ff8efcaa11483f67fc0e61b666": {"text": "\"\"\"Simple reader that reads files of different formats from a directory.\"\"\"\nimport logging\nfrom pathlib import Path\nfrom typing import Callable, Dict, List, Optional, Union\n\nfrom gpt_index.readers.base import BaseReader\nfrom gpt_index.readers.file.base_parser import BaseParser\nfrom gpt_index.readers.file.docs_parser import DocxParser, PDFParser\nfrom gpt_index.readers.file.epub_parser import EpubParser\nfrom gpt_index.readers.file.image_parser import ImageParser\nfrom gpt_index.readers.file.markdown_parser import MarkdownParser\nfrom gpt_index.readers.file.mbox_parser import MboxParser\nfrom gpt_index.readers.file.slides_parser import PptxParser\nfrom gpt_index.readers.file.tabular_parser import PandasCSVParser\nfrom gpt_index.readers.file.video_audio import VideoAudioParser\nfrom gpt_index.readers.schema.base import Document\n\nDEFAULT_FILE_EXTRACTOR: Dict[str, BaseParser] = {\n    \".pdf\": PDFParser(),\n    \".docx\": DocxParser(),\n    \".pptx\": PptxParser(),\n    \".jpg\": ImageParser(),\n    \".png\": ImageParser(),\n    \".jpeg\": ImageParser(),\n    \".mp3\": VideoAudioParser(),\n    \".mp4\": VideoAudioParser(),\n    \".csv\": PandasCSVParser(),\n    \".epub\": EpubParser(),\n    \".md\": MarkdownParser(),\n    \".mbox\": MboxParser(),\n}\n\n\nclass SimpleDirectoryReader(BaseReader):\n    \"\"\"Simple directory reader.\n\n    Can read files into separate documents, or concatenates\n    files into one document text.\n\n    Args:\n        input_dir (str): Path to the directory.\n        input_files (List): List of file paths to read (Optional; overrides input_dir)\n        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n        errors (str): how encoding and decoding errors are to be handled,\n              see https://docs.python.org/3/library/functions.html#open\n        recursive (bool): Whether to recursively search in subdirectories.\n            False by default.\n        required_exts (Optional[List[str]]): List of required extensions.\n            Default is None.\n        file_extractor (Optional[Dict[str, BaseParser]]): A mapping of file\n            extension to a BaseParser class that specifies how to convert that file\n            to text. See DEFAULT_FILE_EXTRACTOR.\n        num_files_limit (Optional[int]): Maximum number of files to read.\n            Default is None.\n        file_metadata (Optional[Callable[str, Dict]]): A function that takes\n            in a filename and returns a Dict of metadata for the Document.\n            Default is None.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dir: Optional[str] = None,\n        input_files: Optional[List] = None,\n        exclude_hidden: bool = True,\n        errors: str = \"ignore\",\n        recursive: bool = False,\n        required_exts: Optional[List[str]] = None,\n        file_extractor: Optional[Dict[str, BaseParser]] = None,\n        num_files_limit: Optional[int] = None,\n        file_metadata: Optional[Callable[[str], Dict]] = None,\n    ) -> None:\n        \"\"\"Initialize with parameters.\"\"\"\n        super().__init__()\n\n        if not input_dir and not input_files:\n            raise ValueError(\"Must provide either `input_dir` or `input_files`.\")\n\n        self.errors = errors\n\n        self.recursive = recursive\n        self.exclude_hidden = exclude_hidden\n        self.required_exts = required_exts\n        self.num_files_limit = num_files_limit\n\n        if input_files:\n            self.input_files = []\n            for path in input_files:\n                input_file = Path(path)\n                self.input_files.append(input_file)\n        elif input_dir:\n            self.input_dir = Path(input_dir)\n            self.input_files = self._add_files(self.input_dir)\n\n        self.file_extractor = file_extractor or DEFAULT_FILE_EXTRACTOR\n        self.file_metadata = file_metadata\n\n    def _add_files(self, input_dir: Path) -> List[Path]:\n        \"\"\"Add files.\"\"\"\n        input_files = sorted(input_dir.iterdir())\n        new_input_files = []\n        dirs_to_explore = []\n        for input_file in input_files:\n            if input_file.is_dir():\n                if self.recursive:\n                    dirs_to_explore.append(input_file)\n            elif self.exclude_hidden and input_file.name.startswith(\".\"):\n                continue\n            elif (\n                self.required_exts is not None\n                and input_file.suffix not in self.required_exts\n            ):\n                continue\n            else:\n                new_input_files.append(input_file)\n\n        for dir_to_explore in dirs_to_explore:\n            sub_input_files = self._add_files(dir_to_explore)\n            new_input_files.extend(sub_input_files)\n\n        if self.num_files_limit is not None and self.num_files_limit > 0:\n            new_input_files = new_input_files[0 : self.num_files_limit]\n\n        # print total number of files added\n        logging.debug(\n            f\"> [SimpleDirectoryReader] Total files added: {len(new_input_files)}\"\n        )\n\n        return new_input_files\n\n    def load_data(self, concatenate: bool = False) -> List[Document]:\n        \"\"\"Load data from the input directory.\n\n        Args:\n            concatenate (bool): whether to concatenate all files into one document.\n                If set to True, file metadata is ignored.\n                False by default.\n\n        Returns:\n            List[Document]: A list of documents.\n\n        \"\"\"\n        data: Union[str, List[str]] = \"\"\n        data_list: List[str] = []\n        metadata_list = []\n        for input_file in self.input_files:\n            if input_file.suffix in self.file_extractor:\n                parser = self.file_extractor[input_file.suffix]\n                if not parser.parser_config_set:\n                    parser.init_parser()\n                data = parser.parse_file(input_file, errors=self.errors)\n            else:\n                # do standard read\n                with open(input_file, \"r\", errors=self.errors) as f:\n                    data = f.read()\n            if isinstance(data, List):\n                data_list.extend(data)\n            else:\n                data_list.append(str(data))\n            if self.file_metadata is not None:\n                metadata_list.append(self.file_metadata(str(input_file)))\n\n        if concatenate:\n            return [Document(\"\\n\".join(data_list))]\n        elif self.file_metadata is not None:\n            return [Document(d, extra_info=m) for d, m in zip(data_list, metadata_list)]\n        else:\n            return [Document(d) for d in data_list]\n", "doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "__type__": "Document"}, "082ceb8e-d59c-4706-a3e3-55dcf58cb6d5": {"text": "\nThe SimpleDirectoryReader class is used to read files from a directory and convert them to text. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files. It can also recursively search in subdirectories, exclude hidden files, and limit the number of files read. Additionally, it can concatenate all files into one document, and optionally take in a function to extract metadata from the files. The class also contains a DEFAULT_FILE_EXTRACTOR dictionary which maps file extensions to a BaseParser class that specifies how to convert the file to text. The purpose of the code is to provide an easy way to read and convert files of different formats from a directory.", "doc_id": "082ceb8e-d59c-4706-a3e3-55dcf58cb6d5", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Simple reader that reads files of different formats from a directory.\"\"\"\nimport logging\nfrom pathlib import Path\nfrom typing import Callable, Dict, List, Optional, Union\n\nfrom gpt_index.readers.base import BaseReader\nfrom gpt_index.readers.file.base_parser import BaseParser\nfrom gpt_index.readers.file.docs_parser import DocxParser, PDFParser\nfrom gpt_index.readers.file.epub_parser import EpubParser\nfrom gpt_index.readers.file.image_parser import ImageParser\nfrom gpt_index.readers.file.markdown_parser import MarkdownParser\nfrom gpt_index.readers.file.mbox_parser import MboxParser\nfrom gpt_index.readers.file.slides_parser import PptxParser\nfrom gpt_index.readers.file.tabular_parser import PandasCSVParser\nfrom gpt_index.readers.file.video_audio import VideoAudioParser\nfrom gpt_index.readers.schema.base import Document\n\nDEFAULT_FILE_EXTRACTOR: Dict[str, BaseParser] = {\n    \".pdf\": PDFParser(),\n    \".docx\": DocxParser(),\n    \".pptx\": PptxParser(),\n    \".jpg\": ImageParser(),\n    \".png\": ImageParser(),\n    \".jpeg\": ImageParser(),\n    \".mp3\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "1": {"text": "   \".jpeg\": ImageParser(),\n    \".mp3\": VideoAudioParser(),\n    \".mp4\": VideoAudioParser(),\n    \".csv\": PandasCSVParser(),\n    \".epub\": EpubParser(),\n    \".md\": MarkdownParser(),\n    \".mbox\": MboxParser(),\n}\n\n\nclass SimpleDirectoryReader(BaseReader):\n    \"\"\"Simple directory reader.\n\n    Can read files into separate documents, or concatenates\n    files into one document text.\n\n    Args:\n        input_dir (str): Path to the directory.\n        input_files (List): List of file paths to read (Optional; overrides input_dir)\n        exclude_hidden (bool): Whether to exclude hidden files (dotfiles).\n        errors (str): how encoding and decoding errors are to be handled,\n              see https://docs.python.org/3/library/functions.html#open\n        recursive (bool): Whether to recursively search in subdirectories.\n            False by default.\n        required_exts (Optional[List[str]]): List of required extensions.\n            Default is", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "2": {"text": "List of required extensions.\n            Default is None.\n        file_extractor (Optional[Dict[str, BaseParser]]): A mapping of file\n            extension to a BaseParser class that specifies how to convert that file\n            to text. See DEFAULT_FILE_EXTRACTOR.\n        num_files_limit (Optional[int]): Maximum number of files to read.\n            Default is None.\n        file_metadata (Optional[Callable[str, Dict]]): A function that takes\n            in a filename and returns a Dict of metadata for the Document.\n            Default is None.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dir: Optional[str] = None,\n        input_files: Optional[List] = None,\n        exclude_hidden: bool = True,\n        errors: str = \"ignore\",\n        recursive: bool = False,\n        required_exts: Optional[List[str]] = None,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "3": {"text": "     required_exts: Optional[List[str]] = None,\n        file_extractor: Optional[Dict[str, BaseParser]] = None,\n        num_files_limit: Optional[int] = None,\n        file_metadata: Optional[Callable[[str], Dict]] = None,\n    ) -> None:\n        \"\"\"Initialize with parameters.\"\"\"\n        super().__init__()\n\n        if not input_dir and not input_files:\n            raise ValueError(\"Must provide either `input_dir` or `input_files`.\")\n\n        self.errors = errors\n\n        self.recursive = recursive\n        self.exclude_hidden = exclude_hidden\n        self.required_exts = required_exts\n        self.num_files_limit = num_files_limit\n\n        if input_files:\n            self.input_files = []\n            for path in input_files:\n                input_file = Path(path)\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "4": {"text": "    input_file = Path(path)\n                self.input_files.append(input_file)\n        elif input_dir:\n            self.input_dir = Path(input_dir)\n            self.input_files = self._add_files(self.input_dir)\n\n        self.file_extractor = file_extractor or DEFAULT_FILE_EXTRACTOR\n        self.file_metadata = file_metadata\n\n    def _add_files(self, input_dir: Path) -> List[Path]:\n        \"\"\"Add files.\"\"\"\n        input_files = sorted(input_dir.iterdir())\n        new_input_files = []\n        dirs_to_explore = []\n        for input_file in input_files:\n            if input_file.is_dir():\n                if self.recursive:\n                    dirs_to_explore.append(input_file)\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "5": {"text": "           elif self.exclude_hidden and input_file.name.startswith(\".\"):\n                continue\n            elif (\n                self.required_exts is not None\n                and input_file.suffix not in self.required_exts\n            ):\n                continue\n            else:\n                new_input_files.append(input_file)\n\n        for dir_to_explore in dirs_to_explore:\n            sub_input_files = self._add_files(dir_to_explore)\n            new_input_files.extend(sub_input_files)\n\n        if self.num_files_limit is not None and self.num_files_limit > 0:\n            new_input_files = new_input_files[0 : self.num_files_limit]\n\n        # print total number", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "6": {"text": "self.num_files_limit]\n\n        # print total number of files added\n        logging.debug(\n            f\"> [SimpleDirectoryReader] Total files added: {len(new_input_files)}\"\n        )\n\n        return new_input_files\n\n    def load_data(self, concatenate: bool = False) -> List[Document]:\n        \"\"\"Load data from the input directory.\n\n        Args:\n            concatenate (bool): whether to concatenate all files into one document.\n                If set to True, file metadata is ignored.\n                False by default.\n\n        Returns:\n            List[Document]: A list of documents.\n\n        \"\"\"\n        data: Union[str, List[str]] = \"\"\n        data_list: List[str] = []\n        metadata_list = []\n        for input_file in self.input_files:\n            if", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "7": {"text": "in self.input_files:\n            if input_file.suffix in self.file_extractor:\n                parser = self.file_extractor[input_file.suffix]\n                if not parser.parser_config_set:\n                    parser.init_parser()\n                data = parser.parse_file(input_file, errors=self.errors)\n            else:\n                # do standard read\n                with open(input_file, \"r\", errors=self.errors) as f:\n                    data = f.read()\n            if isinstance(data, List):\n                data_list.extend(data)\n            else:\n                data_list.append(str(data))\n            if self.file_metadata", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "8": {"text": "           if self.file_metadata is not None:\n                metadata_list.append(self.file_metadata(str(input_file)))\n\n        if concatenate:\n            return [Document(\"\\n\".join(data_list))]\n        elif self.file_metadata is not None:\n            return [Document(d, extra_info=m) for d, m in zip(data_list, metadata_list)]\n        else:\n            return [Document(d) for d in data_list]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/base.py", "file_name": "base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "d0027a089853c5ff8efcaa11483f67fc0e61b666", "node_info": null}, "9": {"text": "This code file contains the SimpleDirectoryReader class, which is used to read files of different formats from a directory. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files and convert them to text. It also has the option to recursively search in subdirectories, exclude hidden files, and limit the number of files read. It can also concatenate all files into one document, and optionally take in a function to extract metadata from the files.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"9": {"text": "This code file contains the SimpleDirectoryReader class, which is used to read files of different formats from a directory. It takes in parameters such as the input directory, a list of files, and a file extractor, and uses them to read the files and convert them to text. It also has the option to recursively search in subdirectories, exclude hidden files, and limit the number of files read. It can also concatenate all files into one document, and optionally take in a function to extract metadata from the files.\n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 9, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}