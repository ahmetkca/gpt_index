{"index_struct": {"text": "\nImageParser.py is a code file that uses the DONUT model to extract text from image files. It requires the installation of pytorch, transformers, sentencepiece, and PIL libraries to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The DONUT model is then used to generate a sequence of text from the image, which is then cleaned up by removing the first task start token. The resulting text is then returned. The purpose of the code is to provide a parser for image files that can extract text from them.", "doc_id": "ac8e3db4-c72f-4106-8aa4-740daf5fad3a", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Image parser.\n\nContains parsers for image files.\n\n\"\"\"\n\nimport re\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass ImageParser(BaseParser):\n    \"\"\"Image parser.\n\n    Extract text from images using DONUT.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"install pytorch to use the model\")\n        try:\n            from transformers import DonutProcessor, VisionEncoderDecoderModel\n        except ImportError:\n            raise ValueError(\"transformers is required for using DONUT model.\")\n        try:\n            import sentencepiece  # noqa: F401\n        except ImportError:\n            raise ValueError(\"sentencepiece is required for using DONUT model.\")\n        try:\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "1": {"text": "is required for using DONUT model.\")\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        processor = DonutProcessor.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        return {\"processor\": processor, \"model\": model}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        import torch\n        from PIL import Image\n\n        model =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "2": {"text": "     from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        processor = self.parser_config[\"processor\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n        # load document image\n        image = Image.open(file)\n        if image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        # prepare decoder inputs\n        task_prompt = \"<s_cord-v2>\"\n        decoder_input_ids = processor.tokenizer(\n            task_prompt, add_special_tokens=False, return_tensors=\"pt\"\n        ).input_ids\n\n        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n        outputs = model.generate(\n            pixel_values.to(device),\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "3": {"text": "pixel_values.to(device),\n            decoder_input_ids=decoder_input_ids.to(device),\n            max_length=model.decoder.config.max_position_embeddings,\n            early_stopping=True,\n            pad_token_id=processor.tokenizer.pad_token_id,\n            eos_token_id=processor.tokenizer.eos_token_id,\n            use_cache=True,\n            num_beams=1,\n            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n            return_dict_in_generate=True,\n        )\n\n        sequence = processor.batch_decode(outputs.sequences)[0]\n        sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(\n            processor.tokenizer.pad_token, \"\"\n        )\n        # remove first task start", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "4": {"text": "      )\n        # remove first task start token\n        sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()\n\n        return sequence\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "5": {"text": "ImageParser.py is a code file that contains parsers for image files. It uses the DONUT model to extract text from images. It requires the installation of pytorch, transformers, sentencepiece, and PIL to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The code then uses the DONUT model to generate a sequence of text from the image. Finally, it removes the first task start token from the sequence and returns the text.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "ImageParser.py is a code file that contains parsers for image files. It uses the DONUT model to extract text from images. It requires the installation of pytorch, transformers, sentencepiece, and PIL to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The code then uses the DONUT model to generate a sequence of text from the image. Finally, it removes the first task start token from the sequence and returns the text.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"618f6054d906179da2ba7ae65568378f60173c97": {"text": "\"\"\"Image parser.\n\nContains parsers for image files.\n\n\"\"\"\n\nimport re\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass ImageParser(BaseParser):\n    \"\"\"Image parser.\n\n    Extract text from images using DONUT.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"install pytorch to use the model\")\n        try:\n            from transformers import DonutProcessor, VisionEncoderDecoderModel\n        except ImportError:\n            raise ValueError(\"transformers is required for using DONUT model.\")\n        try:\n            import sentencepiece  # noqa: F401\n        except ImportError:\n            raise ValueError(\"sentencepiece is required for using DONUT model.\")\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        processor = DonutProcessor.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        return {\"processor\": processor, \"model\": model}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        import torch\n        from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        processor = self.parser_config[\"processor\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n        # load document image\n        image = Image.open(file)\n        if image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        # prepare decoder inputs\n        task_prompt = \"<s_cord-v2>\"\n        decoder_input_ids = processor.tokenizer(\n            task_prompt, add_special_tokens=False, return_tensors=\"pt\"\n        ).input_ids\n\n        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n        outputs = model.generate(\n            pixel_values.to(device),\n            decoder_input_ids=decoder_input_ids.to(device),\n            max_length=model.decoder.config.max_position_embeddings,\n            early_stopping=True,\n            pad_token_id=processor.tokenizer.pad_token_id,\n            eos_token_id=processor.tokenizer.eos_token_id,\n            use_cache=True,\n            num_beams=1,\n            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n            return_dict_in_generate=True,\n        )\n\n        sequence = processor.batch_decode(outputs.sequences)[0]\n        sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(\n            processor.tokenizer.pad_token, \"\"\n        )\n        # remove first task start token\n        sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()\n\n        return sequence\n", "doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "__type__": "Document"}, "ac8e3db4-c72f-4106-8aa4-740daf5fad3a": {"text": "\nImageParser.py is a code file that uses the DONUT model to extract text from image files. It requires the installation of pytorch, transformers, sentencepiece, and PIL libraries to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The DONUT model is then used to generate a sequence of text from the image, which is then cleaned up by removing the first task start token. The resulting text is then returned. The purpose of the code is to provide a parser for image files that can extract text from them.", "doc_id": "ac8e3db4-c72f-4106-8aa4-740daf5fad3a", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Image parser.\n\nContains parsers for image files.\n\n\"\"\"\n\nimport re\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass ImageParser(BaseParser):\n    \"\"\"Image parser.\n\n    Extract text from images using DONUT.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"install pytorch to use the model\")\n        try:\n            from transformers import DonutProcessor, VisionEncoderDecoderModel\n        except ImportError:\n            raise ValueError(\"transformers is required for using DONUT model.\")\n        try:\n            import sentencepiece  # noqa: F401\n        except ImportError:\n            raise ValueError(\"sentencepiece is required for using DONUT model.\")\n        try:\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "1": {"text": "is required for using DONUT model.\")\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        processor = DonutProcessor.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"naver-clova-ix/donut-base-finetuned-cord-v2\"\n        )\n        return {\"processor\": processor, \"model\": model}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        import torch\n        from PIL import Image\n\n        model =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "2": {"text": "     from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        processor = self.parser_config[\"processor\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n        # load document image\n        image = Image.open(file)\n        if image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        # prepare decoder inputs\n        task_prompt = \"<s_cord-v2>\"\n        decoder_input_ids = processor.tokenizer(\n            task_prompt, add_special_tokens=False, return_tensors=\"pt\"\n        ).input_ids\n\n        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n\n        outputs = model.generate(\n            pixel_values.to(device),\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "3": {"text": "pixel_values.to(device),\n            decoder_input_ids=decoder_input_ids.to(device),\n            max_length=model.decoder.config.max_position_embeddings,\n            early_stopping=True,\n            pad_token_id=processor.tokenizer.pad_token_id,\n            eos_token_id=processor.tokenizer.eos_token_id,\n            use_cache=True,\n            num_beams=1,\n            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n            return_dict_in_generate=True,\n        )\n\n        sequence = processor.batch_decode(outputs.sequences)[0]\n        sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(\n            processor.tokenizer.pad_token, \"\"\n        )\n        # remove first task start", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "4": {"text": "      )\n        # remove first task start token\n        sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()\n\n        return sequence\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/image_parser.py", "file_name": "image_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "618f6054d906179da2ba7ae65568378f60173c97", "node_info": null}, "5": {"text": "ImageParser.py is a code file that contains parsers for image files. It uses the DONUT model to extract text from images. It requires the installation of pytorch, transformers, sentencepiece, and PIL to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The code then uses the DONUT model to generate a sequence of text from the image. Finally, it removes the first task start token from the sequence and returns the text.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "ImageParser.py is a code file that contains parsers for image files. It uses the DONUT model to extract text from images. It requires the installation of pytorch, transformers, sentencepiece, and PIL to use the model. The code uses the DonutProcessor and VisionEncoderDecoderModel from transformers to process the image and extract text. It also uses the PIL library to read the image file. The code then uses the DONUT model to generate a sequence of text from the image. Finally, it removes the first task start token from the sequence and returns the text.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}