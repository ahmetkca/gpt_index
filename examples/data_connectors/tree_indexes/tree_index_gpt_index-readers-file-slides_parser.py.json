{"index_struct": {"text": "\nThis code file contains a parser for .pptx files that extracts text, captions images, and specifies slides. It uses the packages python-pptx, pytorch, transformers, and PIL to achieve this. The parser is initialized by the PptxParser class, which contains the caption_image() and parse_file() functions. The caption_image() function takes an image file as input and uses a VisionEncoderDecoderModel, ViTFeatureExtractor, and AutoTokenizer from the transformers package to generate a text caption for the image. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. The purpose of this code is to parse .pptx files and extract text, caption images, and specify slides.", "doc_id": "07e71835-7e0b-4ca0-a96b-13c73cfb364e", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Slides parser.\n\nContains parsers for .pptx files.\n\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass PptxParser(BaseParser):\n    \"\"\"Powerpoint parser.\n\n    Extract text, caption images, and specify slides.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            from pptx import Presentation  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"The package `python-pptx` is required to read Powerpoint files.\"\n            )\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"The package `pytorch` is required to caption images.\")\n        try:\n            from transformers import (\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "1": {"text": "         from transformers import (\n                AutoTokenizer,\n                VisionEncoderDecoderModel,\n                ViTFeatureExtractor,\n            )\n        except ImportError:\n            raise ValueError(\n                \"The package `transformers` is required to caption images.\"\n            )\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "2": {"text": "       )\n        feature_extractor = ViTFeatureExtractor.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n\n        return {\n            \"feature_extractor\": feature_extractor,\n            \"model\": model,\n            \"tokenizer\": tokenizer,\n        }\n\n    def caption_image(self, tmp_image_file: str) -> str:\n        \"\"\"Generate text caption of image.\"\"\"\n        import torch\n        from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        feature_extractor = self.parser_config[\"feature_extractor\"]\n        tokenizer = self.parser_config[\"tokenizer\"]\n\n        device", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "3": {"text": "= self.parser_config[\"tokenizer\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n\n        max_length = 16\n        num_beams = 4\n        gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n\n        i_image = Image.open(tmp_image_file)\n        if i_image.mode != \"RGB\":\n            i_image = i_image.convert(mode=\"RGB\")\n\n        pixel_values = feature_extractor(\n            images=[i_image], return_tensors=\"pt\"\n        ).pixel_values\n        pixel_values = pixel_values.to(device)\n\n        output_ids = model.generate(pixel_values, **gen_kwargs)\n\n        preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n        return preds[0].strip()\n\n    def parse_file(self, file:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "4": {"text": "preds[0].strip()\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        from pptx import Presentation\n\n        presentation = Presentation(file)\n        result = \"\"\n        for i, slide in enumerate(presentation.slides):\n            result += f\"\\n\\nSlide #{i}: \\n\"\n            for shape in slide.shapes:\n                if hasattr(shape, \"image\"):\n                    image = shape.image\n                    # get image \"file\" contents\n                    image_bytes = image.blob\n                    # temporarily save the image to feed into model\n                    image_filename = f\"tmp_image.{image.ext}\"\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "5": {"text": "                   with open(image_filename, \"wb\") as f:\n                        f.write(image_bytes)\n                    result += f\"\\n Image: {self.caption_image(image_filename)}\\n\\n\"\n\n                    os.remove(image_filename)\n                if hasattr(shape, \"text\"):\n                    result += f\"{shape.text}\\n\"\n\n        return result\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 5, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "6": {"text": "This code file contains a parser for .pptx files. It uses the packages python-pptx, pytorch, transformers, and PIL to extract text, caption images, and specify slides. It uses a VisionEncoderDecoderModel and ViTFeatureExtractor from the transformers package to caption images, and a AutoTokenizer to tokenize the output. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "This code file contains a parser for .pptx files. It uses the packages python-pptx, pytorch, transformers, and PIL to extract text, caption images, and specify slides. It uses a VisionEncoderDecoderModel and ViTFeatureExtractor from the transformers package to caption images, and a AutoTokenizer to tokenize the output. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"bf5faad5fc2e97987c1786f59411af5b69411313": {"text": "\"\"\"Slides parser.\n\nContains parsers for .pptx files.\n\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass PptxParser(BaseParser):\n    \"\"\"Powerpoint parser.\n\n    Extract text, caption images, and specify slides.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            from pptx import Presentation  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"The package `python-pptx` is required to read Powerpoint files.\"\n            )\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"The package `pytorch` is required to caption images.\")\n        try:\n            from transformers import (\n                AutoTokenizer,\n                VisionEncoderDecoderModel,\n                ViTFeatureExtractor,\n            )\n        except ImportError:\n            raise ValueError(\n                \"The package `transformers` is required to caption images.\"\n            )\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n        feature_extractor = ViTFeatureExtractor.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n\n        return {\n            \"feature_extractor\": feature_extractor,\n            \"model\": model,\n            \"tokenizer\": tokenizer,\n        }\n\n    def caption_image(self, tmp_image_file: str) -> str:\n        \"\"\"Generate text caption of image.\"\"\"\n        import torch\n        from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        feature_extractor = self.parser_config[\"feature_extractor\"]\n        tokenizer = self.parser_config[\"tokenizer\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n\n        max_length = 16\n        num_beams = 4\n        gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n\n        i_image = Image.open(tmp_image_file)\n        if i_image.mode != \"RGB\":\n            i_image = i_image.convert(mode=\"RGB\")\n\n        pixel_values = feature_extractor(\n            images=[i_image], return_tensors=\"pt\"\n        ).pixel_values\n        pixel_values = pixel_values.to(device)\n\n        output_ids = model.generate(pixel_values, **gen_kwargs)\n\n        preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n        return preds[0].strip()\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        from pptx import Presentation\n\n        presentation = Presentation(file)\n        result = \"\"\n        for i, slide in enumerate(presentation.slides):\n            result += f\"\\n\\nSlide #{i}: \\n\"\n            for shape in slide.shapes:\n                if hasattr(shape, \"image\"):\n                    image = shape.image\n                    # get image \"file\" contents\n                    image_bytes = image.blob\n                    # temporarily save the image to feed into model\n                    image_filename = f\"tmp_image.{image.ext}\"\n                    with open(image_filename, \"wb\") as f:\n                        f.write(image_bytes)\n                    result += f\"\\n Image: {self.caption_image(image_filename)}\\n\\n\"\n\n                    os.remove(image_filename)\n                if hasattr(shape, \"text\"):\n                    result += f\"{shape.text}\\n\"\n\n        return result\n", "doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "__type__": "Document"}, "07e71835-7e0b-4ca0-a96b-13c73cfb364e": {"text": "\nThis code file contains a parser for .pptx files that extracts text, captions images, and specifies slides. It uses the packages python-pptx, pytorch, transformers, and PIL to achieve this. The parser is initialized by the PptxParser class, which contains the caption_image() and parse_file() functions. The caption_image() function takes an image file as input and uses a VisionEncoderDecoderModel, ViTFeatureExtractor, and AutoTokenizer from the transformers package to generate a text caption for the image. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. The purpose of this code is to parse .pptx files and extract text, caption images, and specify slides.", "doc_id": "07e71835-7e0b-4ca0-a96b-13c73cfb364e", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Slides parser.\n\nContains parsers for .pptx files.\n\n\"\"\"\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass PptxParser(BaseParser):\n    \"\"\"Powerpoint parser.\n\n    Extract text, caption images, and specify slides.\n\n    \"\"\"\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        try:\n            from pptx import Presentation  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"The package `python-pptx` is required to read Powerpoint files.\"\n            )\n        try:\n            import torch  # noqa: F401\n        except ImportError:\n            raise ValueError(\"The package `pytorch` is required to caption images.\")\n        try:\n            from transformers import (\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "1": {"text": "         from transformers import (\n                AutoTokenizer,\n                VisionEncoderDecoderModel,\n                ViTFeatureExtractor,\n            )\n        except ImportError:\n            raise ValueError(\n                \"The package `transformers` is required to caption images.\"\n            )\n        try:\n            from PIL import Image  # noqa: F401\n        except ImportError:\n            raise ValueError(\n                \"PIL is required to read image files.\" \"Please run `pip install Pillow`\"\n            )\n\n        model = VisionEncoderDecoderModel.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n      ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "2": {"text": "       )\n        feature_extractor = ViTFeatureExtractor.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n        tokenizer = AutoTokenizer.from_pretrained(\n            \"nlpconnect/vit-gpt2-image-captioning\"\n        )\n\n        return {\n            \"feature_extractor\": feature_extractor,\n            \"model\": model,\n            \"tokenizer\": tokenizer,\n        }\n\n    def caption_image(self, tmp_image_file: str) -> str:\n        \"\"\"Generate text caption of image.\"\"\"\n        import torch\n        from PIL import Image\n\n        model = self.parser_config[\"model\"]\n        feature_extractor = self.parser_config[\"feature_extractor\"]\n        tokenizer = self.parser_config[\"tokenizer\"]\n\n        device", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "3": {"text": "= self.parser_config[\"tokenizer\"]\n\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        model.to(device)\n\n        max_length = 16\n        num_beams = 4\n        gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n\n        i_image = Image.open(tmp_image_file)\n        if i_image.mode != \"RGB\":\n            i_image = i_image.convert(mode=\"RGB\")\n\n        pixel_values = feature_extractor(\n            images=[i_image], return_tensors=\"pt\"\n        ).pixel_values\n        pixel_values = pixel_values.to(device)\n\n        output_ids = model.generate(pixel_values, **gen_kwargs)\n\n        preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n        return preds[0].strip()\n\n    def parse_file(self, file:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "4": {"text": "preds[0].strip()\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> str:\n        \"\"\"Parse file.\"\"\"\n        from pptx import Presentation\n\n        presentation = Presentation(file)\n        result = \"\"\n        for i, slide in enumerate(presentation.slides):\n            result += f\"\\n\\nSlide #{i}: \\n\"\n            for shape in slide.shapes:\n                if hasattr(shape, \"image\"):\n                    image = shape.image\n                    # get image \"file\" contents\n                    image_bytes = image.blob\n                    # temporarily save the image to feed into model\n                    image_filename = f\"tmp_image.{image.ext}\"\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "5": {"text": "                   with open(image_filename, \"wb\") as f:\n                        f.write(image_bytes)\n                    result += f\"\\n Image: {self.caption_image(image_filename)}\\n\\n\"\n\n                    os.remove(image_filename)\n                if hasattr(shape, \"text\"):\n                    result += f\"{shape.text}\\n\"\n\n        return result\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/slides_parser.py", "file_name": "slides_parser.py"}, "index": 5, "child_indices": [], "ref_doc_id": "bf5faad5fc2e97987c1786f59411af5b69411313", "node_info": null}, "6": {"text": "This code file contains a parser for .pptx files. It uses the packages python-pptx, pytorch, transformers, and PIL to extract text, caption images, and specify slides. It uses a VisionEncoderDecoderModel and ViTFeatureExtractor from the transformers package to caption images, and a AutoTokenizer to tokenize the output. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"6": {"text": "This code file contains a parser for .pptx files. It uses the packages python-pptx, pytorch, transformers, and PIL to extract text, caption images, and specify slides. It uses a VisionEncoderDecoderModel and ViTFeatureExtractor from the transformers package to caption images, and a AutoTokenizer to tokenize the output. The parse_file() function parses the file and extracts text and images, and uses the caption_image() function to generate text captions for the images. \n\"\"\"", "doc_id": null, "embedding": null, "extra_info": null, "index": 6, "child_indices": [0, 1, 2, 3, 4, 5], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}