{"index_struct": {"text": "\nThis code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings depending on the concat_rows parameter. The CSVParser class takes a concat_rows parameter to determine whether to concatenate all rows into one document, while the PandasCSVParser class takes a pandas_config parameter to specify options for the pandas.read_csv function call. This code file provides a way to parse tabular data files into strings or lists of strings, allowing for flexibility in how the data is structured and presented.", "doc_id": "691b58cf-b572-466a-97c9-52c15735d3a6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Tabular parser.\n\nContains parsers for tabular data files.\n\n\"\"\"\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Union\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass CSVParser(BaseParser):\n    \"\"\"CSV parser.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, concat_rows: bool = True, **kwargs: Any) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\n\n        Returns:\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "1": {"text": "\"\"\"Parse file.\n\n        Returns:\n            Union[str, List[str]]: a string or a List of strings.\n\n        \"\"\"\n        try:\n            import csv\n        except ImportError:\n            raise ValueError(\"csv module is required to read CSV files.\")\n        text_list = []\n        with open(file, \"r\") as fp:\n            csv_reader = csv.reader(fp)\n            for row in csv_reader:\n                text_list.append(\", \".join(row))\n        if self._concat_rows:\n            return \"\\n\".join(text_list)\n        else:\n            return text_list\n\n\nclass PandasCSVParser(BaseParser):\n    r\"\"\"Pandas-based CSV parser.\n\n    Parses CSVs using the separator detection from Pandas `read_csv`function.\n    If special parameters are required, use", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "2": {"text": "`read_csv`function.\n    If special parameters are required, use the `pandas_config` dict.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n        col_joiner (str): Separator to use for joining cols per row.\n            Set to \", \" by default.\n\n        row_joiner (str): Separator to use for joining each row.\n            Only used when `concat_rows=True`.\n            Set to \"\\n\" by default.\n\n        pandas_config (dict): Options for the `pandas.read_csv` function call.\n            Refer to https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n            for more information.\n            Set to empty dict by default, this means pandas will try to figure\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "3": {"text": "default, this means pandas will try to figure\n            out the separators, table head, etc. on its own.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        *args: Any,\n        concat_rows: bool = True,\n        col_joiner: str = \", \",\n        row_joiner: str = \"\\n\",\n        pandas_config: dict = {},\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n        self._col_joiner = col_joiner\n        self._row_joiner = row_joiner\n        self._pandas_config = pandas_config\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "4": {"text": " def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\"\"\"\n        try:\n            import pandas as pd\n        except ImportError:\n            raise ValueError(\"pandas module is required to read CSV files.\")\n\n        df = pd.read_csv(file, **self._pandas_config)\n\n        text_list = df.apply(\n            lambda row: (self._col_joiner).join(row.astype(str).tolist()), axis=1\n        ).tolist()\n\n        if self._concat_rows:\n            return (self._row_joiner).join(text_list)\n        else:\n            return text_list\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "5": {"text": "This code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "This code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"d730452fdec35104b8b57cd3b6f80a982fb35957": {"text": "\"\"\"Tabular parser.\n\nContains parsers for tabular data files.\n\n\"\"\"\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Union\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass CSVParser(BaseParser):\n    \"\"\"CSV parser.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, concat_rows: bool = True, **kwargs: Any) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\n\n        Returns:\n            Union[str, List[str]]: a string or a List of strings.\n\n        \"\"\"\n        try:\n            import csv\n        except ImportError:\n            raise ValueError(\"csv module is required to read CSV files.\")\n        text_list = []\n        with open(file, \"r\") as fp:\n            csv_reader = csv.reader(fp)\n            for row in csv_reader:\n                text_list.append(\", \".join(row))\n        if self._concat_rows:\n            return \"\\n\".join(text_list)\n        else:\n            return text_list\n\n\nclass PandasCSVParser(BaseParser):\n    r\"\"\"Pandas-based CSV parser.\n\n    Parses CSVs using the separator detection from Pandas `read_csv`function.\n    If special parameters are required, use the `pandas_config` dict.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n        col_joiner (str): Separator to use for joining cols per row.\n            Set to \", \" by default.\n\n        row_joiner (str): Separator to use for joining each row.\n            Only used when `concat_rows=True`.\n            Set to \"\\n\" by default.\n\n        pandas_config (dict): Options for the `pandas.read_csv` function call.\n            Refer to https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n            for more information.\n            Set to empty dict by default, this means pandas will try to figure\n            out the separators, table head, etc. on its own.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        *args: Any,\n        concat_rows: bool = True,\n        col_joiner: str = \", \",\n        row_joiner: str = \"\\n\",\n        pandas_config: dict = {},\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n        self._col_joiner = col_joiner\n        self._row_joiner = row_joiner\n        self._pandas_config = pandas_config\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\"\"\"\n        try:\n            import pandas as pd\n        except ImportError:\n            raise ValueError(\"pandas module is required to read CSV files.\")\n\n        df = pd.read_csv(file, **self._pandas_config)\n\n        text_list = df.apply(\n            lambda row: (self._col_joiner).join(row.astype(str).tolist()), axis=1\n        ).tolist()\n\n        if self._concat_rows:\n            return (self._row_joiner).join(text_list)\n        else:\n            return text_list\n", "doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "__type__": "Document"}, "691b58cf-b572-466a-97c9-52c15735d3a6": {"text": "\nThis code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings depending on the concat_rows parameter. The CSVParser class takes a concat_rows parameter to determine whether to concatenate all rows into one document, while the PandasCSVParser class takes a pandas_config parameter to specify options for the pandas.read_csv function call. This code file provides a way to parse tabular data files into strings or lists of strings, allowing for flexibility in how the data is structured and presented.", "doc_id": "691b58cf-b572-466a-97c9-52c15735d3a6", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Tabular parser.\n\nContains parsers for tabular data files.\n\n\"\"\"\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Union\n\nfrom gpt_index.readers.file.base_parser import BaseParser\n\n\nclass CSVParser(BaseParser):\n    \"\"\"CSV parser.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, concat_rows: bool = True, **kwargs: Any) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\n\n        Returns:\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 0, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "1": {"text": "\"\"\"Parse file.\n\n        Returns:\n            Union[str, List[str]]: a string or a List of strings.\n\n        \"\"\"\n        try:\n            import csv\n        except ImportError:\n            raise ValueError(\"csv module is required to read CSV files.\")\n        text_list = []\n        with open(file, \"r\") as fp:\n            csv_reader = csv.reader(fp)\n            for row in csv_reader:\n                text_list.append(\", \".join(row))\n        if self._concat_rows:\n            return \"\\n\".join(text_list)\n        else:\n            return text_list\n\n\nclass PandasCSVParser(BaseParser):\n    r\"\"\"Pandas-based CSV parser.\n\n    Parses CSVs using the separator detection from Pandas `read_csv`function.\n    If special parameters are required, use", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 1, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "2": {"text": "`read_csv`function.\n    If special parameters are required, use the `pandas_config` dict.\n\n    Args:\n        concat_rows (bool): whether to concatenate all rows into one document.\n            If set to False, a Document will be created for each row.\n            True by default.\n\n        col_joiner (str): Separator to use for joining cols per row.\n            Set to \", \" by default.\n\n        row_joiner (str): Separator to use for joining each row.\n            Only used when `concat_rows=True`.\n            Set to \"\\n\" by default.\n\n        pandas_config (dict): Options for the `pandas.read_csv` function call.\n            Refer to https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n            for more information.\n            Set to empty dict by default, this means pandas will try to figure\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 2, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "3": {"text": "default, this means pandas will try to figure\n            out the separators, table head, etc. on its own.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        *args: Any,\n        concat_rows: bool = True,\n        col_joiner: str = \", \",\n        row_joiner: str = \"\\n\",\n        pandas_config: dict = {},\n        **kwargs: Any\n    ) -> None:\n        \"\"\"Init params.\"\"\"\n        super().__init__(*args, **kwargs)\n        self._concat_rows = concat_rows\n        self._col_joiner = col_joiner\n        self._row_joiner = row_joiner\n        self._pandas_config = pandas_config\n\n    def _init_parser(self) -> Dict:\n        \"\"\"Init parser.\"\"\"\n        return {}\n\n    def parse_file(self, file: Path, errors: str = \"ignore\") ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 3, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "4": {"text": " def parse_file(self, file: Path, errors: str = \"ignore\") -> Union[str, List[str]]:\n        \"\"\"Parse file.\"\"\"\n        try:\n            import pandas as pd\n        except ImportError:\n            raise ValueError(\"pandas module is required to read CSV files.\")\n\n        df = pd.read_csv(file, **self._pandas_config)\n\n        text_list = df.apply(\n            lambda row: (self._col_joiner).join(row.astype(str).tolist()), axis=1\n        ).tolist()\n\n        if self._concat_rows:\n            return (self._row_joiner).join(text_list)\n        else:\n            return text_list\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/file/tabular_parser.py", "file_name": "tabular_parser.py"}, "index": 4, "child_indices": [], "ref_doc_id": "d730452fdec35104b8b57cd3b6f80a982fb35957", "node_info": null}, "5": {"text": "This code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"5": {"text": "This code file contains two classes, CSVParser and PandasCSVParser, which are used to parse tabular data files. The CSVParser class uses the csv module to read CSV files, while the PandasCSVParser class uses the pandas.read_csv function to read CSV files. Both classes have parameters to control whether to concatenate all rows into one document, and the separator to use for joining columns and rows. The parse_file function is used to parse the file and return a string or a list of strings.", "doc_id": null, "embedding": null, "extra_info": null, "index": 5, "child_indices": [0, 1, 2, 3, 4], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}