{"index_struct": {"text": "\nThis code file contains utility functions for Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation, which is used to retrieve the contents of the files in a Github repository. The print_if_verbose and get_file_extension functions are also included. The BufferedAsyncIterator class provides a base class for buffering the results of an async operation, while the BufferedGitBlobDataIterator class provides an async iterator for Git blobs. The print_if_verbose function logs a message if verbose is True, and the get_file_extension function returns the file extension of a given filename. The code file provides a set of utility functions for Github readers, allowing them to retrieve the contents of files in a repository and log messages if verbose is True.", "doc_id": "615ec692-455c-4cee-9468-b97d0cd9a279", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"\nGithub readers utils.\n\nThis module contains utility functions for the Github readers.\n\"\"\"\nimport asyncio\nimport os\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nfrom gpt_index.readers.github_readers.github_api_client import (\n    GitBlobResponseModel,\n    GithubClient,\n    GitTreeResponseModel,\n)\n\n\ndef print_if_verbose(verbose: bool, message: str) -> None:\n    \"\"\"Log message if verbose is True.\"\"\"\n    if verbose:\n        print(message)\n\n\ndef get_file_extension(filename: str) -> str:\n    \"\"\"Get file extension.\"\"\"\n    return f\".{os.path.splitext(filename)[1][1:].lower()}\"\n\n\nclass BufferedAsyncIterator(ABC):\n    \"\"\"\n    Base class for buffered async iterators.\n\n    This class is to be used as a base class for async iterators\n    that need to buffer the results of an async operation.\n    The async operation is defined in the _fill_buffer method.\n    The _fill_buffer method is called when the buffer is empty.\n    \"\"\"\n\n    def __init__(self, buffer_size: int):\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "1": {"text": "   def __init__(self, buffer_size: int):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - `buffer_size (int)`: Size of the buffer.\n                It is also the number of items that will\n                be retrieved from the async operation at once.\n                see _fill_buffer. Defaults to 2. Setting it to 1\n                will result in the same behavior as a synchronous iterator.\n        \"\"\"\n        self._buffer_size = buffer_size\n        self._buffer: List[Tuple[GitBlobResponseModel, str]] = []\n        self._index = 0\n\n    @abstractmethod\n    async def _fill_buffer(self) -> None:\n        raise NotImplementedError\n\n    def __aiter__(self) -> \"BufferedAsyncIterator\":\n        \"\"\"Return the iterator object.\"\"\"\n        return self\n\n    async def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "2": {"text": "object.\"\"\"\n        return self\n\n    async def __anext__(self) -> Tuple[GitBlobResponseModel, str]:\n        \"\"\"\n        Get next item.\n\n        Returns:\n            - `item (Tuple[GitBlobResponseModel, str])`: Next item.\n\n        Raises:\n            - `StopAsyncIteration`: If there are no more items.\n        \"\"\"\n        if not self._buffer:\n            await self._fill_buffer()\n\n        if not self._buffer:\n            raise StopAsyncIteration\n\n        item = self._buffer.pop(0)\n        self._index += 1\n        return item\n\n\nclass BufferedGitBlobDataIterator(BufferedAsyncIterator):\n    \"\"\"\n    Buffered async iterator for Git blobs.\n\n    This class is an async iterator that buffers the results of the get_blob operation.\n    It is used to retrieve the contents of the files in a Github repository.\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "3": {"text": "retrieve the contents of the files in a Github repository.\n    getBlob endpoint supports up to 100 megabytes of content for blobs.\n    This concrete implementation of BufferedAsyncIterator allows you to lazily retrieve\n    the contents of the files in a Github repository.\n    Otherwise you would have to retrieve all the contents of\n    the files in the repository at once, which would\n    be problematic if the repository is large.\n    \"\"\"\n\n    def __init__(\n        self,\n        blobs_and_paths: List[Tuple[GitTreeResponseModel.GitTreeObject, str]],\n        github_client: GithubClient,\n        owner: str,\n        repo: str,\n        loop: asyncio.AbstractEventLoop,\n        buffer_size: int,\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - blobs_and_paths (List[Tuple[GitTreeResponseModel.GitTreeObject,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "4": {"text": "(List[Tuple[GitTreeResponseModel.GitTreeObject, str]]):\n                List of tuples containing the blob and the path of the file.\n            - github_client (GithubClient): Github client.\n            - owner (str): Owner of the repository.\n            - repo (str): Name of the repository.\n            - loop (asyncio.AbstractEventLoop): Event loop.\n            - buffer_size (int): Size of the buffer.\n        \"\"\"\n        super().__init__(buffer_size)\n        self._blobs_and_paths = blobs_and_paths\n        self._github_client = github_client\n        self._owner = owner\n        self._repo = repo\n        self._verbose = verbose\n        if loop is None:\n            loop = asyncio.get_event_loop()\n            if loop is None:\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "5": {"text": "          if loop is None:\n                raise ValueError(\"No event loop found\")\n\n    async def _fill_buffer(self) -> None:\n        \"\"\"\n        Fill the buffer with the results of the get_blob operation.\n\n        The get_blob operation is called for each blob in the blobs_and_paths list.\n        The blobs are retrieved in batches of size buffer_size.\n        \"\"\"\n        del self._buffer[:]\n        self._buffer = []\n        start = self._index\n        end = min(start + self._buffer_size, len(self._blobs_and_paths))\n\n        if start >= end:\n            return\n\n        if self._verbose:\n            start_t = time.time()\n        results: List[GitBlobResponseModel] = await asyncio.gather(\n            *[\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "6": {"text": "  *[\n                self._github_client.get_blob(self._owner, self._repo, blob.sha)\n                for blob, _ in self._blobs_and_paths[\n                    start:end\n                ]  # TODO: use batch_size instead of buffer_size for concurrent requests\n            ]\n        )\n        if self._verbose:\n            end_t = time.time()\n            blob_names_and_sizes = [\n                (blob.path, blob.size) for blob, _ in self._blobs_and_paths[start:end]\n            ]\n            print(\n                \"Time to get blobs (\"\n                + f\"{blob_names_and_sizes}\"\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "7": {"text": "   + f\"{blob_names_and_sizes}\"\n                + f\"): {end_t - start_t:.2f} seconds\"\n            )\n\n        self._buffer = [\n            (result, path)\n            for result, (_, path) in zip(results, self._blobs_and_paths[start:end])\n        ]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 7, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "8": {"text": "This module contains utility functions for the Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation. It is used to retrieve the contents of the files in a Github repository. The get_blob operation is called for each blob in the blobs_and_paths list and the blobs are retrieved in batches of size buffer_size. The print_if_verbose and get_file_extension functions are also included.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"8": {"text": "This module contains utility functions for the Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation. It is used to retrieve the contents of the files in a Github repository. The get_blob operation is called for each blob in the blobs_and_paths list and the blobs are retrieved in batches of size buffer_size. The print_if_verbose and get_file_extension functions are also included.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"98449e52eda3d6ee33e51429362e457d29f7893e": {"text": "\"\"\"\nGithub readers utils.\n\nThis module contains utility functions for the Github readers.\n\"\"\"\nimport asyncio\nimport os\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nfrom gpt_index.readers.github_readers.github_api_client import (\n    GitBlobResponseModel,\n    GithubClient,\n    GitTreeResponseModel,\n)\n\n\ndef print_if_verbose(verbose: bool, message: str) -> None:\n    \"\"\"Log message if verbose is True.\"\"\"\n    if verbose:\n        print(message)\n\n\ndef get_file_extension(filename: str) -> str:\n    \"\"\"Get file extension.\"\"\"\n    return f\".{os.path.splitext(filename)[1][1:].lower()}\"\n\n\nclass BufferedAsyncIterator(ABC):\n    \"\"\"\n    Base class for buffered async iterators.\n\n    This class is to be used as a base class for async iterators\n    that need to buffer the results of an async operation.\n    The async operation is defined in the _fill_buffer method.\n    The _fill_buffer method is called when the buffer is empty.\n    \"\"\"\n\n    def __init__(self, buffer_size: int):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - `buffer_size (int)`: Size of the buffer.\n                It is also the number of items that will\n                be retrieved from the async operation at once.\n                see _fill_buffer. Defaults to 2. Setting it to 1\n                will result in the same behavior as a synchronous iterator.\n        \"\"\"\n        self._buffer_size = buffer_size\n        self._buffer: List[Tuple[GitBlobResponseModel, str]] = []\n        self._index = 0\n\n    @abstractmethod\n    async def _fill_buffer(self) -> None:\n        raise NotImplementedError\n\n    def __aiter__(self) -> \"BufferedAsyncIterator\":\n        \"\"\"Return the iterator object.\"\"\"\n        return self\n\n    async def __anext__(self) -> Tuple[GitBlobResponseModel, str]:\n        \"\"\"\n        Get next item.\n\n        Returns:\n            - `item (Tuple[GitBlobResponseModel, str])`: Next item.\n\n        Raises:\n            - `StopAsyncIteration`: If there are no more items.\n        \"\"\"\n        if not self._buffer:\n            await self._fill_buffer()\n\n        if not self._buffer:\n            raise StopAsyncIteration\n\n        item = self._buffer.pop(0)\n        self._index += 1\n        return item\n\n\nclass BufferedGitBlobDataIterator(BufferedAsyncIterator):\n    \"\"\"\n    Buffered async iterator for Git blobs.\n\n    This class is an async iterator that buffers the results of the get_blob operation.\n    It is used to retrieve the contents of the files in a Github repository.\n    getBlob endpoint supports up to 100 megabytes of content for blobs.\n    This concrete implementation of BufferedAsyncIterator allows you to lazily retrieve\n    the contents of the files in a Github repository.\n    Otherwise you would have to retrieve all the contents of\n    the files in the repository at once, which would\n    be problematic if the repository is large.\n    \"\"\"\n\n    def __init__(\n        self,\n        blobs_and_paths: List[Tuple[GitTreeResponseModel.GitTreeObject, str]],\n        github_client: GithubClient,\n        owner: str,\n        repo: str,\n        loop: asyncio.AbstractEventLoop,\n        buffer_size: int,\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - blobs_and_paths (List[Tuple[GitTreeResponseModel.GitTreeObject, str]]):\n                List of tuples containing the blob and the path of the file.\n            - github_client (GithubClient): Github client.\n            - owner (str): Owner of the repository.\n            - repo (str): Name of the repository.\n            - loop (asyncio.AbstractEventLoop): Event loop.\n            - buffer_size (int): Size of the buffer.\n        \"\"\"\n        super().__init__(buffer_size)\n        self._blobs_and_paths = blobs_and_paths\n        self._github_client = github_client\n        self._owner = owner\n        self._repo = repo\n        self._verbose = verbose\n        if loop is None:\n            loop = asyncio.get_event_loop()\n            if loop is None:\n                raise ValueError(\"No event loop found\")\n\n    async def _fill_buffer(self) -> None:\n        \"\"\"\n        Fill the buffer with the results of the get_blob operation.\n\n        The get_blob operation is called for each blob in the blobs_and_paths list.\n        The blobs are retrieved in batches of size buffer_size.\n        \"\"\"\n        del self._buffer[:]\n        self._buffer = []\n        start = self._index\n        end = min(start + self._buffer_size, len(self._blobs_and_paths))\n\n        if start >= end:\n            return\n\n        if self._verbose:\n            start_t = time.time()\n        results: List[GitBlobResponseModel] = await asyncio.gather(\n            *[\n                self._github_client.get_blob(self._owner, self._repo, blob.sha)\n                for blob, _ in self._blobs_and_paths[\n                    start:end\n                ]  # TODO: use batch_size instead of buffer_size for concurrent requests\n            ]\n        )\n        if self._verbose:\n            end_t = time.time()\n            blob_names_and_sizes = [\n                (blob.path, blob.size) for blob, _ in self._blobs_and_paths[start:end]\n            ]\n            print(\n                \"Time to get blobs (\"\n                + f\"{blob_names_and_sizes}\"\n                + f\"): {end_t - start_t:.2f} seconds\"\n            )\n\n        self._buffer = [\n            (result, path)\n            for result, (_, path) in zip(results, self._blobs_and_paths[start:end])\n        ]\n", "doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "__type__": "Document"}, "615ec692-455c-4cee-9468-b97d0cd9a279": {"text": "\nThis code file contains utility functions for Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation, which is used to retrieve the contents of the files in a Github repository. The print_if_verbose and get_file_extension functions are also included. The BufferedAsyncIterator class provides a base class for buffering the results of an async operation, while the BufferedGitBlobDataIterator class provides an async iterator for Git blobs. The print_if_verbose function logs a message if verbose is True, and the get_file_extension function returns the file extension of a given filename. The code file provides a set of utility functions for Github readers, allowing them to retrieve the contents of files in a repository and log messages if verbose is True.", "doc_id": "615ec692-455c-4cee-9468-b97d0cd9a279", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"\nGithub readers utils.\n\nThis module contains utility functions for the Github readers.\n\"\"\"\nimport asyncio\nimport os\nimport time\nfrom abc import ABC, abstractmethod\nfrom typing import List, Tuple\n\nfrom gpt_index.readers.github_readers.github_api_client import (\n    GitBlobResponseModel,\n    GithubClient,\n    GitTreeResponseModel,\n)\n\n\ndef print_if_verbose(verbose: bool, message: str) -> None:\n    \"\"\"Log message if verbose is True.\"\"\"\n    if verbose:\n        print(message)\n\n\ndef get_file_extension(filename: str) -> str:\n    \"\"\"Get file extension.\"\"\"\n    return f\".{os.path.splitext(filename)[1][1:].lower()}\"\n\n\nclass BufferedAsyncIterator(ABC):\n    \"\"\"\n    Base class for buffered async iterators.\n\n    This class is to be used as a base class for async iterators\n    that need to buffer the results of an async operation.\n    The async operation is defined in the _fill_buffer method.\n    The _fill_buffer method is called when the buffer is empty.\n    \"\"\"\n\n    def __init__(self, buffer_size: int):\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "1": {"text": "   def __init__(self, buffer_size: int):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - `buffer_size (int)`: Size of the buffer.\n                It is also the number of items that will\n                be retrieved from the async operation at once.\n                see _fill_buffer. Defaults to 2. Setting it to 1\n                will result in the same behavior as a synchronous iterator.\n        \"\"\"\n        self._buffer_size = buffer_size\n        self._buffer: List[Tuple[GitBlobResponseModel, str]] = []\n        self._index = 0\n\n    @abstractmethod\n    async def _fill_buffer(self) -> None:\n        raise NotImplementedError\n\n    def __aiter__(self) -> \"BufferedAsyncIterator\":\n        \"\"\"Return the iterator object.\"\"\"\n        return self\n\n    async def", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "2": {"text": "object.\"\"\"\n        return self\n\n    async def __anext__(self) -> Tuple[GitBlobResponseModel, str]:\n        \"\"\"\n        Get next item.\n\n        Returns:\n            - `item (Tuple[GitBlobResponseModel, str])`: Next item.\n\n        Raises:\n            - `StopAsyncIteration`: If there are no more items.\n        \"\"\"\n        if not self._buffer:\n            await self._fill_buffer()\n\n        if not self._buffer:\n            raise StopAsyncIteration\n\n        item = self._buffer.pop(0)\n        self._index += 1\n        return item\n\n\nclass BufferedGitBlobDataIterator(BufferedAsyncIterator):\n    \"\"\"\n    Buffered async iterator for Git blobs.\n\n    This class is an async iterator that buffers the results of the get_blob operation.\n    It is used to retrieve the contents of the files in a Github repository.\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "3": {"text": "retrieve the contents of the files in a Github repository.\n    getBlob endpoint supports up to 100 megabytes of content for blobs.\n    This concrete implementation of BufferedAsyncIterator allows you to lazily retrieve\n    the contents of the files in a Github repository.\n    Otherwise you would have to retrieve all the contents of\n    the files in the repository at once, which would\n    be problematic if the repository is large.\n    \"\"\"\n\n    def __init__(\n        self,\n        blobs_and_paths: List[Tuple[GitTreeResponseModel.GitTreeObject, str]],\n        github_client: GithubClient,\n        owner: str,\n        repo: str,\n        loop: asyncio.AbstractEventLoop,\n        buffer_size: int,\n        verbose: bool = False,\n    ):\n        \"\"\"\n        Initialize params.\n\n        Args:\n            - blobs_and_paths (List[Tuple[GitTreeResponseModel.GitTreeObject,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "4": {"text": "(List[Tuple[GitTreeResponseModel.GitTreeObject, str]]):\n                List of tuples containing the blob and the path of the file.\n            - github_client (GithubClient): Github client.\n            - owner (str): Owner of the repository.\n            - repo (str): Name of the repository.\n            - loop (asyncio.AbstractEventLoop): Event loop.\n            - buffer_size (int): Size of the buffer.\n        \"\"\"\n        super().__init__(buffer_size)\n        self._blobs_and_paths = blobs_and_paths\n        self._github_client = github_client\n        self._owner = owner\n        self._repo = repo\n        self._verbose = verbose\n        if loop is None:\n            loop = asyncio.get_event_loop()\n            if loop is None:\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "5": {"text": "          if loop is None:\n                raise ValueError(\"No event loop found\")\n\n    async def _fill_buffer(self) -> None:\n        \"\"\"\n        Fill the buffer with the results of the get_blob operation.\n\n        The get_blob operation is called for each blob in the blobs_and_paths list.\n        The blobs are retrieved in batches of size buffer_size.\n        \"\"\"\n        del self._buffer[:]\n        self._buffer = []\n        start = self._index\n        end = min(start + self._buffer_size, len(self._blobs_and_paths))\n\n        if start >= end:\n            return\n\n        if self._verbose:\n            start_t = time.time()\n        results: List[GitBlobResponseModel] = await asyncio.gather(\n            *[\n               ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "6": {"text": "  *[\n                self._github_client.get_blob(self._owner, self._repo, blob.sha)\n                for blob, _ in self._blobs_and_paths[\n                    start:end\n                ]  # TODO: use batch_size instead of buffer_size for concurrent requests\n            ]\n        )\n        if self._verbose:\n            end_t = time.time()\n            blob_names_and_sizes = [\n                (blob.path, blob.size) for blob, _ in self._blobs_and_paths[start:end]\n            ]\n            print(\n                \"Time to get blobs (\"\n                + f\"{blob_names_and_sizes}\"\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "7": {"text": "   + f\"{blob_names_and_sizes}\"\n                + f\"): {end_t - start_t:.2f} seconds\"\n            )\n\n        self._buffer = [\n            (result, path)\n            for result, (_, path) in zip(results, self._blobs_and_paths[start:end])\n        ]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/github_readers/utils.py", "file_name": "utils.py"}, "index": 7, "child_indices": [], "ref_doc_id": "98449e52eda3d6ee33e51429362e457d29f7893e", "node_info": null}, "8": {"text": "This module contains utility functions for the Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation. It is used to retrieve the contents of the files in a Github repository. The get_blob operation is called for each blob in the blobs_and_paths list and the blobs are retrieved in batches of size buffer_size. The print_if_verbose and get_file_extension functions are also included.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"8": {"text": "This module contains utility functions for the Github readers. It includes a BufferedAsyncIterator class which is used as a base class for async iterators that need to buffer the results of an async operation. The BufferedGitBlobDataIterator class is an async iterator that buffers the results of the get_blob operation. It is used to retrieve the contents of the files in a Github repository. The get_blob operation is called for each blob in the blobs_and_paths list and the blobs are retrieved in batches of size buffer_size. The print_if_verbose and get_file_extension functions are also included.", "doc_id": null, "embedding": null, "extra_info": null, "index": 8, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}