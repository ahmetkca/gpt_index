{"index_struct": {"text": "\nThis code file contains functions and classes for integrating GPT Index and Weaviate. It includes functions for converting between GPT Index data structures and Weaviate-specific data structures, as well as for creating and retrieving data from Weaviate. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results. The main classes are BaseWeaviateIndexStruct and WeaviateNode, which contain functions for creating a schema, getting entries by ID, and converting to and from GPT Index data structures. The purpose of the code is to facilitate the integration of GPT Index and Weaviate, allowing for the efficient storage and retrieval of data.", "doc_id": "8006787d-adc6-492b-b09b-4b57412e9e97", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Weaviate-specific serializers for GPT Index data structures.\n\nContain conversion to and from dataclasses that GPT Index uses.\n\n\"\"\"\n\nimport json\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Generic, List, Optional, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct, Node\nfrom gpt_index.readers.weaviate.utils import (\n    get_by_id,\n    parse_get_response,\n    validate_client,\n)\nfrom gpt_index.utils import get_new_id\n\nIS = TypeVar(\"IS\", bound=IndexStruct)\n\n\nclass BaseWeaviateIndexStruct(Generic[IS]):\n    \"\"\"Base Weaviate index struct.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n\n    @classmethod\n    def _get_common_properties(cls) -> List[Dict]:\n        \"\"\"Get common properties.\"\"\"\n        return [\n            {\n                \"dataType\": [\"string\"],\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 0, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "1": {"text": "  \"dataType\": [\"string\"],\n                \"description\": \"Text property\",\n                \"name\": \"text\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"Document id\",\n                \"name\": \"doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"extra_info (in JSON)\",\n                \"name\": \"extra_info\",\n            },\n        ]\n\n    @classmethod\n    @abstractmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Get properties specific to each index struct.\n\n        Used in creating schema.\n\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 1, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "2": {"text": "       Used in creating schema.\n\n        \"\"\"\n\n    @classmethod\n    def _get_by_id(cls, client: Any, object_id: str, class_prefix: str) -> Dict:\n        \"\"\"Get entry by id.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        entry = get_by_id(client, object_id, class_name, prop_names)\n        return entry\n\n    @classmethod\n    def create_schema(cls, client: Any, class_prefix: str) -> None:\n        \"\"\"Create schema.\"\"\"\n        validate_client(client)\n        # first check if schema exists\n        schema = client.schema.get()\n        classes = schema[\"classes\"]\n        existing_class_names = {c[\"class\"] for c in", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 2, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "3": {"text": "      existing_class_names = {c[\"class\"] for c in classes}\n        # if schema already exists, don't create\n        class_name = cls._class_name(class_prefix)\n        if class_name in existing_class_names:\n            return\n\n        # get common properties\n        properties = cls._get_common_properties()\n        # get specific properties\n        properties.extend(cls._get_properties())\n        class_obj = {\n            \"class\": cls._class_name(class_prefix),  # <= note the capital \"A\".\n            \"description\": f\"Class for {class_name}\",\n            \"properties\": properties,\n        }\n        client.schema.create_class(class_obj)\n\n    @classmethod\n    @abstractmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> IS:\n        \"\"\"Convert to gpt index list.\"\"\"\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 3, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "4": {"text": "       \"\"\"Convert to gpt index list.\"\"\"\n\n    @classmethod\n    def to_gpt_index_list(\n        cls,\n        client: Any,\n        class_prefix: str,\n        vector: Optional[List[float]] = None,\n        object_limit: Optional[int] = None,\n    ) -> List[IS]:\n        \"\"\"Convert to gpt index list.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        query = client.query.get(class_name, prop_names).with_additional(\n            [\"id\", \"vector\"]\n        )\n        if vector is not None:\n            query = query.with_near_vector(\n                {\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 4, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "5": {"text": "              {\n                    \"vector\": vector,\n                }\n            )\n        if object_limit is not None:\n            query = query.with_limit(object_limit)\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n\n        results: List[IS] = []\n        for entry in entries:\n            results.append(cls._entry_to_gpt_index(entry))\n\n        return results\n\n    @classmethod\n    @abstractmethod\n    def _from_gpt_index(cls, client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n\n    @classmethod\n    def from_gpt_index(cls, client: Any, index: IS, class_prefix: str)", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 5, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "6": {"text": "client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        validate_client(client)\n        index_id = cls._from_gpt_index(client, index, class_prefix)\n        client.batch.flush()\n        return index_id\n\n\nclass WeaviateNode(BaseWeaviateIndexStruct[Node]):\n    \"\"\"Weaviate node.\"\"\"\n\n    @classmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n        return f\"{class_prefix}_Node\"\n\n    @classmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Create schema.\"\"\"\n        return [\n            {\n                \"dataType\": [\"int\"],\n                \"description\": \"The index of the Node\",\n                \"name\": \"index\",\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 6, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "7": {"text": "  \"name\": \"index\",\n            },\n            {\n                \"dataType\": [\"int[]\"],\n                \"description\": \"The child_indices of the Node\",\n                \"name\": \"child_indices\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"The ref_doc_id of the Node\",\n                \"name\": \"ref_doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"node_info (in JSON)\",\n                \"name\": \"node_info\",\n            },\n        ]\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 7, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "8": {"text": "       },\n        ]\n\n    @classmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> Node:\n        \"\"\"Convert to gpt index list.\"\"\"\n        extra_info_str = entry[\"extra_info\"]\n        if extra_info_str == \"\":\n            extra_info = None\n        else:\n            extra_info = json.loads(extra_info_str)\n\n        node_info_str = entry[\"node_info\"]\n        if node_info_str == \"\":\n            node_info = None\n        else:\n            node_info = json.loads(node_info_str)\n        return Node(\n            text=entry[\"text\"],\n            doc_id=entry[\"doc_id\"],\n            index=int(entry[\"index\"]),\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 8, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "9": {"text": "           child_indices=entry[\"child_indices\"],\n            ref_doc_id=entry[\"ref_doc_id\"],\n            embedding=entry[\"_additional\"][\"vector\"],\n            extra_info=extra_info,\n            node_info=node_info,\n        )\n\n    @classmethod\n    def _from_gpt_index(cls, client: Any, node: Node, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        node_dict = node.to_dict()\n        vector = node_dict.pop(\"embedding\")\n        extra_info = node_dict.pop(\"extra_info\")\n        # json-serialize the extra_info\n        extra_info_str = \"\"\n        if extra_info is not None:\n            extra_info_str = json.dumps(extra_info)\n        node_dict[\"extra_info\"] = extra_info_str\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 9, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "10": {"text": "node_dict[\"extra_info\"] = extra_info_str\n        # json-serialize the node_info\n        node_info = node_dict.pop(\"node_info\")\n        node_info_str = \"\"\n        if node_info is not None:\n            node_info_str = json.dumps(node_info)\n        node_dict[\"node_info\"] = node_info_str\n\n        # TODO: account for existing nodes that are stored\n        node_id = get_new_id(set())\n        class_name = cls._class_name(class_prefix)\n        client.batch.add_data_object(node_dict, class_name, node_id, vector)\n\n        return node_id\n\n    @classmethod\n    def delete_document(cls, client: Any, ref_doc_id: str, class_prefix: str) -> None:\n        \"\"\"Delete entry.\"\"\"\n        validate_client(client)\n        # make sure that each entry\n        class_name =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 10, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "11": {"text": "  # make sure that each entry\n        class_name = cls._class_name(class_prefix)\n        where_filter = {\n            \"path\": [\"ref_doc_id\"],\n            \"operator\": \"Equal\",\n            \"valueString\": ref_doc_id,\n        }\n        query = (\n            client.query.get(class_name)\n            .with_additional([\"id\"])\n            .with_where(where_filter)\n        )\n\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n        for entry in entries:\n            client.data_object.delete(entry[\"_additional\"][\"id\"], class_name)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 11, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "12": {"text": "This code file contains Weaviate-specific serializers for GPT Index data structures. It contains functions for converting between dataclasses that GPT Index uses and Weaviate-specific data structures. It also contains functions for creating and retrieving data from Weaviate, as well as for converting between GPT Index data structures and Weaviate-specific data structures. The code is used to facilitate the integration of GPT Index and Weaviate.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "This code file contains functions related to data structures used in the Weaviate GPT index. It includes functions for adding and deleting documents from the index, as well as for retrieving new IDs and class names. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"12": {"text": "This code file contains Weaviate-specific serializers for GPT Index data structures. It contains functions for converting between dataclasses that GPT Index uses and Weaviate-specific data structures. It also contains functions for creating and retrieving data from Weaviate, as well as for converting between GPT Index data structures and Weaviate-specific data structures. The code is used to facilitate the integration of GPT Index and Weaviate.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "This code file contains functions related to data structures used in the Weaviate GPT index. It includes functions for adding and deleting documents from the index, as well as for retrieving new IDs and class names. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"460d2ae4fea64197bd58b237d3e9f7ac8ad5604e": {"text": "\"\"\"Weaviate-specific serializers for GPT Index data structures.\n\nContain conversion to and from dataclasses that GPT Index uses.\n\n\"\"\"\n\nimport json\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Generic, List, Optional, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct, Node\nfrom gpt_index.readers.weaviate.utils import (\n    get_by_id,\n    parse_get_response,\n    validate_client,\n)\nfrom gpt_index.utils import get_new_id\n\nIS = TypeVar(\"IS\", bound=IndexStruct)\n\n\nclass BaseWeaviateIndexStruct(Generic[IS]):\n    \"\"\"Base Weaviate index struct.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n\n    @classmethod\n    def _get_common_properties(cls) -> List[Dict]:\n        \"\"\"Get common properties.\"\"\"\n        return [\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"Text property\",\n                \"name\": \"text\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"Document id\",\n                \"name\": \"doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"extra_info (in JSON)\",\n                \"name\": \"extra_info\",\n            },\n        ]\n\n    @classmethod\n    @abstractmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Get properties specific to each index struct.\n\n        Used in creating schema.\n\n        \"\"\"\n\n    @classmethod\n    def _get_by_id(cls, client: Any, object_id: str, class_prefix: str) -> Dict:\n        \"\"\"Get entry by id.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        entry = get_by_id(client, object_id, class_name, prop_names)\n        return entry\n\n    @classmethod\n    def create_schema(cls, client: Any, class_prefix: str) -> None:\n        \"\"\"Create schema.\"\"\"\n        validate_client(client)\n        # first check if schema exists\n        schema = client.schema.get()\n        classes = schema[\"classes\"]\n        existing_class_names = {c[\"class\"] for c in classes}\n        # if schema already exists, don't create\n        class_name = cls._class_name(class_prefix)\n        if class_name in existing_class_names:\n            return\n\n        # get common properties\n        properties = cls._get_common_properties()\n        # get specific properties\n        properties.extend(cls._get_properties())\n        class_obj = {\n            \"class\": cls._class_name(class_prefix),  # <= note the capital \"A\".\n            \"description\": f\"Class for {class_name}\",\n            \"properties\": properties,\n        }\n        client.schema.create_class(class_obj)\n\n    @classmethod\n    @abstractmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> IS:\n        \"\"\"Convert to gpt index list.\"\"\"\n\n    @classmethod\n    def to_gpt_index_list(\n        cls,\n        client: Any,\n        class_prefix: str,\n        vector: Optional[List[float]] = None,\n        object_limit: Optional[int] = None,\n    ) -> List[IS]:\n        \"\"\"Convert to gpt index list.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        query = client.query.get(class_name, prop_names).with_additional(\n            [\"id\", \"vector\"]\n        )\n        if vector is not None:\n            query = query.with_near_vector(\n                {\n                    \"vector\": vector,\n                }\n            )\n        if object_limit is not None:\n            query = query.with_limit(object_limit)\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n\n        results: List[IS] = []\n        for entry in entries:\n            results.append(cls._entry_to_gpt_index(entry))\n\n        return results\n\n    @classmethod\n    @abstractmethod\n    def _from_gpt_index(cls, client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n\n    @classmethod\n    def from_gpt_index(cls, client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        validate_client(client)\n        index_id = cls._from_gpt_index(client, index, class_prefix)\n        client.batch.flush()\n        return index_id\n\n\nclass WeaviateNode(BaseWeaviateIndexStruct[Node]):\n    \"\"\"Weaviate node.\"\"\"\n\n    @classmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n        return f\"{class_prefix}_Node\"\n\n    @classmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Create schema.\"\"\"\n        return [\n            {\n                \"dataType\": [\"int\"],\n                \"description\": \"The index of the Node\",\n                \"name\": \"index\",\n            },\n            {\n                \"dataType\": [\"int[]\"],\n                \"description\": \"The child_indices of the Node\",\n                \"name\": \"child_indices\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"The ref_doc_id of the Node\",\n                \"name\": \"ref_doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"node_info (in JSON)\",\n                \"name\": \"node_info\",\n            },\n        ]\n\n    @classmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> Node:\n        \"\"\"Convert to gpt index list.\"\"\"\n        extra_info_str = entry[\"extra_info\"]\n        if extra_info_str == \"\":\n            extra_info = None\n        else:\n            extra_info = json.loads(extra_info_str)\n\n        node_info_str = entry[\"node_info\"]\n        if node_info_str == \"\":\n            node_info = None\n        else:\n            node_info = json.loads(node_info_str)\n        return Node(\n            text=entry[\"text\"],\n            doc_id=entry[\"doc_id\"],\n            index=int(entry[\"index\"]),\n            child_indices=entry[\"child_indices\"],\n            ref_doc_id=entry[\"ref_doc_id\"],\n            embedding=entry[\"_additional\"][\"vector\"],\n            extra_info=extra_info,\n            node_info=node_info,\n        )\n\n    @classmethod\n    def _from_gpt_index(cls, client: Any, node: Node, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        node_dict = node.to_dict()\n        vector = node_dict.pop(\"embedding\")\n        extra_info = node_dict.pop(\"extra_info\")\n        # json-serialize the extra_info\n        extra_info_str = \"\"\n        if extra_info is not None:\n            extra_info_str = json.dumps(extra_info)\n        node_dict[\"extra_info\"] = extra_info_str\n        # json-serialize the node_info\n        node_info = node_dict.pop(\"node_info\")\n        node_info_str = \"\"\n        if node_info is not None:\n            node_info_str = json.dumps(node_info)\n        node_dict[\"node_info\"] = node_info_str\n\n        # TODO: account for existing nodes that are stored\n        node_id = get_new_id(set())\n        class_name = cls._class_name(class_prefix)\n        client.batch.add_data_object(node_dict, class_name, node_id, vector)\n\n        return node_id\n\n    @classmethod\n    def delete_document(cls, client: Any, ref_doc_id: str, class_prefix: str) -> None:\n        \"\"\"Delete entry.\"\"\"\n        validate_client(client)\n        # make sure that each entry\n        class_name = cls._class_name(class_prefix)\n        where_filter = {\n            \"path\": [\"ref_doc_id\"],\n            \"operator\": \"Equal\",\n            \"valueString\": ref_doc_id,\n        }\n        query = (\n            client.query.get(class_name)\n            .with_additional([\"id\"])\n            .with_where(where_filter)\n        )\n\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n        for entry in entries:\n            client.data_object.delete(entry[\"_additional\"][\"id\"], class_name)\n", "doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "__type__": "Document"}, "8006787d-adc6-492b-b09b-4b57412e9e97": {"text": "\nThis code file contains functions and classes for integrating GPT Index and Weaviate. It includes functions for converting between GPT Index data structures and Weaviate-specific data structures, as well as for creating and retrieving data from Weaviate. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results. The main classes are BaseWeaviateIndexStruct and WeaviateNode, which contain functions for creating a schema, getting entries by ID, and converting to and from GPT Index data structures. The purpose of the code is to facilitate the integration of GPT Index and Weaviate, allowing for the efficient storage and retrieval of data.", "doc_id": "8006787d-adc6-492b-b09b-4b57412e9e97", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Weaviate-specific serializers for GPT Index data structures.\n\nContain conversion to and from dataclasses that GPT Index uses.\n\n\"\"\"\n\nimport json\nfrom abc import abstractmethod\nfrom typing import Any, Dict, Generic, List, Optional, TypeVar\n\nfrom gpt_index.data_structs.data_structs import IndexStruct, Node\nfrom gpt_index.readers.weaviate.utils import (\n    get_by_id,\n    parse_get_response,\n    validate_client,\n)\nfrom gpt_index.utils import get_new_id\n\nIS = TypeVar(\"IS\", bound=IndexStruct)\n\n\nclass BaseWeaviateIndexStruct(Generic[IS]):\n    \"\"\"Base Weaviate index struct.\"\"\"\n\n    @classmethod\n    @abstractmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n\n    @classmethod\n    def _get_common_properties(cls) -> List[Dict]:\n        \"\"\"Get common properties.\"\"\"\n        return [\n            {\n                \"dataType\": [\"string\"],\n          ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 0, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "1": {"text": "  \"dataType\": [\"string\"],\n                \"description\": \"Text property\",\n                \"name\": \"text\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"Document id\",\n                \"name\": \"doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"extra_info (in JSON)\",\n                \"name\": \"extra_info\",\n            },\n        ]\n\n    @classmethod\n    @abstractmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Get properties specific to each index struct.\n\n        Used in creating schema.\n\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 1, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "2": {"text": "       Used in creating schema.\n\n        \"\"\"\n\n    @classmethod\n    def _get_by_id(cls, client: Any, object_id: str, class_prefix: str) -> Dict:\n        \"\"\"Get entry by id.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        entry = get_by_id(client, object_id, class_name, prop_names)\n        return entry\n\n    @classmethod\n    def create_schema(cls, client: Any, class_prefix: str) -> None:\n        \"\"\"Create schema.\"\"\"\n        validate_client(client)\n        # first check if schema exists\n        schema = client.schema.get()\n        classes = schema[\"classes\"]\n        existing_class_names = {c[\"class\"] for c in", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 2, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "3": {"text": "      existing_class_names = {c[\"class\"] for c in classes}\n        # if schema already exists, don't create\n        class_name = cls._class_name(class_prefix)\n        if class_name in existing_class_names:\n            return\n\n        # get common properties\n        properties = cls._get_common_properties()\n        # get specific properties\n        properties.extend(cls._get_properties())\n        class_obj = {\n            \"class\": cls._class_name(class_prefix),  # <= note the capital \"A\".\n            \"description\": f\"Class for {class_name}\",\n            \"properties\": properties,\n        }\n        client.schema.create_class(class_obj)\n\n    @classmethod\n    @abstractmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> IS:\n        \"\"\"Convert to gpt index list.\"\"\"\n\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 3, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "4": {"text": "       \"\"\"Convert to gpt index list.\"\"\"\n\n    @classmethod\n    def to_gpt_index_list(\n        cls,\n        client: Any,\n        class_prefix: str,\n        vector: Optional[List[float]] = None,\n        object_limit: Optional[int] = None,\n    ) -> List[IS]:\n        \"\"\"Convert to gpt index list.\"\"\"\n        validate_client(client)\n        class_name = cls._class_name(class_prefix)\n        properties = cls._get_common_properties() + cls._get_properties()\n        prop_names = [p[\"name\"] for p in properties]\n        query = client.query.get(class_name, prop_names).with_additional(\n            [\"id\", \"vector\"]\n        )\n        if vector is not None:\n            query = query.with_near_vector(\n                {\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 4, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "5": {"text": "              {\n                    \"vector\": vector,\n                }\n            )\n        if object_limit is not None:\n            query = query.with_limit(object_limit)\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n\n        results: List[IS] = []\n        for entry in entries:\n            results.append(cls._entry_to_gpt_index(entry))\n\n        return results\n\n    @classmethod\n    @abstractmethod\n    def _from_gpt_index(cls, client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n\n    @classmethod\n    def from_gpt_index(cls, client: Any, index: IS, class_prefix: str)", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 5, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "6": {"text": "client: Any, index: IS, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        validate_client(client)\n        index_id = cls._from_gpt_index(client, index, class_prefix)\n        client.batch.flush()\n        return index_id\n\n\nclass WeaviateNode(BaseWeaviateIndexStruct[Node]):\n    \"\"\"Weaviate node.\"\"\"\n\n    @classmethod\n    def _class_name(cls, class_prefix: str) -> str:\n        \"\"\"Return class name.\"\"\"\n        return f\"{class_prefix}_Node\"\n\n    @classmethod\n    def _get_properties(cls) -> List[Dict]:\n        \"\"\"Create schema.\"\"\"\n        return [\n            {\n                \"dataType\": [\"int\"],\n                \"description\": \"The index of the Node\",\n                \"name\": \"index\",\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 6, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "7": {"text": "  \"name\": \"index\",\n            },\n            {\n                \"dataType\": [\"int[]\"],\n                \"description\": \"The child_indices of the Node\",\n                \"name\": \"child_indices\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"The ref_doc_id of the Node\",\n                \"name\": \"ref_doc_id\",\n            },\n            {\n                \"dataType\": [\"string\"],\n                \"description\": \"node_info (in JSON)\",\n                \"name\": \"node_info\",\n            },\n        ]\n\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 7, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "8": {"text": "       },\n        ]\n\n    @classmethod\n    def _entry_to_gpt_index(cls, entry: Dict) -> Node:\n        \"\"\"Convert to gpt index list.\"\"\"\n        extra_info_str = entry[\"extra_info\"]\n        if extra_info_str == \"\":\n            extra_info = None\n        else:\n            extra_info = json.loads(extra_info_str)\n\n        node_info_str = entry[\"node_info\"]\n        if node_info_str == \"\":\n            node_info = None\n        else:\n            node_info = json.loads(node_info_str)\n        return Node(\n            text=entry[\"text\"],\n            doc_id=entry[\"doc_id\"],\n            index=int(entry[\"index\"]),\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 8, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "9": {"text": "           child_indices=entry[\"child_indices\"],\n            ref_doc_id=entry[\"ref_doc_id\"],\n            embedding=entry[\"_additional\"][\"vector\"],\n            extra_info=extra_info,\n            node_info=node_info,\n        )\n\n    @classmethod\n    def _from_gpt_index(cls, client: Any, node: Node, class_prefix: str) -> str:\n        \"\"\"Convert from gpt index.\"\"\"\n        node_dict = node.to_dict()\n        vector = node_dict.pop(\"embedding\")\n        extra_info = node_dict.pop(\"extra_info\")\n        # json-serialize the extra_info\n        extra_info_str = \"\"\n        if extra_info is not None:\n            extra_info_str = json.dumps(extra_info)\n        node_dict[\"extra_info\"] = extra_info_str\n     ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 9, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "10": {"text": "node_dict[\"extra_info\"] = extra_info_str\n        # json-serialize the node_info\n        node_info = node_dict.pop(\"node_info\")\n        node_info_str = \"\"\n        if node_info is not None:\n            node_info_str = json.dumps(node_info)\n        node_dict[\"node_info\"] = node_info_str\n\n        # TODO: account for existing nodes that are stored\n        node_id = get_new_id(set())\n        class_name = cls._class_name(class_prefix)\n        client.batch.add_data_object(node_dict, class_name, node_id, vector)\n\n        return node_id\n\n    @classmethod\n    def delete_document(cls, client: Any, ref_doc_id: str, class_prefix: str) -> None:\n        \"\"\"Delete entry.\"\"\"\n        validate_client(client)\n        # make sure that each entry\n        class_name =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 10, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "11": {"text": "  # make sure that each entry\n        class_name = cls._class_name(class_prefix)\n        where_filter = {\n            \"path\": [\"ref_doc_id\"],\n            \"operator\": \"Equal\",\n            \"valueString\": ref_doc_id,\n        }\n        query = (\n            client.query.get(class_name)\n            .with_additional([\"id\"])\n            .with_where(where_filter)\n        )\n\n        query_result = query.do()\n        parsed_result = parse_get_response(query_result)\n        entries = parsed_result[class_name]\n        for entry in entries:\n            client.data_object.delete(entry[\"_additional\"][\"id\"], class_name)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/readers/weaviate/data_structs.py", "file_name": "data_structs.py"}, "index": 11, "child_indices": [], "ref_doc_id": "460d2ae4fea64197bd58b237d3e9f7ac8ad5604e", "node_info": null}, "12": {"text": "This code file contains Weaviate-specific serializers for GPT Index data structures. It contains functions for converting between dataclasses that GPT Index uses and Weaviate-specific data structures. It also contains functions for creating and retrieving data from Weaviate, as well as for converting between GPT Index data structures and Weaviate-specific data structures. The code is used to facilitate the integration of GPT Index and Weaviate.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "This code file contains functions related to data structures used in the Weaviate GPT index. It includes functions for adding and deleting documents from the index, as well as for retrieving new IDs and class names. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"12": {"text": "This code file contains Weaviate-specific serializers for GPT Index data structures. It contains functions for converting between dataclasses that GPT Index uses and Weaviate-specific data structures. It also contains functions for creating and retrieving data from Weaviate, as well as for converting between GPT Index data structures and Weaviate-specific data structures. The code is used to facilitate the integration of GPT Index and Weaviate.", "doc_id": null, "embedding": null, "extra_info": null, "index": 12, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "13": {"text": "This code file contains functions related to data structures used in the Weaviate GPT index. It includes functions for adding and deleting documents from the index, as well as for retrieving new IDs and class names. The code uses the JSON serialization format to store node information, and the client.batch and client.query functions to add and delete documents from the index. The code also uses the parse_get_response function to parse the query results.", "doc_id": null, "embedding": null, "extra_info": null, "index": 13, "child_indices": [10, 11], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}