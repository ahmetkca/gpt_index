{"index_struct": {"text": "\nThis code file provides general utility functions and classes for use in other code files. It includes a GlobalsHelper class to retrieve globals, a get_new_id() and get_new_int_id() function to generate unique IDs, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The GlobalsHelper class provides a tokenizer and stopwords list, while the get_new_id() and get_new_int_id() functions generate unique IDs. The temp_set_attrs() context manager allows for temporary setting of attributes on a class, and the ErrorToRetry class and retry_on_exceptions_with_backoff() function provide a way to retry a function call in case of an exception. The purpose of this code is to provide general utility functions and classes for use in other code files, allowing for the retrieval of globals, generation of unique IDs, setting of temporary attributes, and retrying of functions in case", "doc_id": "1f8ab003-3273-41c7-90b6-329c240037ef", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"General utils functions.\"\"\"\n\nimport random\nimport sys\nimport time\nimport traceback\nimport uuid\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Generator, List, Optional, Set, Type, cast\n\nimport nltk\n\n\nclass GlobalsHelper:\n    \"\"\"Helper to retrieve globals.\n\n    Helpful for global caching of certain variables that can be expensive to load.\n    (e.g. tokenization)\n\n    \"\"\"\n\n    _tokenizer: Optional[Callable[[str], List]] = None\n    _stopwords: Optional[List[str]] = None\n\n    @property\n    def tokenizer(self) -> Callable[[str], List]:\n        \"\"\"Get tokenizer.\"\"\"\n        if self._tokenizer is None:\n            # if python version >= 3.9, then use tiktoken\n            # else use GPT2TokenizerFast\n            if sys.version_info >= (3, 9):\n                tiktoken_import_err = (\n                    \"`tiktoken` package not found, please run `pip install", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "1": {"text": "    \"`tiktoken` package not found, please run `pip install tiktoken`\"\n                )\n                try:\n                    import tiktoken\n                except ImportError:\n                    raise ValueError(tiktoken_import_err)\n                enc = tiktoken.get_encoding(\"gpt2\")\n                self._tokenizer = cast(Callable[[str], List], enc.encode)\n            else:\n                import transformers\n\n                tokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\n\n                def tokenizer_fn(text: str) -> List:\n                    return tokenizer(text)[\"input_ids\"]\n\n                self._tokenizer =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "2": {"text": "               self._tokenizer = tokenizer_fn\n        return self._tokenizer\n\n    @property\n    def stopwords(self) -> List[str]:\n        \"\"\"Get stopwords.\"\"\"\n        if self._stopwords is None:\n            try:\n                from nltk.corpus import stopwords\n            except ImportError:\n                raise ValueError(\n                    \"`nltk` package not found, please run `pip install nltk`\"\n                )\n            nltk.download(\"stopwords\")\n            self._stopwords = stopwords.words(\"english\")\n        return self._stopwords\n\n\nglobals_helper = GlobalsHelper()\n\n\ndef get_new_id(d: Set) -> str:\n    \"\"\"Get a new ID.\"\"\"\n    while True:\n        new_id = str(uuid.uuid4())\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "3": {"text": "   new_id = str(uuid.uuid4())\n        if new_id not in d:\n            break\n    return new_id\n\n\ndef get_new_int_id(d: Set) -> int:\n    \"\"\"Get a new integer ID.\"\"\"\n    while True:\n        new_id = random.randint(0, sys.maxsize)\n        if new_id not in d:\n            break\n    return new_id\n\n\n@contextmanager\ndef temp_set_attrs(obj: Any, **kwargs: Any) -> Generator:\n    \"\"\"Temporary setter.\n\n    Utility class for setting a temporary value for an attribute on a class.\n    Taken from: https://tinyurl.com/2p89xymh\n\n    \"\"\"\n    prev_values = {k: getattr(obj, k) for k in kwargs}\n    for k, v in kwargs.items():\n        setattr(obj, k, v)\n    try:\n        yield\n    finally:\n        for k, v in prev_values.items():\n            setattr(obj, k,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "4": {"text": "           setattr(obj, k, v)\n\n\n@dataclass\nclass ErrorToRetry:\n    \"\"\"Exception types that should be retried.\n\n    Args:\n        exception_cls (Type[Exception]): Class of exception.\n        check_fn (Optional[Callable[[Any]], bool]]):\n            A function that takes an exception instance as input and returns\n            whether to retry.\n\n    \"\"\"\n\n    exception_cls: Type[Exception]\n    check_fn: Optional[Callable[[Any], bool]] = None\n\n\ndef retry_on_exceptions_with_backoff(\n    lambda_fn: Callable,\n    errors_to_retry: List[ErrorToRetry],\n    max_tries: int = 10,\n    min_backoff_secs: float = 0.5,\n    max_backoff_secs: float = 60.0,\n) -> Any:\n    \"\"\"Execute lambda function with retries and exponential backoff.\n\n    Args:\n        lambda_fn (Callable): Function to be called and output we want.\n        errors_to_retry (List[ErrorToRetry]): List of errors to", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "5": {"text": " errors_to_retry (List[ErrorToRetry]): List of errors to retry.\n            At least one needs to be provided.\n        max_tries (int): Maximum number of tries, including the first. Defaults to 10.\n        min_backoff_secs (float): Minimum amount of backoff time between attempts.\n            Defaults to 0.5.\n        max_backoff_secs (float): Maximum amount of backoff time between attempts.\n            Defaults to 60.\n\n    \"\"\"\n    if not errors_to_retry:\n        raise ValueError(\"At least one error to retry needs to be provided\")\n\n    error_checks = {\n        error_to_retry.exception_cls: error_to_retry.check_fn\n        for error_to_retry in errors_to_retry\n    }\n    exception_class_tuples = tuple(error_checks.keys())\n\n    backoff_secs = min_backoff_secs\n    tries = 0\n\n    while True:\n        try:\n            return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "6": {"text": "     try:\n            return lambda_fn()\n        except exception_class_tuples as e:\n            traceback.print_exc()\n            tries += 1\n            if tries >= max_tries:\n                raise\n            check_fn = error_checks.get(e.__class__)\n            if check_fn and not check_fn(e):\n                raise\n            time.sleep(backoff_secs)\n            backoff_secs = min(backoff_secs * 2, max_backoff_secs)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "7": {"text": "This code file contains functions and classes related to general utilities. It includes a GlobalsHelper class to retrieve globals, a get_new_id() function to generate a new ID, a get_new_int_id() function to generate a new integer ID, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The purpose of this code is to provide general utility functions and classes for use in other code files.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains functions and classes related to general utilities. It includes a GlobalsHelper class to retrieve globals, a get_new_id() function to generate a new ID, a get_new_int_id() function to generate a new integer ID, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The purpose of this code is to provide general utility functions and classes for use in other code files.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"c070558fc2f2babc0f4f950c573000ba295a80c7": {"text": "\"\"\"General utils functions.\"\"\"\n\nimport random\nimport sys\nimport time\nimport traceback\nimport uuid\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Generator, List, Optional, Set, Type, cast\n\nimport nltk\n\n\nclass GlobalsHelper:\n    \"\"\"Helper to retrieve globals.\n\n    Helpful for global caching of certain variables that can be expensive to load.\n    (e.g. tokenization)\n\n    \"\"\"\n\n    _tokenizer: Optional[Callable[[str], List]] = None\n    _stopwords: Optional[List[str]] = None\n\n    @property\n    def tokenizer(self) -> Callable[[str], List]:\n        \"\"\"Get tokenizer.\"\"\"\n        if self._tokenizer is None:\n            # if python version >= 3.9, then use tiktoken\n            # else use GPT2TokenizerFast\n            if sys.version_info >= (3, 9):\n                tiktoken_import_err = (\n                    \"`tiktoken` package not found, please run `pip install tiktoken`\"\n                )\n                try:\n                    import tiktoken\n                except ImportError:\n                    raise ValueError(tiktoken_import_err)\n                enc = tiktoken.get_encoding(\"gpt2\")\n                self._tokenizer = cast(Callable[[str], List], enc.encode)\n            else:\n                import transformers\n\n                tokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\n\n                def tokenizer_fn(text: str) -> List:\n                    return tokenizer(text)[\"input_ids\"]\n\n                self._tokenizer = tokenizer_fn\n        return self._tokenizer\n\n    @property\n    def stopwords(self) -> List[str]:\n        \"\"\"Get stopwords.\"\"\"\n        if self._stopwords is None:\n            try:\n                from nltk.corpus import stopwords\n            except ImportError:\n                raise ValueError(\n                    \"`nltk` package not found, please run `pip install nltk`\"\n                )\n            nltk.download(\"stopwords\")\n            self._stopwords = stopwords.words(\"english\")\n        return self._stopwords\n\n\nglobals_helper = GlobalsHelper()\n\n\ndef get_new_id(d: Set) -> str:\n    \"\"\"Get a new ID.\"\"\"\n    while True:\n        new_id = str(uuid.uuid4())\n        if new_id not in d:\n            break\n    return new_id\n\n\ndef get_new_int_id(d: Set) -> int:\n    \"\"\"Get a new integer ID.\"\"\"\n    while True:\n        new_id = random.randint(0, sys.maxsize)\n        if new_id not in d:\n            break\n    return new_id\n\n\n@contextmanager\ndef temp_set_attrs(obj: Any, **kwargs: Any) -> Generator:\n    \"\"\"Temporary setter.\n\n    Utility class for setting a temporary value for an attribute on a class.\n    Taken from: https://tinyurl.com/2p89xymh\n\n    \"\"\"\n    prev_values = {k: getattr(obj, k) for k in kwargs}\n    for k, v in kwargs.items():\n        setattr(obj, k, v)\n    try:\n        yield\n    finally:\n        for k, v in prev_values.items():\n            setattr(obj, k, v)\n\n\n@dataclass\nclass ErrorToRetry:\n    \"\"\"Exception types that should be retried.\n\n    Args:\n        exception_cls (Type[Exception]): Class of exception.\n        check_fn (Optional[Callable[[Any]], bool]]):\n            A function that takes an exception instance as input and returns\n            whether to retry.\n\n    \"\"\"\n\n    exception_cls: Type[Exception]\n    check_fn: Optional[Callable[[Any], bool]] = None\n\n\ndef retry_on_exceptions_with_backoff(\n    lambda_fn: Callable,\n    errors_to_retry: List[ErrorToRetry],\n    max_tries: int = 10,\n    min_backoff_secs: float = 0.5,\n    max_backoff_secs: float = 60.0,\n) -> Any:\n    \"\"\"Execute lambda function with retries and exponential backoff.\n\n    Args:\n        lambda_fn (Callable): Function to be called and output we want.\n        errors_to_retry (List[ErrorToRetry]): List of errors to retry.\n            At least one needs to be provided.\n        max_tries (int): Maximum number of tries, including the first. Defaults to 10.\n        min_backoff_secs (float): Minimum amount of backoff time between attempts.\n            Defaults to 0.5.\n        max_backoff_secs (float): Maximum amount of backoff time between attempts.\n            Defaults to 60.\n\n    \"\"\"\n    if not errors_to_retry:\n        raise ValueError(\"At least one error to retry needs to be provided\")\n\n    error_checks = {\n        error_to_retry.exception_cls: error_to_retry.check_fn\n        for error_to_retry in errors_to_retry\n    }\n    exception_class_tuples = tuple(error_checks.keys())\n\n    backoff_secs = min_backoff_secs\n    tries = 0\n\n    while True:\n        try:\n            return lambda_fn()\n        except exception_class_tuples as e:\n            traceback.print_exc()\n            tries += 1\n            if tries >= max_tries:\n                raise\n            check_fn = error_checks.get(e.__class__)\n            if check_fn and not check_fn(e):\n                raise\n            time.sleep(backoff_secs)\n            backoff_secs = min(backoff_secs * 2, max_backoff_secs)\n", "doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "__type__": "Document"}, "1f8ab003-3273-41c7-90b6-329c240037ef": {"text": "\nThis code file provides general utility functions and classes for use in other code files. It includes a GlobalsHelper class to retrieve globals, a get_new_id() and get_new_int_id() function to generate unique IDs, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The GlobalsHelper class provides a tokenizer and stopwords list, while the get_new_id() and get_new_int_id() functions generate unique IDs. The temp_set_attrs() context manager allows for temporary setting of attributes on a class, and the ErrorToRetry class and retry_on_exceptions_with_backoff() function provide a way to retry a function call in case of an exception. The purpose of this code is to provide general utility functions and classes for use in other code files, allowing for the retrieval of globals, generation of unique IDs, setting of temporary attributes, and retrying of functions in case", "doc_id": "1f8ab003-3273-41c7-90b6-329c240037ef", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"General utils functions.\"\"\"\n\nimport random\nimport sys\nimport time\nimport traceback\nimport uuid\nfrom contextlib import contextmanager\nfrom dataclasses import dataclass\nfrom typing import Any, Callable, Generator, List, Optional, Set, Type, cast\n\nimport nltk\n\n\nclass GlobalsHelper:\n    \"\"\"Helper to retrieve globals.\n\n    Helpful for global caching of certain variables that can be expensive to load.\n    (e.g. tokenization)\n\n    \"\"\"\n\n    _tokenizer: Optional[Callable[[str], List]] = None\n    _stopwords: Optional[List[str]] = None\n\n    @property\n    def tokenizer(self) -> Callable[[str], List]:\n        \"\"\"Get tokenizer.\"\"\"\n        if self._tokenizer is None:\n            # if python version >= 3.9, then use tiktoken\n            # else use GPT2TokenizerFast\n            if sys.version_info >= (3, 9):\n                tiktoken_import_err = (\n                    \"`tiktoken` package not found, please run `pip install", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 0, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "1": {"text": "    \"`tiktoken` package not found, please run `pip install tiktoken`\"\n                )\n                try:\n                    import tiktoken\n                except ImportError:\n                    raise ValueError(tiktoken_import_err)\n                enc = tiktoken.get_encoding(\"gpt2\")\n                self._tokenizer = cast(Callable[[str], List], enc.encode)\n            else:\n                import transformers\n\n                tokenizer = transformers.GPT2TokenizerFast.from_pretrained(\"gpt2\")\n\n                def tokenizer_fn(text: str) -> List:\n                    return tokenizer(text)[\"input_ids\"]\n\n                self._tokenizer =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 1, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "2": {"text": "               self._tokenizer = tokenizer_fn\n        return self._tokenizer\n\n    @property\n    def stopwords(self) -> List[str]:\n        \"\"\"Get stopwords.\"\"\"\n        if self._stopwords is None:\n            try:\n                from nltk.corpus import stopwords\n            except ImportError:\n                raise ValueError(\n                    \"`nltk` package not found, please run `pip install nltk`\"\n                )\n            nltk.download(\"stopwords\")\n            self._stopwords = stopwords.words(\"english\")\n        return self._stopwords\n\n\nglobals_helper = GlobalsHelper()\n\n\ndef get_new_id(d: Set) -> str:\n    \"\"\"Get a new ID.\"\"\"\n    while True:\n        new_id = str(uuid.uuid4())\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 2, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "3": {"text": "   new_id = str(uuid.uuid4())\n        if new_id not in d:\n            break\n    return new_id\n\n\ndef get_new_int_id(d: Set) -> int:\n    \"\"\"Get a new integer ID.\"\"\"\n    while True:\n        new_id = random.randint(0, sys.maxsize)\n        if new_id not in d:\n            break\n    return new_id\n\n\n@contextmanager\ndef temp_set_attrs(obj: Any, **kwargs: Any) -> Generator:\n    \"\"\"Temporary setter.\n\n    Utility class for setting a temporary value for an attribute on a class.\n    Taken from: https://tinyurl.com/2p89xymh\n\n    \"\"\"\n    prev_values = {k: getattr(obj, k) for k in kwargs}\n    for k, v in kwargs.items():\n        setattr(obj, k, v)\n    try:\n        yield\n    finally:\n        for k, v in prev_values.items():\n            setattr(obj, k,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 3, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "4": {"text": "           setattr(obj, k, v)\n\n\n@dataclass\nclass ErrorToRetry:\n    \"\"\"Exception types that should be retried.\n\n    Args:\n        exception_cls (Type[Exception]): Class of exception.\n        check_fn (Optional[Callable[[Any]], bool]]):\n            A function that takes an exception instance as input and returns\n            whether to retry.\n\n    \"\"\"\n\n    exception_cls: Type[Exception]\n    check_fn: Optional[Callable[[Any], bool]] = None\n\n\ndef retry_on_exceptions_with_backoff(\n    lambda_fn: Callable,\n    errors_to_retry: List[ErrorToRetry],\n    max_tries: int = 10,\n    min_backoff_secs: float = 0.5,\n    max_backoff_secs: float = 60.0,\n) -> Any:\n    \"\"\"Execute lambda function with retries and exponential backoff.\n\n    Args:\n        lambda_fn (Callable): Function to be called and output we want.\n        errors_to_retry (List[ErrorToRetry]): List of errors to", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 4, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "5": {"text": " errors_to_retry (List[ErrorToRetry]): List of errors to retry.\n            At least one needs to be provided.\n        max_tries (int): Maximum number of tries, including the first. Defaults to 10.\n        min_backoff_secs (float): Minimum amount of backoff time between attempts.\n            Defaults to 0.5.\n        max_backoff_secs (float): Maximum amount of backoff time between attempts.\n            Defaults to 60.\n\n    \"\"\"\n    if not errors_to_retry:\n        raise ValueError(\"At least one error to retry needs to be provided\")\n\n    error_checks = {\n        error_to_retry.exception_cls: error_to_retry.check_fn\n        for error_to_retry in errors_to_retry\n    }\n    exception_class_tuples = tuple(error_checks.keys())\n\n    backoff_secs = min_backoff_secs\n    tries = 0\n\n    while True:\n        try:\n            return", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 5, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "6": {"text": "     try:\n            return lambda_fn()\n        except exception_class_tuples as e:\n            traceback.print_exc()\n            tries += 1\n            if tries >= max_tries:\n                raise\n            check_fn = error_checks.get(e.__class__)\n            if check_fn and not check_fn(e):\n                raise\n            time.sleep(backoff_secs)\n            backoff_secs = min(backoff_secs * 2, max_backoff_secs)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "gpt_index/utils.py", "file_name": "utils.py"}, "index": 6, "child_indices": [], "ref_doc_id": "c070558fc2f2babc0f4f950c573000ba295a80c7", "node_info": null}, "7": {"text": "This code file contains functions and classes related to general utilities. It includes a GlobalsHelper class to retrieve globals, a get_new_id() function to generate a new ID, a get_new_int_id() function to generate a new integer ID, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The purpose of this code is to provide general utility functions and classes for use in other code files.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"7": {"text": "This code file contains functions and classes related to general utilities. It includes a GlobalsHelper class to retrieve globals, a get_new_id() function to generate a new ID, a get_new_int_id() function to generate a new integer ID, a temp_set_attrs() context manager to set a temporary value for an attribute on a class, an ErrorToRetry class to define exception types that should be retried, and a retry_on_exceptions_with_backoff() function to execute a lambda function with retries and exponential backoff. The purpose of this code is to provide general utility functions and classes for use in other code files.", "doc_id": null, "embedding": null, "extra_info": null, "index": 7, "child_indices": [0, 1, 2, 3, 4, 5, 6], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}