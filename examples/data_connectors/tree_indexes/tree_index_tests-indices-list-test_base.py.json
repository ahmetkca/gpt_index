{"index_struct": {"text": "\nThe code file test_base.py tests the GPTListIndex class, which is used to store and query text documents. It tests the build_list, build_list_multiple, insert, delete, and query functions, as well as the node info calculation with overlapping node text. The code uses the unittest.mock library to patch common functions, such as the LLMPredictor, PromptHelper, and TokenTextSplitter. It also uses the pytest library to create fixtures for documents and index kwargs. The code tests the ability to save and load the index from disk or a string, as well as the ability to add extra information to the documents in the index. The purpose of the code is to ensure that the GPTListIndex class functions correctly and can be used to create a list index from a list of documents and query it. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity, to achieve this.", "doc_id": "759e302a-cfc5-448d-981b-583b5d7e885a", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "1": {"text": "Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "2": {"text": "   _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "3": {"text": "   Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) ==", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "4": {"text": "   assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "5": {"text": "Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "6": {"text": "== \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "7": {"text": "   query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "8": {"text": "  _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "9": {"text": "return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "10": {"text": " chunk_size=30,\n            chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "11": {"text": "is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "12": {"text": "   documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 12, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "13": {"text": "   _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 13, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "14": {"text": "   doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 14, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "15": {"text": "   _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 15, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "16": {"text": "== \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 16, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "17": {"text": "== \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 17, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "18": {"text": "This code file tests the GPTListIndex class, which is used to build a list index from documents. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to calculate node info with overlapping node text. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity.", "doc_id": null, "embedding": null, "extra_info": null, "index": 18, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "19": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to create a list index from a list of documents. It tests the query and embedding query functions, as well as the ability to save and load the index from disk or a string. It also tests the ability to add extra information to the documents in the index. The code uses the patch and object functions to mock certain functions and classes, and uses the globals_helper tokenizer.", "doc_id": null, "embedding": null, "extra_info": null, "index": 19, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"18": {"text": "This code file tests the GPTListIndex class, which is used to build a list index from documents. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to calculate node info with overlapping node text. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity.", "doc_id": null, "embedding": null, "extra_info": null, "index": 18, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "19": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to create a list index from a list of documents. It tests the query and embedding query functions, as well as the ability to save and load the index from disk or a string. It also tests the ability to add extra information to the documents in the index. The code uses the patch and object functions to mock certain functions and classes, and uses the globals_helper tokenizer.", "doc_id": null, "embedding": null, "extra_info": null, "index": 19, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"e08da1f225af970a08546034c5064e568f7aa219": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n            chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "759e302a-cfc5-448d-981b-583b5d7e885a": {"text": "\nThe code file test_base.py tests the GPTListIndex class, which is used to store and query text documents. It tests the build_list, build_list_multiple, insert, delete, and query functions, as well as the node info calculation with overlapping node text. The code uses the unittest.mock library to patch common functions, such as the LLMPredictor, PromptHelper, and TokenTextSplitter. It also uses the pytest library to create fixtures for documents and index kwargs. The code tests the ability to save and load the index from disk or a string, as well as the ability to add extra information to the documents in the index. The purpose of the code is to ensure that the GPTListIndex class functions correctly and can be used to create a list index from a list of documents and query it. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity, to achieve this.", "doc_id": "759e302a-cfc5-448d-981b-583b5d7e885a", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test list index.\"\"\"\n\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\nfrom typing import Any, Dict, List, Optional, Tuple, cast\nfrom unittest.mock import patch\n\nimport pytest\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.indices.query.list.embedding_query import GPTListIndexEmbeddingQuery\nfrom gpt_index.langchain_helpers.chain_wrapper import LLMPredictor\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.prompts.base import Prompt\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.utils import globals_helper\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_predict import mock_llmpredictor_predict\nfrom tests.mock_utils.mock_prompts import MOCK_REFINE_PROMPT, MOCK_TEXT_QA_PROMPT\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "1": {"text": "Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    index_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@pytest.fixture\ndef documents() -> List[Document]:\n    \"\"\"Get documents.\"\"\"\n    # NOTE: one document for now\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    return [Document(doc_text)]\n\n\n@patch_common\ndef test_build_list(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "2": {"text": "   _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build list.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_build_list_multiple(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n) -> None:\n    \"\"\"Test build list multiple.\"\"\"\n    documents = [\n        Document(\"Hello world.\\nThis is a test.\"),\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "3": {"text": "   Document(\"Hello world.\\nThis is a test.\"),\n        Document(\"This is another test.\\nThis is a test v2.\"),\n    ]\n    list_index = GPTListIndex(documents=documents)\n    assert len(list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_list_insert(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list.\"\"\"\n    list_index = GPTListIndex([])\n    assert len(list_index.index_struct.nodes) ==", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "4": {"text": "   assert len(list_index.index_struct.nodes) == 0\n    list_index.insert(documents[0])\n    # check contents of nodes\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n    # test insert with ID\n    document = documents[0]\n    document.doc_id = \"test_id\"\n    list_index = GPTListIndex([])\n    list_index.insert(document)\n    # check contents of nodes\n    for node in list_index.index_struct.nodes:\n        assert node.ref_doc_id == \"test_id\"\n\n\n@patch_common\ndef test_list_delete(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "5": {"text": "Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test insert to list and then delete.\"\"\"\n    new_documents = [\n        Document(\"Hello world.\\nThis is a test.\", doc_id=\"test_id_1\"),\n        Document(\"This is another test.\", doc_id=\"test_id_2\"),\n        Document(\"This is a test v2.\", doc_id=\"test_id_3\"),\n    ]\n\n    # delete from documents\n    list_index = GPTListIndex(new_documents)\n    # assert source doc is in docstore\n    source_doc = list_index.docstore.get_document(\"test_id_1\")\n    assert source_doc is not None\n    list_index.delete(\"test_id_1\")\n    assert len(list_index.index_struct.nodes) == 2\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_2\"\n    assert list_index.index_struct.nodes[0].text == \"This is another test.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_3\"\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "6": {"text": "== \"test_id_3\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test v2.\"\n    # check that not in docstore anymore\n    source_doc = list_index.docstore.get_document(\"test_id_1\", raise_error=False)\n    assert source_doc is None\n\n    list_index = GPTListIndex(new_documents)\n    list_index.delete(\"test_id_2\")\n    assert len(list_index.index_struct.nodes) == 3\n    assert list_index.index_struct.nodes[0].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert list_index.index_struct.nodes[1].ref_doc_id == \"test_id_1\"\n    assert list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert list_index.index_struct.nodes[2].ref_doc_id == \"test_id_3\"\n    assert list_index.index_struct.nodes[2].text == \"This is a test v2.\"\n\n\ndef _get_embeddings(\n    query_str: str, nodes: List[Node]\n) ->", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "7": {"text": "   query_str: str, nodes: List[Node]\n) -> Tuple[List[float], List[List[float]]]:\n    \"\"\"Get node text embedding similarity.\"\"\"\n    text_embed_map: Dict[str, List[float]] = {\n        \"Hello world.\": [1.0, 0.0, 0.0, 0.0, 0.0],\n        \"This is a test.\": [0.0, 1.0, 0.0, 0.0, 0.0],\n        \"This is another test.\": [0.0, 0.0, 1.0, 0.0, 0.0],\n        \"This is a test v2.\": [0.0, 0.0, 0.0, 1.0, 0.0],\n    }\n    node_embeddings = []\n    for node in nodes:\n        node_embeddings.append(text_embed_map[node.get_text()])\n\n    return [1.0, 0, 0, 0, 0], node_embeddings\n\n\n@patch_common\ndef test_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "8": {"text": "  _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    query_str = \"What is?\"\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:Hello world.\")\n    node_info = (\n        response.source_nodes[0].node_info if response.source_nodes[0].node_info else {}\n    )\n    assert node_info[\"start\"] == 0\n    assert node_info[\"end\"] == 12\n\n\n@patch.object(LLMPredictor, \"total_tokens_used\", return_value=0)\n@patch.object(LLMPredictor, \"predict\", side_effect=mock_llmpredictor_predict)\n@patch.object(LLMPredictor, \"__init__\", return_value=None)\ndef test_index_overlap(\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "9": {"text": "return_value=None)\ndef test_index_overlap(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test node info calculation with overlapping node text.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n\n    documents = [\n        Document(\n            \"Hello world. This is a test 1. This is a test 2.\"\n            + \" This is a test 3. This is a test 4. This is a test 5.\\n\"\n        )\n    ]\n\n    def _mock_text_splitter_with_space(\n        prompt: Prompt, num_chunks: int, padding: Optional[int] = 1\n    ) -> TokenTextSplitter:\n        \"\"\"Mock text splitter.\"\"\"\n        return TokenTextSplitter(\n            separator=\" \",\n            chunk_size=30,\n           ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "10": {"text": " chunk_size=30,\n            chunk_overlap=10,\n            tokenizer=globals_helper.tokenizer,\n        )\n\n    with patch.object(\n        PromptHelper,\n        \"get_text_splitter_given_prompt\",\n        side_effect=_mock_text_splitter_with_space,\n    ):\n        index = GPTListIndex(documents, **index_kwargs)\n\n        query_str = \"What is?\"\n        response = index.query(query_str, mode=\"default\", **query_kwargs)\n        node_info_0 = (\n            response.source_nodes[0].node_info\n            if response.source_nodes[0].node_info\n            else {}\n        )\n        # First chunk: 'Hello world. This is a test 1. This is a test 2.\n        # This is a test 3. This is a test 4. This is a'\n    ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 10, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "11": {"text": "is a test 3. This is a test 4. This is a'\n        assert node_info_0[\"start\"] == 0  # start at the start\n        assert node_info_0[\"end\"] == 94  # Length of first chunk.\n\n        node_info_1 = (\n            response.source_nodes[1].node_info\n            if response.source_nodes[1].node_info\n            else {}\n        )\n        # Second chunk: 'This is a test 4. This is a test 5.\\n'\n        assert node_info_1[\"start\"] == 67  # Position of second chunk relative to start\n        assert node_info_1[\"end\"] == 103  # End index\n\n\n@patch_common\ndef test_query_with_keywords(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs:", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 11, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "12": {"text": "   documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test list query with keywords.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test query with keywords\n    query_str = \"What is?\"\n    query_kwargs.update({\"required_keywords\": [\"test\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n    query_kwargs.update({\"exclude_keywords\": [\"Hello\"]})\n    response = index.query(query_str, mode=\"default\", **query_kwargs)\n    assert str(response) == (\"What is?:This is a test.\")\n\n\n@patch_common\n@patch.object(\n    GPTListIndexEmbeddingQuery,\n    \"_get_embeddings\",\n    side_effect=_get_embeddings,\n)\ndef test_embedding_query(\n    _mock_similarity: Any,\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 12, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "13": {"text": "   _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n    struct_kwargs: Dict,\n) -> None:\n    \"\"\"Test embedding query.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    index = GPTListIndex(documents, **index_kwargs)\n\n    # test embedding query\n    query_str = \"What is?\"\n    response = index.query(\n        query_str, mode=\"embedding\", similarity_top_k=1, **query_kwargs\n    )\n    assert str(response) == (\"What is?:Hello world.\")\n\n\n@patch_common\ndef test_extra_info(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test build/query with extra info.\"\"\"\n    doc_text = (\n        \"Hello", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 13, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "14": {"text": "   doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    extra_info = {\"extra_info\": \"extra_info\", \"foo\": \"bar\"}\n    new_document = Document(doc_text, extra_info=extra_info)\n    list_index = GPTListIndex(documents=[new_document])\n    assert list_index.index_struct.nodes[0].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"Hello world.\"\n    )\n    assert list_index.index_struct.nodes[3].get_text() == (\n        \"extra_info: extra_info\\n\" \"foo: bar\\n\\n\" \"This is a test v2.\"\n    )\n\n\n@patch_common\ndef test_to_from_disk(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 14, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "15": {"text": "   _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    with TemporaryDirectory() as tmp_dir:\n        list_index.save_to_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        new_list_index = cast(\n            GPTListIndex, GPTListIndex.load_from_disk(str(Path(tmp_dir) / \"tmp.json\"))\n        )\n        assert len(new_list_index.index_struct.nodes) == 4\n        # check contents of nodes\n        assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n        assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n        assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n        assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 15, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "16": {"text": "== \"This is another test.\"\n        assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n\n\n@patch_common\ndef test_to_from_string(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    documents: List[Document],\n) -> None:\n    \"\"\"Test saving to disk and from disk.\"\"\"\n    list_index = GPTListIndex(documents=documents)\n    new_list_index = cast(\n        GPTListIndex, GPTListIndex.load_from_string(list_index.save_to_string())\n    )\n    assert len(new_list_index.index_struct.nodes) == 4\n    # check contents of nodes\n    assert new_list_index.index_struct.nodes[0].text == \"Hello world.\"\n    assert new_list_index.index_struct.nodes[1].text == \"This is a test.\"\n    assert new_list_index.index_struct.nodes[2].text == \"This is another test.\"\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 16, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "17": {"text": "== \"This is another test.\"\n    assert new_list_index.index_struct.nodes[3].text == \"This is a test v2.\"\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/list/test_base.py", "file_name": "test_base.py"}, "index": 17, "child_indices": [], "ref_doc_id": "e08da1f225af970a08546034c5064e568f7aa219", "node_info": null}, "18": {"text": "This code file tests the GPTListIndex class, which is used to build a list index from documents. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to calculate node info with overlapping node text. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity.", "doc_id": null, "embedding": null, "extra_info": null, "index": 18, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "19": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to create a list index from a list of documents. It tests the query and embedding query functions, as well as the ability to save and load the index from disk or a string. It also tests the ability to add extra information to the documents in the index. The code uses the patch and object functions to mock certain functions and classes, and uses the globals_helper tokenizer.", "doc_id": null, "embedding": null, "extra_info": null, "index": 19, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"18": {"text": "This code file tests the GPTListIndex class, which is used to build a list index from documents. It tests the build_list, build_list_multiple, list_insert, list_delete, and query functions. It also tests the index_overlap function, which is used to calculate node info with overlapping node text. The code uses various data structures, such as dictionaries and lists, and algorithms, such as text splitting and embedding similarity.", "doc_id": null, "embedding": null, "extra_info": null, "index": 18, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}, "19": {"text": "This code file tests the functionality of the GPTListIndex class, which is used to create a list index from a list of documents. It tests the query and embedding query functions, as well as the ability to save and load the index from disk or a string. It also tests the ability to add extra information to the documents in the index. The code uses the patch and object functions to mock certain functions and classes, and uses the globals_helper tokenizer.", "doc_id": null, "embedding": null, "extra_info": null, "index": 19, "child_indices": [10, 11, 12, 13, 14, 15, 16, 17], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}