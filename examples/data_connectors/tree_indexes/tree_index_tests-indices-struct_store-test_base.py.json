{"index_struct": {"text": "\nThis code file tests the GPTSQLStructStoreIndex class, which is used to store documents in a SQL database. It creates a test table with two columns, user_id and foo, and inserts two documents into it. The code then checks that the documents were successfully inserted and that the index can be queried using both SQL and natural language. Additionally, the code tests the default output parser, which parses a string into a dictionary of fields. The purpose of the code is to ensure that the index is functioning correctly and that the output parser is able to correctly parse strings into dictionaries.", "doc_id": "1331731c-ffad-4e5f-bf03-6c3b5dfdc04c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test struct store indices.\"\"\"\n\nimport re\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport pytest\nfrom sqlalchemy import (\n    Column,\n    Integer,\n    MetaData,\n    String,\n    Table,\n    column,\n    create_engine,\n    delete,\n    select,\n)\n\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.struct_store.base import default_output_parser\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.schema import BaseDocument\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_REFINE_PROMPT,\n    MOCK_SCHEMA_EXTRACT_PROMPT,\n    MOCK_TABLE_CONTEXT_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef _mock_output_parser(output: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Mock", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "1": {"text": "str) -> Optional[Dict[str, Any]]:\n    \"\"\"Mock output parser.\n\n    Split via commas instead of newlines, in order to fit\n    the format of the mock test document (newlines create\n    separate text chunks in the testing code).\n\n    \"\"\"\n    tups = output.split(\",\")\n\n    fields = {}\n    for tup in tups:\n        if \":\" in tup:\n            tokens = tup.split(\":\")\n            field = re.sub(r\"\\W+\", \"\", tokens[0])\n            value = re.sub(r\"\\W+\", \"\", tokens[1])\n            fields[field] = value\n    return fields\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    # NOTE: QuestionAnswer and Refine templates aren't technically used\n    index_kwargs = {\n        \"schema_extract_prompt\": MOCK_SCHEMA_EXTRACT_PROMPT,\n        \"output_parser\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "2": {"text": "       \"output_parser\": _mock_output_parser,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@patch_common\ndef test_sql_index(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "3": {"text": "Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n    # try with documents with more text chunks\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "4": {"text": "       connection.execute(delete_stmt)\n    docs = [Document(text=\"user_id:2\\nfoo:bar\"), Document(text=\"user_id:8\\nfoo:hello\")]\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n\n@patch_common\ndef test_sql_index_with_context(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "5": {"text": "None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    # test setting table_context_dict\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    table_context_dict = {\"test_table\": \"test_table_context\"}\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        table_context_dict=table_context_dict,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "6": {"text": "      table_context_dict=table_context_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == table_context_dict\n\n    # test setting sql_context_builder\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n    sql_database = SQLDatabase(engine)\n    # this should cause the mock QuestionAnswer prompt to run\n    sql_context_builder = SQLContextBuilder(\n        sql_database,\n        table_context_prompt=MOCK_TABLE_CONTEXT_PROMPT,\n        table_context_task=\"extract_test\",\n    )\n    context_documents_dict: Dict[str, List[BaseDocument]] = {\n        \"test_table\": [Document(\"test_table_context\")]\n    }\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        sql_context_builder=sql_context_builder,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "7": {"text": "      sql_context_builder=sql_context_builder,\n        context_documents_dict=context_documents_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == {\n        \"test_table\": \"extract_test:test_table_context\"\n    }\n\n    # test error if both are set\n    # TODO:\n\n\n@patch_common\ndef test_sql_index_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "8": {"text": " metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    # NOTE: table is created by tying to metadata_obj\n    Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    sql_database = SQLDatabase(engine)\n    # NOTE: we can use the default output parser for this\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # query the index with SQL\n    response = index.query(\n        \"SELECT user_id, foo FROM test_table\", mode=\"sql\", **query_kwargs\n    )\n    assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n    # query the index with natural language\n    response = index.query(\"test_table:user_id,foo\", mode=\"default\", **query_kwargs)\n    assert response.response == \"[(2, 'bar'),", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "9": {"text": "   assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n\ndef test_default_output_parser() -> None:\n    \"\"\"Test default output parser.\"\"\"\n    test_str = \"user_id:2\\n\" \"foo:bar\\n\" \",,testing:testing2..\\n\" \"number:123,456,789\\n\"\n    fields = default_output_parser(test_str)\n    assert fields == {\n        \"user_id\": \"2\",\n        \"foo\": \"bar\",\n        \"testing\": \"testing2\",\n        \"number\": \"123456789\",\n    }\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "10": {"text": "This code file tests the GPTSQLStructStoreIndex, a Struct Store index used to store documents in a SQL database. It tests the index's functionality by creating a test table, inserting documents into it, and querying the index with SQL and natural language. It also tests the default output parser, which parses a string into a dictionary of fields.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file tests the GPTSQLStructStoreIndex, a Struct Store index used to store documents in a SQL database. It tests the index's functionality by creating a test table, inserting documents into it, and querying the index with SQL and natural language. It also tests the default output parser, which parses a string into a dictionary of fields.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"49a136026ce2a0e2b09e2ab3da725e37dc5f5e94": {"text": "\"\"\"Test struct store indices.\"\"\"\n\nimport re\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport pytest\nfrom sqlalchemy import (\n    Column,\n    Integer,\n    MetaData,\n    String,\n    Table,\n    column,\n    create_engine,\n    delete,\n    select,\n)\n\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.struct_store.base import default_output_parser\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.schema import BaseDocument\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_REFINE_PROMPT,\n    MOCK_SCHEMA_EXTRACT_PROMPT,\n    MOCK_TABLE_CONTEXT_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef _mock_output_parser(output: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Mock output parser.\n\n    Split via commas instead of newlines, in order to fit\n    the format of the mock test document (newlines create\n    separate text chunks in the testing code).\n\n    \"\"\"\n    tups = output.split(\",\")\n\n    fields = {}\n    for tup in tups:\n        if \":\" in tup:\n            tokens = tup.split(\":\")\n            field = re.sub(r\"\\W+\", \"\", tokens[0])\n            value = re.sub(r\"\\W+\", \"\", tokens[1])\n            fields[field] = value\n    return fields\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    # NOTE: QuestionAnswer and Refine templates aren't technically used\n    index_kwargs = {\n        \"schema_extract_prompt\": MOCK_SCHEMA_EXTRACT_PROMPT,\n        \"output_parser\": _mock_output_parser,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@patch_common\ndef test_sql_index(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n    # try with documents with more text chunks\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n    docs = [Document(text=\"user_id:2\\nfoo:bar\"), Document(text=\"user_id:8\\nfoo:hello\")]\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n\n@patch_common\ndef test_sql_index_with_context(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    # test setting table_context_dict\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    table_context_dict = {\"test_table\": \"test_table_context\"}\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        table_context_dict=table_context_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == table_context_dict\n\n    # test setting sql_context_builder\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n    sql_database = SQLDatabase(engine)\n    # this should cause the mock QuestionAnswer prompt to run\n    sql_context_builder = SQLContextBuilder(\n        sql_database,\n        table_context_prompt=MOCK_TABLE_CONTEXT_PROMPT,\n        table_context_task=\"extract_test\",\n    )\n    context_documents_dict: Dict[str, List[BaseDocument]] = {\n        \"test_table\": [Document(\"test_table_context\")]\n    }\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        sql_context_builder=sql_context_builder,\n        context_documents_dict=context_documents_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == {\n        \"test_table\": \"extract_test:test_table_context\"\n    }\n\n    # test error if both are set\n    # TODO:\n\n\n@patch_common\ndef test_sql_index_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    # NOTE: table is created by tying to metadata_obj\n    Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    sql_database = SQLDatabase(engine)\n    # NOTE: we can use the default output parser for this\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # query the index with SQL\n    response = index.query(\n        \"SELECT user_id, foo FROM test_table\", mode=\"sql\", **query_kwargs\n    )\n    assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n    # query the index with natural language\n    response = index.query(\"test_table:user_id,foo\", mode=\"default\", **query_kwargs)\n    assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n\ndef test_default_output_parser() -> None:\n    \"\"\"Test default output parser.\"\"\"\n    test_str = \"user_id:2\\n\" \"foo:bar\\n\" \",,testing:testing2..\\n\" \"number:123,456,789\\n\"\n    fields = default_output_parser(test_str)\n    assert fields == {\n        \"user_id\": \"2\",\n        \"foo\": \"bar\",\n        \"testing\": \"testing2\",\n        \"number\": \"123456789\",\n    }\n", "doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "1331731c-ffad-4e5f-bf03-6c3b5dfdc04c": {"text": "\nThis code file tests the GPTSQLStructStoreIndex class, which is used to store documents in a SQL database. It creates a test table with two columns, user_id and foo, and inserts two documents into it. The code then checks that the documents were successfully inserted and that the index can be queried using both SQL and natural language. Additionally, the code tests the default output parser, which parses a string into a dictionary of fields. The purpose of the code is to ensure that the index is functioning correctly and that the output parser is able to correctly parse strings into dictionaries.", "doc_id": "1331731c-ffad-4e5f-bf03-6c3b5dfdc04c", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test struct store indices.\"\"\"\n\nimport re\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport pytest\nfrom sqlalchemy import (\n    Column,\n    Integer,\n    MetaData,\n    String,\n    Table,\n    column,\n    create_engine,\n    delete,\n    select,\n)\n\nfrom gpt_index.indices.common.struct_store.base import SQLContextBuilder\nfrom gpt_index.indices.struct_store.base import default_output_parser\nfrom gpt_index.indices.struct_store.sql import GPTSQLStructStoreIndex\nfrom gpt_index.langchain_helpers.sql_wrapper import SQLDatabase\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.schema import BaseDocument\nfrom tests.mock_utils.mock_decorator import patch_common\nfrom tests.mock_utils.mock_prompts import (\n    MOCK_REFINE_PROMPT,\n    MOCK_SCHEMA_EXTRACT_PROMPT,\n    MOCK_TABLE_CONTEXT_PROMPT,\n    MOCK_TEXT_QA_PROMPT,\n)\n\n\ndef _mock_output_parser(output: str) -> Optional[Dict[str, Any]]:\n    \"\"\"Mock", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "1": {"text": "str) -> Optional[Dict[str, Any]]:\n    \"\"\"Mock output parser.\n\n    Split via commas instead of newlines, in order to fit\n    the format of the mock test document (newlines create\n    separate text chunks in the testing code).\n\n    \"\"\"\n    tups = output.split(\",\")\n\n    fields = {}\n    for tup in tups:\n        if \":\" in tup:\n            tokens = tup.split(\":\")\n            field = re.sub(r\"\\W+\", \"\", tokens[0])\n            value = re.sub(r\"\\W+\", \"\", tokens[1])\n            fields[field] = value\n    return fields\n\n\n@pytest.fixture\ndef struct_kwargs() -> Tuple[Dict, Dict]:\n    \"\"\"Index kwargs.\"\"\"\n    # NOTE: QuestionAnswer and Refine templates aren't technically used\n    index_kwargs = {\n        \"schema_extract_prompt\": MOCK_SCHEMA_EXTRACT_PROMPT,\n        \"output_parser\":", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "2": {"text": "       \"output_parser\": _mock_output_parser,\n    }\n    query_kwargs = {\n        \"text_qa_template\": MOCK_TEXT_QA_PROMPT,\n        \"refine_template\": MOCK_REFINE_PROMPT,\n    }\n    return index_kwargs, query_kwargs\n\n\n@patch_common\ndef test_sql_index(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\",", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 2, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "3": {"text": "Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n    # try with documents with more text chunks\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n  ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 3, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "4": {"text": "       connection.execute(delete_stmt)\n    docs = [Document(text=\"user_id:2\\nfoo:bar\"), Document(text=\"user_id:8\\nfoo:hello\")]\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n    # test that the document is inserted\n    stmt = select([column(\"user_id\"), column(\"foo\")]).select_from(test_table)\n    engine = index.sql_database.engine\n    with engine.connect() as connection:\n        results = connection.execute(stmt).fetchall()\n        assert results == [(2, \"bar\"), (8, \"hello\")]\n\n\n@patch_common\ndef test_sql_index_with_context(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n   ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 4, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "5": {"text": "None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    # test setting table_context_dict\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    test_table = Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    # NOTE: we can use the default output parser for this\n    index_kwargs, _ = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    sql_database = SQLDatabase(engine)\n    table_context_dict = {\"test_table\": \"test_table_context\"}\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        table_context_dict=table_context_dict,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 5, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "6": {"text": "      table_context_dict=table_context_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == table_context_dict\n\n    # test setting sql_context_builder\n    delete_stmt = delete(test_table)\n    with engine.connect() as connection:\n        connection.execute(delete_stmt)\n    sql_database = SQLDatabase(engine)\n    # this should cause the mock QuestionAnswer prompt to run\n    sql_context_builder = SQLContextBuilder(\n        sql_database,\n        table_context_prompt=MOCK_TABLE_CONTEXT_PROMPT,\n        table_context_task=\"extract_test\",\n    )\n    context_documents_dict: Dict[str, List[BaseDocument]] = {\n        \"test_table\": [Document(\"test_table_context\")]\n    }\n    index = GPTSQLStructStoreIndex(\n        docs,\n        sql_database=sql_database,\n        table_name=table_name,\n        sql_context_builder=sql_context_builder,\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 6, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "7": {"text": "      sql_context_builder=sql_context_builder,\n        context_documents_dict=context_documents_dict,\n        **index_kwargs\n    )\n    assert index._index_struct.context_dict == {\n        \"test_table\": \"extract_test:test_table_context\"\n    }\n\n    # test error if both are set\n    # TODO:\n\n\n@patch_common\ndef test_sql_index_query(\n    _mock_init: Any,\n    _mock_predict: Any,\n    _mock_total_tokens_used: Any,\n    _mock_split_text_overlap: Any,\n    _mock_split_text: Any,\n    struct_kwargs: Tuple[Dict, Dict],\n) -> None:\n    \"\"\"Test GPTSQLStructStoreIndex.\"\"\"\n    index_kwargs, query_kwargs = struct_kwargs\n    docs = [Document(text=\"user_id:2,foo:bar\"), Document(text=\"user_id:8,foo:hello\")]\n    engine = create_engine(\"sqlite:///:memory:\")\n    metadata_obj = MetaData(bind=engine)\n    table_name =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 7, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "8": {"text": " metadata_obj = MetaData(bind=engine)\n    table_name = \"test_table\"\n    # NOTE: table is created by tying to metadata_obj\n    Table(\n        table_name,\n        metadata_obj,\n        Column(\"user_id\", Integer, primary_key=True),\n        Column(\"foo\", String(16), nullable=False),\n    )\n    metadata_obj.create_all()\n    sql_database = SQLDatabase(engine)\n    # NOTE: we can use the default output parser for this\n    index = GPTSQLStructStoreIndex(\n        docs, sql_database=sql_database, table_name=table_name, **index_kwargs\n    )\n\n    # query the index with SQL\n    response = index.query(\n        \"SELECT user_id, foo FROM test_table\", mode=\"sql\", **query_kwargs\n    )\n    assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n    # query the index with natural language\n    response = index.query(\"test_table:user_id,foo\", mode=\"default\", **query_kwargs)\n    assert response.response == \"[(2, 'bar'),", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 8, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "9": {"text": "   assert response.response == \"[(2, 'bar'), (8, 'hello')]\"\n\n\ndef test_default_output_parser() -> None:\n    \"\"\"Test default output parser.\"\"\"\n    test_str = \"user_id:2\\n\" \"foo:bar\\n\" \",,testing:testing2..\\n\" \"number:123,456,789\\n\"\n    fields = default_output_parser(test_str)\n    assert fields == {\n        \"user_id\": \"2\",\n        \"foo\": \"bar\",\n        \"testing\": \"testing2\",\n        \"number\": \"123456789\",\n    }\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/struct_store/test_base.py", "file_name": "test_base.py"}, "index": 9, "child_indices": [], "ref_doc_id": "49a136026ce2a0e2b09e2ab3da725e37dc5f5e94", "node_info": null}, "10": {"text": "This code file tests the GPTSQLStructStoreIndex, a Struct Store index used to store documents in a SQL database. It tests the index's functionality by creating a test table, inserting documents into it, and querying the index with SQL and natural language. It also tests the default output parser, which parses a string into a dictionary of fields.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file tests the GPTSQLStructStoreIndex, a Struct Store index used to store documents in a SQL database. It tests the index's functionality by creating a test table, inserting documents into it, and querying the index with SQL and natural language. It also tests the default output parser, which parses a string into a dictionary of fields.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}