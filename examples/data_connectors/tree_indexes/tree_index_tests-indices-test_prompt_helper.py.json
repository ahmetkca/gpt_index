{"index_struct": {"text": "\nThe code file contains the PromptHelper class, which is used to manipulate text. It utilizes the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list. The PromptHelper class provides functions to split text into chunks of a given size, truncate text, and format prompts. It also provides methods to manipulate the text, such as adding or removing words, and to check the length of the text. The get_chunk_size_given_prompt function is used to determine the size of each chunk given a prompt. The get_text_splitter_given_prompt function is used to create a text splitter object that can be used to split text into chunks. The get_text_from_nodes and get_numbered_text_from_nodes functions are used to get text from a list of nodes. The compact_text_chunks function is used to compact text chunks into a single string. Finally, the get_biggest_prompt function is used to get the biggest prompt from a list of prompts. The purpose of the code is to provide a way to manipulate text in an efficient and easy to understand manner.", "doc_id": "d8766085-d8f5-4e39-bf54-b91aac4041fe", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test PromptHelper.\"\"\"\nfrom typing import List\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.prompts.base import Prompt\nfrom tests.mock_utils.mock_utils import mock_tokenizer\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\"]\n\n\ndef test_get_chunk_size() -> None:\n    \"\"\"Test get chunk size given prompt.\"\"\"\n    # test with 1 chunk\n    empty_prompt_text = \"This is the prompt\"\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 1, padding=0\n    )\n    assert chunk_size == 6\n\n    # test having 2 chunks\n    prompt_helper = PromptHelper(\n        max_input_size=11,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 0, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "1": {"text": "PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 3\n\n    # test with 2 chunks, and with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=2,\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 2\n\n    # test padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 1, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "2": {"text": "      max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=1\n    )\n    assert chunk_size == 2\n\n\ndef test_get_text_splitter() -> None:\n    \"\"\"Test get text splitter.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    assert text_splitter._chunk_size == 2\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 2, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "3": {"text": "= text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=1,\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n\n\ndef test_get_text_splitter_partial() -> None:\n    \"\"\"Test get text splitter with a partially formatted prompt.\"\"\"\n\n    class TestPromptFoo(Prompt):\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 3, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "4": {"text": "prompt.\"\"\"\n\n    class TestPromptFoo(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"foo\", \"text\"]\n\n    # test without partially formatting\n    test_prompt_text = \"This is the {foo} prompt{text}\"\n    test_prompt = TestPromptFoo(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with partially formatting\n    test_prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 4, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "5": {"text": "   # test with partially formatting\n    test_prompt = TestPromptFoo(test_prompt_text)\n    test_prompt = test_prompt.partial_format(foo=\"bar\")\n    prompt_helper = PromptHelper(\n        max_input_size=12, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    assert prompt_helper._get_empty_prompt_txt(test_prompt) == \"This is the bar prompt\"\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n\ndef test_get_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 5, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "6": {"text": "   # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=11\n    # For each text chunk, there's 4 tokens for text + 1 for the padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_text_from_nodes([node1, node2], prompt=test_prompt)\n    assert str(response) == (\"This is a test\\n\" \"Hello world bar foo\")\n\n\ndef test_get_numbered_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=17\n    # For each text chunk,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 6, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "7": {"text": "# set max_input_size=17\n    # For each text chunk, there's 3 for text, 5 for padding (including number)\n    prompt_helper = PromptHelper(\n        max_input_size=17, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_numbered_text_from_nodes(\n        [node1, node2], prompt=test_prompt\n    )\n    assert str(response) == (\"(1) This is a\\n\\n(2) Hello world bar\")\n\n\ndef test_compact_text() -> None:\n    \"\"\"Test compact text.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=9,\n        num_output=1,\n        max_chunk_overlap=0,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 7, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "8": {"text": "  max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        separator=\"\\n\\n\",\n    )\n    text_chunks = [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n    compacted_chunks = prompt_helper.compact_text_chunks(test_prompt, text_chunks)\n    assert compacted_chunks == [\"Hello\\n\\nworld\\n\\nfoo\", \"Hello\\n\\nworld\\n\\nbar\"]\n\n\ndef test_get_biggest_prompt() -> None:\n    \"\"\"Test get_biggest_prompt from PromptHelper.\"\"\"\n    # NOTE: inputs don't matter\n    prompt_helper = PromptHelper(max_input_size=1, num_output=1, max_chunk_overlap=0)\n    prompt1 = TestPrompt(\"This is the prompt{text}\")\n    prompt2 = TestPrompt(\"This is the longer prompt{text}\")\n    prompt3 = TestPrompt(\"This is the {text}\")\n    biggest_prompt = prompt_helper.get_biggest_prompt([prompt1, prompt2, prompt3])\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 8, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "9": {"text": "prompt2, prompt3])\n    assert biggest_prompt.prompt.template == prompt2.prompt.template\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 9, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "10": {"text": "This code file tests the PromptHelper class from the gpt_index library. It tests the get_chunk_size_given_prompt, get_text_splitter_given_prompt, get_text_from_nodes, get_numbered_text_from_nodes, and compact_text_chunks functions, as well as the get_biggest_prompt function. The purpose of the code is to test the functionality of the PromptHelper class, which is used to split text into chunks and truncate text, as well as to get the biggest prompt from a list of prompts. The code uses the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file tests the PromptHelper class from the gpt_index library. It tests the get_chunk_size_given_prompt, get_text_splitter_given_prompt, get_text_from_nodes, get_numbered_text_from_nodes, and compact_text_chunks functions, as well as the get_biggest_prompt function. The purpose of the code is to test the functionality of the PromptHelper class, which is used to split text into chunks and truncate text, as well as to get the biggest prompt from a list of prompts. The code uses the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"726d88a507fa99e69d3f782fb2697d21049f82e0": {"text": "\"\"\"Test PromptHelper.\"\"\"\nfrom typing import List\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.prompts.base import Prompt\nfrom tests.mock_utils.mock_utils import mock_tokenizer\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\"]\n\n\ndef test_get_chunk_size() -> None:\n    \"\"\"Test get chunk size given prompt.\"\"\"\n    # test with 1 chunk\n    empty_prompt_text = \"This is the prompt\"\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 1, padding=0\n    )\n    assert chunk_size == 6\n\n    # test having 2 chunks\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 3\n\n    # test with 2 chunks, and with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=2,\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 2\n\n    # test padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=1\n    )\n    assert chunk_size == 2\n\n\ndef test_get_text_splitter() -> None:\n    \"\"\"Test get text splitter.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    assert text_splitter._chunk_size == 2\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=1,\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n\n\ndef test_get_text_splitter_partial() -> None:\n    \"\"\"Test get text splitter with a partially formatted prompt.\"\"\"\n\n    class TestPromptFoo(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"foo\", \"text\"]\n\n    # test without partially formatting\n    test_prompt_text = \"This is the {foo} prompt{text}\"\n    test_prompt = TestPromptFoo(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with partially formatting\n    test_prompt = TestPromptFoo(test_prompt_text)\n    test_prompt = test_prompt.partial_format(foo=\"bar\")\n    prompt_helper = PromptHelper(\n        max_input_size=12, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    assert prompt_helper._get_empty_prompt_txt(test_prompt) == \"This is the bar prompt\"\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n\ndef test_get_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=11\n    # For each text chunk, there's 4 tokens for text + 1 for the padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_text_from_nodes([node1, node2], prompt=test_prompt)\n    assert str(response) == (\"This is a test\\n\" \"Hello world bar foo\")\n\n\ndef test_get_numbered_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=17\n    # For each text chunk, there's 3 for text, 5 for padding (including number)\n    prompt_helper = PromptHelper(\n        max_input_size=17, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_numbered_text_from_nodes(\n        [node1, node2], prompt=test_prompt\n    )\n    assert str(response) == (\"(1) This is a\\n\\n(2) Hello world bar\")\n\n\ndef test_compact_text() -> None:\n    \"\"\"Test compact text.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=9,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        separator=\"\\n\\n\",\n    )\n    text_chunks = [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n    compacted_chunks = prompt_helper.compact_text_chunks(test_prompt, text_chunks)\n    assert compacted_chunks == [\"Hello\\n\\nworld\\n\\nfoo\", \"Hello\\n\\nworld\\n\\nbar\"]\n\n\ndef test_get_biggest_prompt() -> None:\n    \"\"\"Test get_biggest_prompt from PromptHelper.\"\"\"\n    # NOTE: inputs don't matter\n    prompt_helper = PromptHelper(max_input_size=1, num_output=1, max_chunk_overlap=0)\n    prompt1 = TestPrompt(\"This is the prompt{text}\")\n    prompt2 = TestPrompt(\"This is the longer prompt{text}\")\n    prompt3 = TestPrompt(\"This is the {text}\")\n    biggest_prompt = prompt_helper.get_biggest_prompt([prompt1, prompt2, prompt3])\n    assert biggest_prompt.prompt.template == prompt2.prompt.template\n", "doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "__type__": "Document"}, "d8766085-d8f5-4e39-bf54-b91aac4041fe": {"text": "\nThe code file contains the PromptHelper class, which is used to manipulate text. It utilizes the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list. The PromptHelper class provides functions to split text into chunks of a given size, truncate text, and format prompts. It also provides methods to manipulate the text, such as adding or removing words, and to check the length of the text. The get_chunk_size_given_prompt function is used to determine the size of each chunk given a prompt. The get_text_splitter_given_prompt function is used to create a text splitter object that can be used to split text into chunks. The get_text_from_nodes and get_numbered_text_from_nodes functions are used to get text from a list of nodes. The compact_text_chunks function is used to compact text chunks into a single string. Finally, the get_biggest_prompt function is used to get the biggest prompt from a list of prompts. The purpose of the code is to provide a way to manipulate text in an efficient and easy to understand manner.", "doc_id": "d8766085-d8f5-4e39-bf54-b91aac4041fe", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test PromptHelper.\"\"\"\nfrom typing import List\n\nfrom gpt_index.data_structs.data_structs import Node\nfrom gpt_index.indices.prompt_helper import PromptHelper\nfrom gpt_index.prompts.base import Prompt\nfrom tests.mock_utils.mock_utils import mock_tokenizer\n\n\nclass TestPrompt(Prompt):\n    \"\"\"Test prompt class.\"\"\"\n\n    input_variables: List[str] = [\"text\"]\n\n\ndef test_get_chunk_size() -> None:\n    \"\"\"Test get chunk size given prompt.\"\"\"\n    # test with 1 chunk\n    empty_prompt_text = \"This is the prompt\"\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 1, padding=0\n    )\n    assert chunk_size == 6\n\n    # test having 2 chunks\n    prompt_helper = PromptHelper(\n        max_input_size=11,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 0, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "1": {"text": "PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 3\n\n    # test with 2 chunks, and with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=2,\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=0\n    )\n    assert chunk_size == 2\n\n    # test padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 1, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "2": {"text": "      max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    chunk_size = prompt_helper.get_chunk_size_given_prompt(\n        empty_prompt_text, 2, padding=1\n    )\n    assert chunk_size == 2\n\n\ndef test_get_text_splitter() -> None:\n    \"\"\"Test get text splitter.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    assert text_splitter._chunk_size == 2\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 2, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "3": {"text": "= text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with chunk_size_limit\n    prompt_helper = PromptHelper(\n        max_input_size=11,\n        num_output=1,\n        max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        chunk_size_limit=1,\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n\n\ndef test_get_text_splitter_partial() -> None:\n    \"\"\"Test get text splitter with a partially formatted prompt.\"\"\"\n\n    class TestPromptFoo(Prompt):\n ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 3, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "4": {"text": "prompt.\"\"\"\n\n    class TestPromptFoo(Prompt):\n        \"\"\"Test prompt class.\"\"\"\n\n        input_variables: List[str] = [\"foo\", \"text\"]\n\n    # test without partially formatting\n    test_prompt_text = \"This is the {foo} prompt{text}\"\n    test_prompt = TestPromptFoo(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n    # test with partially formatting\n    test_prompt =", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 4, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "5": {"text": "   # test with partially formatting\n    test_prompt = TestPromptFoo(test_prompt_text)\n    test_prompt = test_prompt.partial_format(foo=\"bar\")\n    prompt_helper = PromptHelper(\n        max_input_size=12, num_output=1, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    assert prompt_helper._get_empty_prompt_txt(test_prompt) == \"This is the bar prompt\"\n    text_splitter = prompt_helper.get_text_splitter_given_prompt(\n        test_prompt, 2, padding=1\n    )\n    test_text = \"Hello world foo Hello world bar\"\n    text_chunks = text_splitter.split_text(test_text)\n    assert text_chunks == [\"Hello world\", \"foo Hello\", \"world bar\"]\n    truncated_text = text_splitter.truncate_text(test_text)\n    assert truncated_text == \"Hello world\"\n\n\ndef test_get_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 5, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "6": {"text": "   # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=11\n    # For each text chunk, there's 4 tokens for text + 1 for the padding\n    prompt_helper = PromptHelper(\n        max_input_size=11, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_text_from_nodes([node1, node2], prompt=test_prompt)\n    assert str(response) == (\"This is a test\\n\" \"Hello world bar foo\")\n\n\ndef test_get_numbered_text_from_nodes() -> None:\n    \"\"\"Test get_text_from_nodes.\"\"\"\n    # test prompt uses up one token\n    test_prompt_txt = \"test{text}\"\n    test_prompt = TestPrompt(test_prompt_txt)\n    # set max_input_size=17\n    # For each text chunk,", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 6, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "7": {"text": "# set max_input_size=17\n    # For each text chunk, there's 3 for text, 5 for padding (including number)\n    prompt_helper = PromptHelper(\n        max_input_size=17, num_output=0, max_chunk_overlap=0, tokenizer=mock_tokenizer\n    )\n    node1 = Node(text=\"This is a test foo bar\")\n    node2 = Node(text=\"Hello world bar foo\")\n\n    response = prompt_helper.get_numbered_text_from_nodes(\n        [node1, node2], prompt=test_prompt\n    )\n    assert str(response) == (\"(1) This is a\\n\\n(2) Hello world bar\")\n\n\ndef test_compact_text() -> None:\n    \"\"\"Test compact text.\"\"\"\n    test_prompt_text = \"This is the prompt{text}\"\n    test_prompt = TestPrompt(test_prompt_text)\n    prompt_helper = PromptHelper(\n        max_input_size=9,\n        num_output=1,\n        max_chunk_overlap=0,\n       ", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 7, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "8": {"text": "  max_chunk_overlap=0,\n        tokenizer=mock_tokenizer,\n        separator=\"\\n\\n\",\n    )\n    text_chunks = [\"Hello\", \"world\", \"foo\", \"Hello\", \"world\", \"bar\"]\n    compacted_chunks = prompt_helper.compact_text_chunks(test_prompt, text_chunks)\n    assert compacted_chunks == [\"Hello\\n\\nworld\\n\\nfoo\", \"Hello\\n\\nworld\\n\\nbar\"]\n\n\ndef test_get_biggest_prompt() -> None:\n    \"\"\"Test get_biggest_prompt from PromptHelper.\"\"\"\n    # NOTE: inputs don't matter\n    prompt_helper = PromptHelper(max_input_size=1, num_output=1, max_chunk_overlap=0)\n    prompt1 = TestPrompt(\"This is the prompt{text}\")\n    prompt2 = TestPrompt(\"This is the longer prompt{text}\")\n    prompt3 = TestPrompt(\"This is the {text}\")\n    biggest_prompt = prompt_helper.get_biggest_prompt([prompt1, prompt2, prompt3])\n    assert", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 8, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "9": {"text": "prompt2, prompt3])\n    assert biggest_prompt.prompt.template == prompt2.prompt.template\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/indices/test_prompt_helper.py", "file_name": "test_prompt_helper.py"}, "index": 9, "child_indices": [], "ref_doc_id": "726d88a507fa99e69d3f782fb2697d21049f82e0", "node_info": null}, "10": {"text": "This code file tests the PromptHelper class from the gpt_index library. It tests the get_chunk_size_given_prompt, get_text_splitter_given_prompt, get_text_from_nodes, get_numbered_text_from_nodes, and compact_text_chunks functions, as well as the get_biggest_prompt function. The purpose of the code is to test the functionality of the PromptHelper class, which is used to split text into chunks and truncate text, as well as to get the biggest prompt from a list of prompts. The code uses the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"10": {"text": "This code file tests the PromptHelper class from the gpt_index library. It tests the get_chunk_size_given_prompt, get_text_splitter_given_prompt, get_text_from_nodes, get_numbered_text_from_nodes, and compact_text_chunks functions, as well as the get_biggest_prompt function. The purpose of the code is to test the functionality of the PromptHelper class, which is used to split text into chunks and truncate text, as well as to get the biggest prompt from a list of prompts. The code uses the Node, Prompt, and mock_tokenizer classes, as well as the input_variables list.", "doc_id": null, "embedding": null, "extra_info": null, "index": 10, "child_indices": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}