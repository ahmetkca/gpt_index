{"index_struct": {"text": "\nThis code file provides a mock implementation of a text splitter for testing purposes. It contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which both take a text string as an input and split it into tokens based on newline characters. The mock_token_splitter_newline function returns a list of strings, while the mock_token_splitter_newline_with_overlaps function returns a list of TextSplit objects, which contain the string and an offset value. This code is useful for testing text splitting algorithms and data structures.", "doc_id": "73badb86-62fb-41c3-a9b8-1c3c44ce1c31", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Mock text splitter.\"\"\"\n\nfrom typing import List, Optional\n\nfrom gpt_index.langchain_helpers.text_splitter import TextSplit\n\n\ndef mock_token_splitter_newline(\n    text: str, extra_info_str: Optional[str] = None\n) -> List[str]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    return text.split(\"\\n\")\n\n\ndef mock_token_splitter_newline_with_overlaps(\n    text: str, extra_info_str: Optional[str]\n) -> List[TextSplit]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    strings = text.split(\"\\n\")\n    return [TextSplit(string, 0) for string in strings]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/mock_utils/mock_text_splitter.py", "file_name": "mock_text_splitter.py"}, "index": 0, "child_indices": [], "ref_doc_id": "5a3061faae831fc4d5601f0ac4e30c811c1efe28", "node_info": null}, "1": {"text": "This code file contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which are used to split a given text string into tokens based on newline characters. The first function returns a list of strings, while the second returns a list of TextSplit objects, which contain the string and an offset value. The purpose of this code is to provide a mock implementation of a text splitter for testing purposes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 1, "child_indices": [0], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"1": {"text": "This code file contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which are used to split a given text string into tokens based on newline characters. The first function returns a list of strings, while the second returns a list of TextSplit objects, which contain the string and an offset value. The purpose of this code is to provide a mock implementation of a text splitter for testing purposes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 1, "child_indices": [0], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"5a3061faae831fc4d5601f0ac4e30c811c1efe28": {"text": "\"\"\"Mock text splitter.\"\"\"\n\nfrom typing import List, Optional\n\nfrom gpt_index.langchain_helpers.text_splitter import TextSplit\n\n\ndef mock_token_splitter_newline(\n    text: str, extra_info_str: Optional[str] = None\n) -> List[str]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    return text.split(\"\\n\")\n\n\ndef mock_token_splitter_newline_with_overlaps(\n    text: str, extra_info_str: Optional[str]\n) -> List[TextSplit]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    strings = text.split(\"\\n\")\n    return [TextSplit(string, 0) for string in strings]\n", "doc_id": "5a3061faae831fc4d5601f0ac4e30c811c1efe28", "embedding": null, "extra_info": {"file_path": "tests/mock_utils/mock_text_splitter.py", "file_name": "mock_text_splitter.py"}, "__type__": "Document"}, "73badb86-62fb-41c3-a9b8-1c3c44ce1c31": {"text": "\nThis code file provides a mock implementation of a text splitter for testing purposes. It contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which both take a text string as an input and split it into tokens based on newline characters. The mock_token_splitter_newline function returns a list of strings, while the mock_token_splitter_newline_with_overlaps function returns a list of TextSplit objects, which contain the string and an offset value. This code is useful for testing text splitting algorithms and data structures.", "doc_id": "73badb86-62fb-41c3-a9b8-1c3c44ce1c31", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Mock text splitter.\"\"\"\n\nfrom typing import List, Optional\n\nfrom gpt_index.langchain_helpers.text_splitter import TextSplit\n\n\ndef mock_token_splitter_newline(\n    text: str, extra_info_str: Optional[str] = None\n) -> List[str]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    return text.split(\"\\n\")\n\n\ndef mock_token_splitter_newline_with_overlaps(\n    text: str, extra_info_str: Optional[str]\n) -> List[TextSplit]:\n    \"\"\"Mock token splitter by newline.\"\"\"\n    if text == \"\":\n        return []\n    strings = text.split(\"\\n\")\n    return [TextSplit(string, 0) for string in strings]\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/mock_utils/mock_text_splitter.py", "file_name": "mock_text_splitter.py"}, "index": 0, "child_indices": [], "ref_doc_id": "5a3061faae831fc4d5601f0ac4e30c811c1efe28", "node_info": null}, "1": {"text": "This code file contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which are used to split a given text string into tokens based on newline characters. The first function returns a list of strings, while the second returns a list of TextSplit objects, which contain the string and an offset value. The purpose of this code is to provide a mock implementation of a text splitter for testing purposes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 1, "child_indices": [0], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"1": {"text": "This code file contains two functions, mock_token_splitter_newline and mock_token_splitter_newline_with_overlaps, which are used to split a given text string into tokens based on newline characters. The first function returns a list of strings, while the second returns a list of TextSplit objects, which contain the string and an offset value. The purpose of this code is to provide a mock implementation of a text splitter for testing purposes.", "doc_id": null, "embedding": null, "extra_info": null, "index": 1, "child_indices": [0], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}