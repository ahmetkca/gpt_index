{"index_struct": {"text": "\nThis code file tests a token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The mock token splitter splits the text into tokens, the mock LLM predictor counts the tokens, and the three indices store and query the data. The query function searches for specific tokens in the data. The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": "b55f2bd8-5005-4430-9317-b94e3cf47253", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test token predictor.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.token_counter.mock_chain_wrapper import MockLLMPredictor\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\ndef test_token_predictor(mock_split: Any) -> None:\n    \"\"\"Test token predictor.\"\"\"\n    # here, just assert that token predictor runs (before checking behavior)\n    # TODO: mock token counting a bit more carefully\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/token_predictor/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e0e254d6052ab57612b1bac55836ca45a71c201b", "node_info": null}, "1": {"text": "is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    document = Document(doc_text)\n    llm_predictor = MockLLMPredictor(max_tokens=256)\n\n    # test tree index\n    index = GPTTreeIndex([document], llm_predictor=llm_predictor)\n    index.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test keyword table index\n    index_keyword = GPTKeywordTableIndex([document], llm_predictor=llm_predictor)\n    index_keyword.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test list index\n    index_list = GPTListIndex([document], llm_predictor=llm_predictor)\n    index_list.query(\"What is?\", llm_predictor=llm_predictor)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/token_predictor/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e0e254d6052ab57612b1bac55836ca45a71c201b", "node_info": null}, "2": {"text": "This code file tests the token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": null, "embedding": null, "extra_info": null, "index": 2, "child_indices": [0, 1], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"2": {"text": "This code file tests the token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": null, "embedding": null, "extra_info": null, "index": 2, "child_indices": [0, 1], "ref_doc_id": null, "node_info": null}}}, "docstore": {"docs": {"e0e254d6052ab57612b1bac55836ca45a71c201b": {"text": "\"\"\"Test token predictor.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.token_counter.mock_chain_wrapper import MockLLMPredictor\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\ndef test_token_predictor(mock_split: Any) -> None:\n    \"\"\"Test token predictor.\"\"\"\n    # here, just assert that token predictor runs (before checking behavior)\n    # TODO: mock token counting a bit more carefully\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    document = Document(doc_text)\n    llm_predictor = MockLLMPredictor(max_tokens=256)\n\n    # test tree index\n    index = GPTTreeIndex([document], llm_predictor=llm_predictor)\n    index.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test keyword table index\n    index_keyword = GPTKeywordTableIndex([document], llm_predictor=llm_predictor)\n    index_keyword.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test list index\n    index_list = GPTListIndex([document], llm_predictor=llm_predictor)\n    index_list.query(\"What is?\", llm_predictor=llm_predictor)\n", "doc_id": "e0e254d6052ab57612b1bac55836ca45a71c201b", "embedding": null, "extra_info": {"file_path": "tests/token_predictor/test_base.py", "file_name": "test_base.py"}, "__type__": "Document"}, "b55f2bd8-5005-4430-9317-b94e3cf47253": {"text": "\nThis code file tests a token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The mock token splitter splits the text into tokens, the mock LLM predictor counts the tokens, and the three indices store and query the data. The query function searches for specific tokens in the data. The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": "b55f2bd8-5005-4430-9317-b94e3cf47253", "embedding": null, "extra_info": null, "all_nodes": {"0": {"text": "\"\"\"Test token predictor.\"\"\"\n\nfrom typing import Any\nfrom unittest.mock import patch\n\nfrom gpt_index.indices.keyword_table.base import GPTKeywordTableIndex\nfrom gpt_index.indices.list.base import GPTListIndex\nfrom gpt_index.indices.tree.base import GPTTreeIndex\nfrom gpt_index.langchain_helpers.text_splitter import TokenTextSplitter\nfrom gpt_index.readers.schema.base import Document\nfrom gpt_index.token_counter.mock_chain_wrapper import MockLLMPredictor\nfrom tests.mock_utils.mock_text_splitter import mock_token_splitter_newline\n\n\n@patch.object(TokenTextSplitter, \"split_text\", side_effect=mock_token_splitter_newline)\ndef test_token_predictor(mock_split: Any) -> None:\n    \"\"\"Test token predictor.\"\"\"\n    # here, just assert that token predictor runs (before checking behavior)\n    # TODO: mock token counting a bit more carefully\n    doc_text = (\n        \"Hello world.\\n\"\n        \"This is a test.\\n\"\n        \"This is another test.\\n\"\n        \"This is a test", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/token_predictor/test_base.py", "file_name": "test_base.py"}, "index": 0, "child_indices": [], "ref_doc_id": "e0e254d6052ab57612b1bac55836ca45a71c201b", "node_info": null}, "1": {"text": "is another test.\\n\"\n        \"This is a test v2.\"\n    )\n    document = Document(doc_text)\n    llm_predictor = MockLLMPredictor(max_tokens=256)\n\n    # test tree index\n    index = GPTTreeIndex([document], llm_predictor=llm_predictor)\n    index.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test keyword table index\n    index_keyword = GPTKeywordTableIndex([document], llm_predictor=llm_predictor)\n    index_keyword.query(\"What is?\", llm_predictor=llm_predictor)\n\n    # test list index\n    index_list = GPTListIndex([document], llm_predictor=llm_predictor)\n    index_list.query(\"What is?\", llm_predictor=llm_predictor)\n", "doc_id": null, "embedding": null, "extra_info": {"file_path": "tests/token_predictor/test_base.py", "file_name": "test_base.py"}, "index": 1, "child_indices": [], "ref_doc_id": "e0e254d6052ab57612b1bac55836ca45a71c201b", "node_info": null}, "2": {"text": "This code file tests the token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": null, "embedding": null, "extra_info": null, "index": 2, "child_indices": [0, 1], "ref_doc_id": null, "node_info": null}}, "root_nodes": {"2": {"text": "This code file tests the token predictor by using a mock token splitter, a mock LLM predictor, and three different indices (GPTTreeIndex, GPTKeywordTableIndex, and GPTListIndex). The purpose of the code is to ensure that the token predictor runs correctly and that the query function works as expected.", "doc_id": null, "embedding": null, "extra_info": null, "index": 2, "child_indices": [0, 1], "ref_doc_id": null, "node_info": null}}, "__type__": "tree"}}}}